2013-08-16 10:54:16,119 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-16 10:54:16,168 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-16 10:54:16,360 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-16 10:54:16,508 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-16 10:54:16,509 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-16 10:54:16,533 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-16 10:54:16,533 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1376648880181_0010, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-16 10:54:16,658 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-16 10:54:17,337 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010
2013-08-16 10:54:17,674 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-16 10:54:17,677 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-16 10:54:17,678 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-16 10:54:17,679 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-16 10:54:17,680 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-16 10:54:17,681 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-16 10:54:17,681 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-16 10:54:17,682 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-16 10:54:17,682 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-16 10:54:17,952 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-16 10:54:18,510 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-16 10:54:18,626 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1622c7d6
2013-08-16 10:54:18,671 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-16 10:54:18,678 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376648880181_0010_r_000009_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-16 10:54:18,700 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 1 to fetcher#5
2013-08-16 10:54:18,700 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-3:8080 to fetcher#5
2013-08-16 10:54:18,701 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 1 to fetcher#1
2013-08-16 10:54:18,706 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-5:8080 to fetcher#1
2013-08-16 10:54:18,708 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 1 to fetcher#4
2013-08-16 10:54:18,708 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-4:8080 to fetcher#4
2013-08-16 10:54:18,710 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#2
2013-08-16 10:54:18,711 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-6:8080 to fetcher#2
2013-08-16 10:54:18,711 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 1 to fetcher#3
2013-08-16 10:54:18,711 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-7:8080 to fetcher#3
2013-08-16 10:54:18,724 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376648880181_0010_r_000009_1: Got 40 new map-outputs
2013-08-16 10:54:18,951 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000007_0 sent hash and received reply
2013-08-16 10:54:18,951 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000001_0 sent hash and received reply
2013-08-16 10:54:18,953 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000003_0 sent hash and received reply
2013-08-16 10:54:18,954 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000002_0 sent hash and received reply
2013-08-16 10:54:18,965 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000007_0 decomp: 13894194 len: 13894198 to MEMORY
2013-08-16 10:54:19,006 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000002_0 decomp: 13877658 len: 13877662 to MEMORY
2013-08-16 10:54:19,010 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000003_0 decomp: 13934650 len: 13934654 to MEMORY
2013-08-16 10:54:19,015 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000001_0 decomp: 13829090 len: 13829094 to MEMORY
2013-08-16 10:54:19,137 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13894194 bytes from map-output for attempt_1376648880181_0010_m_000007_0
2013-08-16 10:54:19,142 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13894194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55535592
2013-08-16 10:54:19,144 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#3 in 433s
2013-08-16 10:54:19,144 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 4 to fetcher#3
2013-08-16 10:54:19,144 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-2:8080 to fetcher#3
2013-08-16 10:54:19,157 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000010_0,attempt_1376648880181_0010_m_000018_0,attempt_1376648880181_0010_m_000021_0,attempt_1376648880181_0010_m_000030_0 sent hash and received reply
2013-08-16 10:54:19,177 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000010_0 decomp: 13910730 len: 13910734 to MEMORY
2013-08-16 10:54:19,537 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13829090 bytes from map-output for attempt_1376648880181_0010_m_000001_0
2013-08-16 10:54:19,538 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13829090, inMemoryMapOutputs.size() -> 2, commitMemory -> 13894194, usedMemory ->69446322
2013-08-16 10:54:19,539 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#5 in 839s
2013-08-16 10:54:19,540 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 7 to fetcher#5
2013-08-16 10:54:19,540 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-512-3:8080 to fetcher#5
2013-08-16 10:54:19,552 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000004_0,attempt_1376648880181_0010_m_000012_0,attempt_1376648880181_0010_m_000016_0,attempt_1376648880181_0010_m_000023_0,attempt_1376648880181_0010_m_000025_0,attempt_1376648880181_0010_m_000028_0,attempt_1376648880181_0010_m_000037_0 sent hash and received reply
2013-08-16 10:54:19,731 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000004_0 decomp: 13896274 len: 13896278 to MEMORY
2013-08-16 10:54:19,777 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13877658 bytes from map-output for attempt_1376648880181_0010_m_000002_0
2013-08-16 10:54:19,778 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13877658, inMemoryMapOutputs.size() -> 3, commitMemory -> 27723284, usedMemory ->83342596
2013-08-16 10:54:19,778 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#2 in 1067s
2013-08-16 10:54:19,778 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 6 to fetcher#2
2013-08-16 10:54:19,778 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-6:8080 to fetcher#2
2013-08-16 10:54:19,783 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000017_0,attempt_1376648880181_0010_m_000022_0,attempt_1376648880181_0010_m_000020_0,attempt_1376648880181_0010_m_000035_0,attempt_1376648880181_0010_m_000033_0,attempt_1376648880181_0010_m_000039_1 sent hash and received reply
2013-08-16 10:54:19,788 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000017_0 decomp: 13907714 len: 13907718 to MEMORY
2013-08-16 10:54:19,967 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13907714 bytes from map-output for attempt_1376648880181_0010_m_000017_0
2013-08-16 10:54:19,969 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13907714, inMemoryMapOutputs.size() -> 4, commitMemory -> 41600942, usedMemory ->97250310
2013-08-16 10:54:19,975 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000022_0 decomp: 13916138 len: 13916142 to MEMORY
2013-08-16 10:54:20,089 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13916138 bytes from map-output for attempt_1376648880181_0010_m_000022_0
2013-08-16 10:54:20,091 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13916138, inMemoryMapOutputs.size() -> 5, commitMemory -> 55508656, usedMemory ->111166448
2013-08-16 10:54:20,104 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000020_0 decomp: 13899394 len: 13899398 to MEMORY
2013-08-16 10:54:20,134 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13934650 bytes from map-output for attempt_1376648880181_0010_m_000003_0
2013-08-16 10:54:20,134 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13934650, inMemoryMapOutputs.size() -> 6, commitMemory -> 69424794, usedMemory ->125065842
2013-08-16 10:54:20,136 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#1 in 1430s
2013-08-16 10:54:20,137 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 7 to fetcher#1
2013-08-16 10:54:20,137 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-512-5:8080 to fetcher#1
2013-08-16 10:54:20,153 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000009_0,attempt_1376648880181_0010_m_000014_0,attempt_1376648880181_0010_m_000015_0,attempt_1376648880181_0010_m_000024_0,attempt_1376648880181_0010_m_000029_0,attempt_1376648880181_0010_m_000027_0,attempt_1376648880181_0010_m_000034_0 sent hash and received reply
2013-08-16 10:54:20,276 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000009_0 decomp: 13863618 len: 13863622 to MEMORY
2013-08-16 10:54:20,388 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13899394 bytes from map-output for attempt_1376648880181_0010_m_000020_0
2013-08-16 10:54:20,393 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13899394, inMemoryMapOutputs.size() -> 7, commitMemory -> 83359444, usedMemory ->138929460
2013-08-16 10:54:20,393 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97258838 > mergeThreshold=86139864. Current usedMemory=138929460
2013-08-16 10:54:20,396 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 10:54:20,397 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 10:54:20,398 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#2 in 620s
2013-08-16 10:54:20,408 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896274 bytes from map-output for attempt_1376648880181_0010_m_000004_0
2013-08-16 10:54:20,408 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896274, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138929460
2013-08-16 10:54:20,409 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-16 10:54:20,411 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#5 in 871s
2013-08-16 10:54:20,523 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13910730 bytes from map-output for attempt_1376648880181_0010_m_000010_0
2013-08-16 10:54:20,524 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13910730, inMemoryMapOutputs.size() -> 2, commitMemory -> 13896274, usedMemory ->138929460
2013-08-16 10:54:20,527 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 10:54:20,529 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#3 in 1385s
2013-08-16 10:54:20,693 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 10:54:20,701 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 10:54:20,702 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97258747 bytes
2013-08-16 10:54:22,631 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376648880181_0010_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010/output/attempt_1376648880181_0010_r_000009_1/map_1.out.merged of size 97258830
2013-08-16 10:54:22,631 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 3 to fetcher#3
2013-08-16 10:54:22,632 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-2:8080 to fetcher#3
2013-08-16 10:54:22,632 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#2
2013-08-16 10:54:22,632 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#2
2013-08-16 10:54:22,633 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 3 to fetcher#5
2013-08-16 10:54:22,634 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-6:8080 to fetcher#5
2013-08-16 10:54:22,635 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000032_0,attempt_1376648880181_0010_m_000036_1 sent hash and received reply
2013-08-16 10:54:22,637 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000030_0,attempt_1376648880181_0010_m_000018_0,attempt_1376648880181_0010_m_000021_0 sent hash and received reply
2013-08-16 10:54:22,639 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000039_1,attempt_1376648880181_0010_m_000035_0,attempt_1376648880181_0010_m_000033_0 sent hash and received reply
2013-08-16 10:54:22,642 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000032_0 decomp: 13853010 len: 13853014 to MEMORY
2013-08-16 10:54:22,718 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000030_0 decomp: 13919882 len: 13919886 to MEMORY
2013-08-16 10:54:22,726 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000039_1 decomp: 13937770 len: 13937774 to MEMORY
2013-08-16 10:54:22,860 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13937770 bytes from map-output for attempt_1376648880181_0010_m_000039_1
2013-08-16 10:54:22,861 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13937770, inMemoryMapOutputs.size() -> 3, commitMemory -> 27807004, usedMemory ->83381284
2013-08-16 10:54:22,865 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000035_0 decomp: 13853010 len: 13853014 to MEMORY
2013-08-16 10:54:22,972 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13853010 bytes from map-output for attempt_1376648880181_0010_m_000032_0
2013-08-16 10:54:22,972 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13853010, inMemoryMapOutputs.size() -> 4, commitMemory -> 41744774, usedMemory ->97234294
2013-08-16 10:54:22,978 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000036_1 decomp: 13845938 len: 13845942 to MEMORY
2013-08-16 10:54:23,013 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13863618 bytes from map-output for attempt_1376648880181_0010_m_000009_0
2013-08-16 10:54:23,015 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13863618, inMemoryMapOutputs.size() -> 5, commitMemory -> 55597784, usedMemory ->111080232
2013-08-16 10:54:23,110 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13845938 bytes from map-output for attempt_1376648880181_0010_m_000036_1
2013-08-16 10:54:23,114 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13845938, inMemoryMapOutputs.size() -> 6, commitMemory -> 69461402, usedMemory ->124947386
2013-08-16 10:54:23,114 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000014_0 decomp: 13867154 len: 13867158 to MEMORY
2013-08-16 10:54:23,115 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#2 in 483s
2013-08-16 10:54:23,115 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 6 to fetcher#2
2013-08-16 10:54:23,115 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-3:8080 to fetcher#2
2013-08-16 10:54:23,122 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000012_0,attempt_1376648880181_0010_m_000023_0,attempt_1376648880181_0010_m_000037_0,attempt_1376648880181_0010_m_000025_0,attempt_1376648880181_0010_m_000028_0,attempt_1376648880181_0010_m_000016_0 sent hash and received reply
2013-08-16 10:54:23,127 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000012_0 decomp: 13775218 len: 13775222 to MEMORY
2013-08-16 10:54:23,169 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13853010 bytes from map-output for attempt_1376648880181_0010_m_000035_0
2013-08-16 10:54:23,169 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13853010, inMemoryMapOutputs.size() -> 7, commitMemory -> 83307340, usedMemory ->138722604
2013-08-16 10:54:23,169 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97160350 > mergeThreshold=86139864. Current usedMemory=138722604
2013-08-16 10:54:23,171 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 10:54:23,173 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-16 10:54:23,174 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#5 in 540s
2013-08-16 10:54:23,403 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 10:54:23,404 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 10:54:23,404 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97160259 bytes
2013-08-16 10:54:23,693 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13775218 bytes from map-output for attempt_1376648880181_0010_m_000012_0
2013-08-16 10:54:23,693 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13775218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138722604
2013-08-16 10:54:23,694 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 10:54:23,695 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#2 in 579s
2013-08-16 10:54:23,702 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13919882 bytes from map-output for attempt_1376648880181_0010_m_000030_0
2013-08-16 10:54:23,702 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13919882, inMemoryMapOutputs.size() -> 2, commitMemory -> 13775218, usedMemory ->138722604
2013-08-16 10:54:23,703 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 10:54:23,703 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#3 in 1072s
2013-08-16 10:54:23,932 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13867154 bytes from map-output for attempt_1376648880181_0010_m_000014_0
2013-08-16 10:54:23,932 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13867154, inMemoryMapOutputs.size() -> 3, commitMemory -> 27695100, usedMemory ->138722604
2013-08-16 10:54:23,933 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-16 10:54:23,933 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#1 in 3796s
2013-08-16 10:54:24,438 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376648880181_0010_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010/output/attempt_1376648880181_0010_r_000009_1/map_36.out.merged of size 97160342
2013-08-16 10:54:24,438 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#3
2013-08-16 10:54:24,438 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-6:8080 to fetcher#3
2013-08-16 10:54:24,439 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 5 to fetcher#2
2013-08-16 10:54:24,439 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-5:8080 to fetcher#2
2013-08-16 10:54:24,440 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 2 to fetcher#5
2013-08-16 10:54:24,440 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-2:8080 to fetcher#5
2013-08-16 10:54:24,440 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 5 to fetcher#1
2013-08-16 10:54:24,440 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-3:8080 to fetcher#1
2013-08-16 10:54:24,442 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000033_0 sent hash and received reply
2013-08-16 10:54:24,496 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000023_0,attempt_1376648880181_0010_m_000037_0,attempt_1376648880181_0010_m_000025_0,attempt_1376648880181_0010_m_000016_0,attempt_1376648880181_0010_m_000028_0 sent hash and received reply
2013-08-16 10:54:24,496 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000018_0,attempt_1376648880181_0010_m_000021_0 sent hash and received reply
2013-08-16 10:54:24,497 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000029_0,attempt_1376648880181_0010_m_000034_0,attempt_1376648880181_0010_m_000024_0,attempt_1376648880181_0010_m_000027_0,attempt_1376648880181_0010_m_000015_0 sent hash and received reply
2013-08-16 10:54:24,498 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000033_0 decomp: 13848330 len: 13848334 to MEMORY
2013-08-16 10:54:24,502 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000018_0 decomp: 13867882 len: 13867886 to MEMORY
2013-08-16 10:54:24,505 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000029_0 decomp: 13897522 len: 13897526 to MEMORY
2013-08-16 10:54:24,509 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000023_0 decomp: 13842402 len: 13842406 to MEMORY
2013-08-16 10:54:24,598 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13848330 bytes from map-output for attempt_1376648880181_0010_m_000033_0
2013-08-16 10:54:24,599 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13848330, inMemoryMapOutputs.size() -> 4, commitMemory -> 41562254, usedMemory ->97018390
2013-08-16 10:54:24,599 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#3 in 161s
2013-08-16 10:54:24,968 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13842402 bytes from map-output for attempt_1376648880181_0010_m_000023_0
2013-08-16 10:54:24,968 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13842402, inMemoryMapOutputs.size() -> 5, commitMemory -> 55410584, usedMemory ->97018390
2013-08-16 10:54:25,058 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000037_0 decomp: 13855090 len: 13855094 to MEMORY
2013-08-16 10:54:25,320 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13867882 bytes from map-output for attempt_1376648880181_0010_m_000018_0
2013-08-16 10:54:25,320 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13867882, inMemoryMapOutputs.size() -> 6, commitMemory -> 69252986, usedMemory ->110873480
2013-08-16 10:54:25,325 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376648880181_0010_m_000021_0 decomp: 13897210 len: 13897214 to MEMORY
2013-08-16 10:54:25,544 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13855090 bytes from map-output for attempt_1376648880181_0010_m_000037_0
2013-08-16 10:54:25,544 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13855090, inMemoryMapOutputs.size() -> 7, commitMemory -> 83120868, usedMemory ->124770690
2013-08-16 10:54:25,545 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=96975958 > mergeThreshold=86139864. Current usedMemory=124770690
2013-08-16 10:54:25,546 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 10:54:25,563 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376648880181_0010_m_000025_0 decomp: 13887018 len: 13887022 to MEMORY
2013-08-16 10:54:25,867 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 10:54:25,867 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 10:54:25,868 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 96975867 bytes
2013-08-16 10:54:26,021 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13897210 bytes from map-output for attempt_1376648880181_0010_m_000021_0
2013-08-16 10:54:26,022 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13897210, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138657708
2013-08-16 10:54:26,022 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#5 in 1582s
2013-08-16 10:54:26,105 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13887018 bytes from map-output for attempt_1376648880181_0010_m_000025_0
2013-08-16 10:54:26,105 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13887018, inMemoryMapOutputs.size() -> 2, commitMemory -> 13897210, usedMemory ->138657708
2013-08-16 10:54:26,106 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-16 10:54:26,106 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#1 in 1666s
2013-08-16 10:54:26,107 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 2 to fetcher#3
2013-08-16 10:54:26,107 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-3:8080 to fetcher#3
2013-08-16 10:54:26,111 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000028_0,attempt_1376648880181_0010_m_000016_0 sent hash and received reply
2013-08-16 10:54:26,112 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 10:54:26,112 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#3 in 5s
2013-08-16 10:54:27,299 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376648880181_0010_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010/output/attempt_1376648880181_0010_r_000009_1/map_12.out.merged of size 96975950
2013-08-16 10:54:27,299 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 2 to fetcher#3
2013-08-16 10:54:27,299 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-3:8080 to fetcher#3
2013-08-16 10:54:27,304 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000016_0,attempt_1376648880181_0010_m_000028_0 sent hash and received reply
2013-08-16 10:54:27,310 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000016_0 decomp: 13883274 len: 13883278 to MEMORY
2013-08-16 10:54:27,546 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13883274 bytes from map-output for attempt_1376648880181_0010_m_000016_0
2013-08-16 10:54:27,546 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13883274, inMemoryMapOutputs.size() -> 3, commitMemory -> 27784228, usedMemory ->55565024
2013-08-16 10:54:27,551 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376648880181_0010_m_000028_0 decomp: 13898458 len: 13898462 to MEMORY
2013-08-16 10:54:27,716 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13898458 bytes from map-output for attempt_1376648880181_0010_m_000028_0
2013-08-16 10:54:27,765 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13898458, inMemoryMapOutputs.size() -> 4, commitMemory -> 41667502, usedMemory ->69463482
2013-08-16 10:54:27,765 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#3 in 466s
2013-08-16 10:54:28,218 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13897522 bytes from map-output for attempt_1376648880181_0010_m_000029_0
2013-08-16 10:54:28,218 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13897522, inMemoryMapOutputs.size() -> 5, commitMemory -> 55565960, usedMemory ->69463482
2013-08-16 10:54:28,311 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000034_0 decomp: 13847498 len: 13847502 to MEMORY
2013-08-16 10:54:33,002 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13847498 bytes from map-output for attempt_1376648880181_0010_m_000034_0
2013-08-16 10:54:33,003 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13847498, inMemoryMapOutputs.size() -> 6, commitMemory -> 69463482, usedMemory ->83310980
2013-08-16 10:54:33,007 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000024_0 decomp: 13896066 len: 13896070 to MEMORY
2013-08-16 10:54:35,002 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896066 bytes from map-output for attempt_1376648880181_0010_m_000024_0
2013-08-16 10:54:35,002 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896066, inMemoryMapOutputs.size() -> 7, commitMemory -> 83310980, usedMemory ->97207046
2013-08-16 10:54:35,002 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97207046 > mergeThreshold=86139864. Current usedMemory=97207046
2013-08-16 10:54:35,003 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 10:54:35,020 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000027_0 decomp: 13856546 len: 13856550 to MEMORY
2013-08-16 10:54:35,330 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 10:54:35,330 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 10:54:35,330 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97206955 bytes
2013-08-16 10:54:36,478 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376648880181_0010_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010/output/attempt_1376648880181_0010_r_000009_1/map_34.out.merged of size 97207038
2013-08-16 10:54:38,686 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13856546 bytes from map-output for attempt_1376648880181_0010_m_000027_0
2013-08-16 10:54:38,686 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13856546, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13856546
2013-08-16 10:54:38,691 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376648880181_0010_m_000015_0 decomp: 13942450 len: 13942454 to MEMORY
2013-08-16 10:54:40,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13942450 bytes from map-output for attempt_1376648880181_0010_m_000015_0
2013-08-16 10:54:40,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13942450, inMemoryMapOutputs.size() -> 2, commitMemory -> 13856546, usedMemory ->27798996
2013-08-16 10:54:40,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#2 in 15636s
2013-08-16 10:54:42,493 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000000_0 sent hash and received reply
2013-08-16 10:54:42,502 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000000_0 decomp: 13950250 len: 13950254 to MEMORY
2013-08-16 10:55:07,111 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13950250 bytes from map-output for attempt_1376648880181_0010_m_000000_0
2013-08-16 10:55:07,112 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13950250, inMemoryMapOutputs.size() -> 3, commitMemory -> 27798996, usedMemory ->41749246
2013-08-16 10:55:07,112 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#4 in 48404s
2013-08-16 10:55:07,112 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 9 to fetcher#4
2013-08-16 10:55:07,113 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-512-4:8080 to fetcher#4
2013-08-16 10:55:07,120 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376648880181_0010&reduce=9&map=attempt_1376648880181_0010_m_000005_0,attempt_1376648880181_0010_m_000006_0,attempt_1376648880181_0010_m_000011_0,attempt_1376648880181_0010_m_000008_0,attempt_1376648880181_0010_m_000013_0,attempt_1376648880181_0010_m_000019_0,attempt_1376648880181_0010_m_000026_0,attempt_1376648880181_0010_m_000031_0,attempt_1376648880181_0010_m_000038_0 sent hash and received reply
2013-08-16 10:55:07,126 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000005_0 decomp: 13862162 len: 13862166 to MEMORY
2013-08-16 10:55:14,567 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13862162 bytes from map-output for attempt_1376648880181_0010_m_000005_0
2013-08-16 10:55:14,567 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13862162, inMemoryMapOutputs.size() -> 4, commitMemory -> 41749246, usedMemory ->55611408
2013-08-16 10:55:14,572 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000006_0 decomp: 13843442 len: 13843446 to MEMORY
2013-08-16 10:55:16,742 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13843442 bytes from map-output for attempt_1376648880181_0010_m_000006_0
2013-08-16 10:55:16,742 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13843442, inMemoryMapOutputs.size() -> 5, commitMemory -> 55611408, usedMemory ->69454850
2013-08-16 10:55:16,878 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000011_0 decomp: 13850202 len: 13850206 to MEMORY
2013-08-16 10:55:20,035 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13850202 bytes from map-output for attempt_1376648880181_0010_m_000011_0
2013-08-16 10:55:20,035 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13850202, inMemoryMapOutputs.size() -> 6, commitMemory -> 69454850, usedMemory ->83305052
2013-08-16 10:55:20,039 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000008_0 decomp: 13927578 len: 13927582 to MEMORY
2013-08-16 10:55:27,115 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13927578 bytes from map-output for attempt_1376648880181_0010_m_000008_0
2013-08-16 10:55:27,115 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13927578, inMemoryMapOutputs.size() -> 7, commitMemory -> 83305052, usedMemory ->97232630
2013-08-16 10:55:27,115 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97232630 > mergeThreshold=86139864. Current usedMemory=97232630
2013-08-16 10:55:27,115 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 10:55:27,119 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000013_0 decomp: 13898146 len: 13898150 to MEMORY
2013-08-16 10:55:27,507 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 10:55:27,508 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 10:55:27,508 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97232539 bytes
2013-08-16 10:55:28,662 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376648880181_0010_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376648880181_0010/output/attempt_1376648880181_0010_r_000009_1/map_6.out.merged of size 97232622
2013-08-16 10:55:34,113 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13898146 bytes from map-output for attempt_1376648880181_0010_m_000013_0
2013-08-16 10:55:34,114 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13898146, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13898146
2013-08-16 10:55:34,118 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000019_0 decomp: 13909170 len: 13909174 to MEMORY
2013-08-16 10:55:41,267 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909170 bytes from map-output for attempt_1376648880181_0010_m_000019_0
2013-08-16 10:55:41,267 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909170, inMemoryMapOutputs.size() -> 2, commitMemory -> 13898146, usedMemory ->27807316
2013-08-16 10:55:41,342 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000026_0 decomp: 13889930 len: 13889934 to MEMORY
2013-08-16 10:55:46,336 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13889930 bytes from map-output for attempt_1376648880181_0010_m_000026_0
2013-08-16 10:55:46,339 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13889930, inMemoryMapOutputs.size() -> 3, commitMemory -> 27807316, usedMemory ->41697246
2013-08-16 10:55:46,344 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000031_0 decomp: 13890450 len: 13890454 to MEMORY
2013-08-16 10:55:49,212 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13890450 bytes from map-output for attempt_1376648880181_0010_m_000031_0
2013-08-16 10:55:49,213 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13890450, inMemoryMapOutputs.size() -> 4, commitMemory -> 41697246, usedMemory ->55587696
2013-08-16 10:55:49,219 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376648880181_0010_m_000038_0 decomp: 13851242 len: 13851246 to MEMORY
2013-08-16 10:55:51,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13851242 bytes from map-output for attempt_1376648880181_0010_m_000038_0
2013-08-16 10:55:51,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13851242, inMemoryMapOutputs.size() -> 5, commitMemory -> 55587696, usedMemory ->69438938
2013-08-16 10:55:51,021 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-16 10:55:51,022 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#4 in 43910s
2013-08-16 10:55:51,028 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-16 10:55:51,302 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-16 10:55:51,302 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69438873 bytes
2013-08-16 10:55:52,194 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69438938 bytes to disk to satisfy reduce memory limit
2013-08-16 10:55:52,196 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 555273716 bytes from disk
2013-08-16 10:55:52,197 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-16 10:55:52,197 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-16 10:55:52,200 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 555273614 bytes
2013-08-16 10:55:52,297 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-16 10:56:11,133 WARN [main] org.apache.hadoop.hdfs.DFSClient: Unable to persist blocks in hflush for /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376648880181_0010_r_000009_1/part-r-00009
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376648880181_0010_r_000009_1/part-r-00009: File does not exist. Holder DFSClient_attempt_1376648880181_0010_r_000009_1_44896841_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.fsync(FSNamesystem.java:3110)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.fsync(NameNodeRpcServer.java:830)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.fsync(ClientNamenodeProtocolServerSideTranslatorPB.java:718)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:41033)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.fsync(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.fsync(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.fsync(ClientNamenodeProtocolTranslatorPB.java:694)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1644)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1545)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1528)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:124)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.close(TeraOutputFormat.java:75)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:572)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-16 10:56:11,134 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376648880181_0010_r_000009_1/part-r-00009
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376648880181_0010_r_000009_1/part-r-00009: File does not exist. Holder DFSClient_attempt_1376648880181_0010_r_000009_1_44896841_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-16 10:56:11,134 WARN [main] org.apache.hadoop.hdfs.DFSClient: Error while syncing
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1650)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1545)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1528)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:124)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.close(TeraOutputFormat.java:75)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:572)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-16 10:56:11,136 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-16 10:56:11,136 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1650)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1545)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1528)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:124)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.close(TeraOutputFormat.java:75)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:572)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

