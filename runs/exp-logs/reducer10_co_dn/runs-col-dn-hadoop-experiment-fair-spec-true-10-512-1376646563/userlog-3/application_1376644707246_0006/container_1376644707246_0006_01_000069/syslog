2013-08-16 09:40:01,504 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-16 09:40:01,554 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-16 09:40:01,826 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-16 09:40:02,007 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-16 09:40:02,008 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-16 09:40:02,033 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-16 09:40:02,033 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1376644707246_0006, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@4a1fc79a)
2013-08-16 09:40:02,171 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-16 09:40:02,955 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006
2013-08-16 09:40:03,331 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-16 09:40:03,407 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-16 09:40:03,409 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-16 09:40:03,409 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-16 09:40:03,423 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-16 09:40:03,427 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-16 09:40:03,431 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-16 09:40:03,432 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-16 09:40:03,432 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-16 09:40:03,808 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-16 09:40:04,406 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-16 09:40:04,527 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3850c651
2013-08-16 09:40:04,573 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-16 09:40:04,582 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376644707246_0006_r_000006_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-16 09:40:04,606 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 1 to fetcher#4
2013-08-16 09:40:04,607 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-2:8080 to fetcher#4
2013-08-16 09:40:04,608 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 1 to fetcher#5
2013-08-16 09:40:04,611 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-3:8080 to fetcher#5
2013-08-16 09:40:04,611 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 2 to fetcher#3
2013-08-16 09:40:04,611 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-5:8080 to fetcher#3
2013-08-16 09:40:04,612 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#1
2013-08-16 09:40:04,612 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-6:8080 to fetcher#1
2013-08-16 09:40:04,613 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 1 to fetcher#2
2013-08-16 09:40:04,613 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-7:8080 to fetcher#2
2013-08-16 09:40:04,636 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376644707246_0006_r_000006_1: Got 40 new map-outputs
2013-08-16 09:40:04,836 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000000_0,attempt_1376644707246_0006_m_000002_0 sent hash and received reply
2013-08-16 09:40:04,836 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000005_0 sent hash and received reply
2013-08-16 09:40:04,838 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000004_0 sent hash and received reply
2013-08-16 09:40:04,887 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000005_0 decomp: 13918842 len: 13918846 to MEMORY
2013-08-16 09:40:04,895 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000004_0 decomp: 13862058 len: 13862062 to MEMORY
2013-08-16 09:40:04,895 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000000_0 decomp: 13890138 len: 13890142 to MEMORY
2013-08-16 09:40:05,066 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13862058 bytes from map-output for attempt_1376644707246_0006_m_000004_0
2013-08-16 09:40:05,070 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13862058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41671038
2013-08-16 09:40:05,072 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#4 in 466s
2013-08-16 09:40:05,072 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 6 to fetcher#4
2013-08-16 09:40:05,072 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-4:8080 to fetcher#4
2013-08-16 09:40:05,089 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000010_0,attempt_1376644707246_0006_m_000014_0,attempt_1376644707246_0006_m_000025_0,attempt_1376644707246_0006_m_000028_0,attempt_1376644707246_0006_m_000034_0,attempt_1376644707246_0006_m_000039_0 sent hash and received reply
2013-08-16 09:40:05,094 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000010_0 decomp: 13922274 len: 13922278 to MEMORY
2013-08-16 09:40:05,129 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13890138 bytes from map-output for attempt_1376644707246_0006_m_000000_0
2013-08-16 09:40:05,130 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13890138, inMemoryMapOutputs.size() -> 2, commitMemory -> 13862058, usedMemory ->55593312
2013-08-16 09:40:05,145 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000002_0 decomp: 13912082 len: 13912086 to MEMORY
2013-08-16 09:40:05,342 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922274 bytes from map-output for attempt_1376644707246_0006_m_000010_0
2013-08-16 09:40:05,342 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922274, inMemoryMapOutputs.size() -> 3, commitMemory -> 27752196, usedMemory ->69505394
2013-08-16 09:40:05,527 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000014_0 decomp: 13940578 len: 13940582 to MEMORY
2013-08-16 09:40:05,586 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13912082 bytes from map-output for attempt_1376644707246_0006_m_000002_0
2013-08-16 09:40:05,586 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13912082, inMemoryMapOutputs.size() -> 4, commitMemory -> 41674470, usedMemory ->83445972
2013-08-16 09:40:05,587 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#3 in 976s
2013-08-16 09:40:05,587 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 8 to fetcher#3
2013-08-16 09:40:05,587 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-512-5:8080 to fetcher#3
2013-08-16 09:40:05,603 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000012_0,attempt_1376644707246_0006_m_000003_0,attempt_1376644707246_0006_m_000017_0,attempt_1376644707246_0006_m_000020_0,attempt_1376644707246_0006_m_000023_0,attempt_1376644707246_0006_m_000029_0,attempt_1376644707246_0006_m_000033_0,attempt_1376644707246_0006_m_000036_0 sent hash and received reply
2013-08-16 09:40:05,610 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000012_0 decomp: 13942242 len: 13942246 to MEMORY
2013-08-16 09:40:05,689 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13940578 bytes from map-output for attempt_1376644707246_0006_m_000014_0
2013-08-16 09:40:05,689 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13940578, inMemoryMapOutputs.size() -> 5, commitMemory -> 55586552, usedMemory ->97388214
2013-08-16 09:40:05,694 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000025_0 decomp: 13922274 len: 13922278 to MEMORY
2013-08-16 09:40:05,970 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13942242 bytes from map-output for attempt_1376644707246_0006_m_000012_0
2013-08-16 09:40:05,970 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13942242, inMemoryMapOutputs.size() -> 6, commitMemory -> 69527130, usedMemory ->111310488
2013-08-16 09:40:05,978 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000003_0 decomp: 13850306 len: 13850310 to MEMORY
2013-08-16 09:40:06,136 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922274 bytes from map-output for attempt_1376644707246_0006_m_000025_0
2013-08-16 09:40:06,136 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922274, inMemoryMapOutputs.size() -> 7, commitMemory -> 83469372, usedMemory ->125160794
2013-08-16 09:40:06,138 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97391646 > mergeThreshold=86139864. Current usedMemory=125160794
2013-08-16 09:40:06,139 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 09:40:06,142 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13850306 bytes from map-output for attempt_1376644707246_0006_m_000003_0
2013-08-16 09:40:06,328 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13850306, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139038556
2013-08-16 09:40:06,328 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000028_0 decomp: 13877762 len: 13877766 to MEMORY
2013-08-16 09:40:06,329 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 09:40:06,329 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#3 in 742s
2013-08-16 09:40:06,425 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13877762 bytes from map-output for attempt_1376644707246_0006_m_000028_0
2013-08-16 09:40:06,425 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13877762, inMemoryMapOutputs.size() -> 2, commitMemory -> 13850306, usedMemory ->139038556
2013-08-16 09:40:06,426 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-16 09:40:06,426 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#4 in 1354s
2013-08-16 09:40:06,740 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 09:40:06,748 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 09:40:06,748 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97391555 bytes
2013-08-16 09:40:07,638 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000001_0 sent hash and received reply
2013-08-16 09:40:07,640 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 09:40:07,640 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#2 in 3027s
2013-08-16 09:40:08,276 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376644707246_0006_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006/output/attempt_1376644707246_0006_r_000006_1/map_4.out.merged of size 97391638
2013-08-16 09:40:08,277 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 5 to fetcher#2
2013-08-16 09:40:08,277 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-7:8080 to fetcher#2
2013-08-16 09:40:08,277 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 5 to fetcher#3
2013-08-16 09:40:08,277 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-2:8080 to fetcher#3
2013-08-16 09:40:08,277 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 2 to fetcher#4
2013-08-16 09:40:08,278 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-4:8080 to fetcher#4
2013-08-16 09:40:08,281 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000008_0,attempt_1376644707246_0006_m_000019_0,attempt_1376644707246_0006_m_000021_0,attempt_1376644707246_0006_m_000026_0,attempt_1376644707246_0006_m_000032_0 sent hash and received reply
2013-08-16 09:40:08,283 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000039_0,attempt_1376644707246_0006_m_000034_0 sent hash and received reply
2013-08-16 09:40:08,286 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000008_0 decomp: 13910626 len: 13910630 to MEMORY
2013-08-16 09:40:08,751 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000039_0 decomp: 13982282 len: 13982286 to MEMORY
2013-08-16 09:40:08,868 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13910626 bytes from map-output for attempt_1376644707246_0006_m_000008_0
2013-08-16 09:40:08,869 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13910626, inMemoryMapOutputs.size() -> 3, commitMemory -> 27728068, usedMemory ->69539818
2013-08-16 09:40:08,873 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000019_0 decomp: 13936106 len: 13936110 to MEMORY
2013-08-16 09:40:08,931 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13936106 bytes from map-output for attempt_1376644707246_0006_m_000019_0
2013-08-16 09:40:08,931 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13936106, inMemoryMapOutputs.size() -> 4, commitMemory -> 41638694, usedMemory ->83475924
2013-08-16 09:40:08,935 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000021_0 decomp: 13939018 len: 13939022 to MEMORY
2013-08-16 09:40:08,978 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000009_0,attempt_1376644707246_0006_m_000015_0,attempt_1376644707246_0006_m_000016_0,attempt_1376644707246_0006_m_000037_0,attempt_1376644707246_0006_m_000001_0 sent hash and received reply
2013-08-16 09:40:08,985 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376644707246_0006_m_000009_0 decomp: 13925290 len: 13925294 to MEMORY
2013-08-16 09:40:08,999 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13939018 bytes from map-output for attempt_1376644707246_0006_m_000021_0
2013-08-16 09:40:08,999 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13939018, inMemoryMapOutputs.size() -> 5, commitMemory -> 55574800, usedMemory ->111340232
2013-08-16 09:40:09,104 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000026_0 decomp: 13869338 len: 13869342 to MEMORY
2013-08-16 09:40:09,161 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13869338 bytes from map-output for attempt_1376644707246_0006_m_000026_0
2013-08-16 09:40:09,161 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13869338, inMemoryMapOutputs.size() -> 6, commitMemory -> 69513818, usedMemory ->125209570
2013-08-16 09:40:09,166 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376644707246_0006_m_000032_0 decomp: 13908442 len: 13908446 to MEMORY
2013-08-16 09:40:09,405 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925290 bytes from map-output for attempt_1376644707246_0006_m_000009_0
2013-08-16 09:40:09,405 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925290, inMemoryMapOutputs.size() -> 7, commitMemory -> 83383156, usedMemory ->139118012
2013-08-16 09:40:09,405 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97308446 > mergeThreshold=86139864. Current usedMemory=139118012
2013-08-16 09:40:09,405 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 09:40:09,408 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 09:40:09,408 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#2 in 1131s
2013-08-16 09:40:09,579 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13918842 bytes from map-output for attempt_1376644707246_0006_m_000005_0
2013-08-16 09:40:09,583 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13918842, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139118012
2013-08-16 09:40:09,584 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#5 in 4973s
2013-08-16 09:40:09,644 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 09:40:09,645 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 09:40:09,645 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97308355 bytes
2013-08-16 09:40:10,433 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13982282 bytes from map-output for attempt_1376644707246_0006_m_000039_0
2013-08-16 09:40:10,434 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13982282, inMemoryMapOutputs.size() -> 2, commitMemory -> 13918842, usedMemory ->139118012
2013-08-16 09:40:10,434 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-16 09:40:10,435 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#4 in 2157s
2013-08-16 09:40:11,827 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376644707246_0006_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006/output/attempt_1376644707246_0006_r_000006_1/map_3.out.merged of size 97308438
2013-08-16 09:40:11,827 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 5 to fetcher#4
2013-08-16 09:40:11,828 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-3:8080 to fetcher#4
2013-08-16 09:40:11,830 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 6 to fetcher#5
2013-08-16 09:40:11,830 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-5:8080 to fetcher#5
2013-08-16 09:40:11,830 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 4 to fetcher#2
2013-08-16 09:40:11,831 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-7:8080 to fetcher#2
2013-08-16 09:40:11,833 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000006_0,attempt_1376644707246_0006_m_000011_0,attempt_1376644707246_0006_m_000024_0,attempt_1376644707246_0006_m_000030_0,attempt_1376644707246_0006_m_000035_0 sent hash and received reply
2013-08-16 09:40:11,877 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000033_0,attempt_1376644707246_0006_m_000029_0,attempt_1376644707246_0006_m_000023_0,attempt_1376644707246_0006_m_000020_0,attempt_1376644707246_0006_m_000017_0,attempt_1376644707246_0006_m_000036_0 sent hash and received reply
2013-08-16 09:40:11,879 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000006_0 decomp: 13979994 len: 13979998 to MEMORY
2013-08-16 09:40:11,882 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000033_0 decomp: 13913330 len: 13913334 to MEMORY
2013-08-16 09:40:12,029 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13913330 bytes from map-output for attempt_1376644707246_0006_m_000033_0
2013-08-16 09:40:12,029 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13913330, inMemoryMapOutputs.size() -> 3, commitMemory -> 27901124, usedMemory ->69702890
2013-08-16 09:40:12,032 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000029_0 decomp: 13849162 len: 13849166 to MEMORY
2013-08-16 09:40:12,164 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13849162 bytes from map-output for attempt_1376644707246_0006_m_000029_0
2013-08-16 09:40:12,164 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13849162, inMemoryMapOutputs.size() -> 4, commitMemory -> 41814454, usedMemory ->83552052
2013-08-16 09:40:12,167 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000023_0 decomp: 13934026 len: 13934030 to MEMORY
2013-08-16 09:40:12,308 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13934026 bytes from map-output for attempt_1376644707246_0006_m_000023_0
2013-08-16 09:40:12,309 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13934026, inMemoryMapOutputs.size() -> 5, commitMemory -> 55663616, usedMemory ->97486078
2013-08-16 09:40:12,395 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000020_0 decomp: 13937042 len: 13937046 to MEMORY
2013-08-16 09:40:12,485 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13937042 bytes from map-output for attempt_1376644707246_0006_m_000020_0
2013-08-16 09:40:12,485 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13937042, inMemoryMapOutputs.size() -> 6, commitMemory -> 69597642, usedMemory ->111423120
2013-08-16 09:40:12,490 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000017_0 decomp: 13911874 len: 13911878 to MEMORY
2013-08-16 09:40:12,708 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13911874 bytes from map-output for attempt_1376644707246_0006_m_000017_0
2013-08-16 09:40:12,708 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13911874, inMemoryMapOutputs.size() -> 7, commitMemory -> 83534684, usedMemory ->125334994
2013-08-16 09:40:12,708 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97446558 > mergeThreshold=86139864. Current usedMemory=125334994
2013-08-16 09:40:12,708 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 09:40:12,713 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000036_0 decomp: 13979266 len: 13979270 to MEMORY
2013-08-16 09:40:12,837 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13979266 bytes from map-output for attempt_1376644707246_0006_m_000036_0
2013-08-16 09:40:12,838 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13979266, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139314260
2013-08-16 09:40:12,838 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#5 in 1008s
2013-08-16 09:40:13,055 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 09:40:13,056 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 09:40:13,056 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97446467 bytes
2013-08-16 09:40:14,143 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13908442 bytes from map-output for attempt_1376644707246_0006_m_000032_0
2013-08-16 09:40:14,144 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13908442, inMemoryMapOutputs.size() -> 2, commitMemory -> 13979266, usedMemory ->139314260
2013-08-16 09:40:14,144 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#3 in 5867s
2013-08-16 09:40:14,879 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376644707246_0006_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006/output/attempt_1376644707246_0006_r_000006_1/map_29.out.merged of size 97446550
2013-08-16 09:40:14,880 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 1 to fetcher#5
2013-08-16 09:40:14,880 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-4:8080 to fetcher#5
2013-08-16 09:40:14,884 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000034_0 sent hash and received reply
2013-08-16 09:40:14,891 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376644707246_0006_m_000034_0 decomp: 13933090 len: 13933094 to MEMORY
2013-08-16 09:40:15,094 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13933090 bytes from map-output for attempt_1376644707246_0006_m_000034_0
2013-08-16 09:40:15,094 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13933090, inMemoryMapOutputs.size() -> 3, commitMemory -> 27887708, usedMemory ->55800792
2013-08-16 09:40:15,094 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#5 in 214s
2013-08-16 09:40:15,621 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000037_0,attempt_1376644707246_0006_m_000016_0,attempt_1376644707246_0006_m_000001_0,attempt_1376644707246_0006_m_000015_0 sent hash and received reply
2013-08-16 09:40:15,804 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376644707246_0006_m_000037_0 decomp: 13951082 len: 13951086 to MEMORY
2013-08-16 09:40:15,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13979994 bytes from map-output for attempt_1376644707246_0006_m_000006_0
2013-08-16 09:40:15,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13979994, inMemoryMapOutputs.size() -> 4, commitMemory -> 41820798, usedMemory ->69751874
2013-08-16 09:40:15,996 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000011_0 decomp: 13922274 len: 13922278 to MEMORY
2013-08-16 09:40:19,800 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000007_0 sent hash and received reply
2013-08-16 09:40:19,806 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000007_0 decomp: 13907298 len: 13907302 to MEMORY
2013-08-16 09:40:20,847 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922274 bytes from map-output for attempt_1376644707246_0006_m_000011_0
2013-08-16 09:40:20,848 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922274, inMemoryMapOutputs.size() -> 5, commitMemory -> 55800792, usedMemory ->97581446
2013-08-16 09:40:21,032 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000024_0 decomp: 13937770 len: 13937774 to MEMORY
2013-08-16 09:40:21,079 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13937770 bytes from map-output for attempt_1376644707246_0006_m_000024_0
2013-08-16 09:40:21,079 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13937770, inMemoryMapOutputs.size() -> 6, commitMemory -> 69723066, usedMemory ->111519216
2013-08-16 09:40:21,084 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000030_0 decomp: 13877138 len: 13877142 to MEMORY
2013-08-16 09:40:22,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13877138 bytes from map-output for attempt_1376644707246_0006_m_000030_0
2013-08-16 09:40:22,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13877138, inMemoryMapOutputs.size() -> 7, commitMemory -> 83660836, usedMemory ->125396354
2013-08-16 09:40:22,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97537974 > mergeThreshold=86139864. Current usedMemory=125396354
2013-08-16 09:40:22,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 09:40:23,002 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376644707246_0006_m_000035_0 decomp: 13970634 len: 13970638 to MEMORY
2013-08-16 09:40:23,489 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 09:40:23,489 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 09:40:23,489 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97537883 bytes
2013-08-16 09:40:24,169 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970634 bytes from map-output for attempt_1376644707246_0006_m_000035_0
2013-08-16 09:40:24,170 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970634, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139366988
2013-08-16 09:40:24,170 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#4 in 12342s
2013-08-16 09:40:25,132 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376644707246_0006_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006/output/attempt_1376644707246_0006_r_000006_1/map_30.out.merged of size 97537966
2013-08-16 09:40:56,220 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13907298 bytes from map-output for attempt_1376644707246_0006_m_000007_0
2013-08-16 09:40:56,220 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13907298, inMemoryMapOutputs.size() -> 2, commitMemory -> 13970634, usedMemory ->41829014
2013-08-16 09:40:56,221 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#1 in 51609s
2013-08-16 09:40:56,222 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 6 to fetcher#1
2013-08-16 09:40:56,222 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-6:8080 to fetcher#1
2013-08-16 09:40:56,425 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376644707246_0006&reduce=6&map=attempt_1376644707246_0006_m_000018_0,attempt_1376644707246_0006_m_000013_0,attempt_1376644707246_0006_m_000022_0,attempt_1376644707246_0006_m_000027_0,attempt_1376644707246_0006_m_000031_0,attempt_1376644707246_0006_m_000038_0 sent hash and received reply
2013-08-16 09:40:56,429 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000018_0 decomp: 13950562 len: 13950566 to MEMORY
2013-08-16 09:41:43,381 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13950562 bytes from map-output for attempt_1376644707246_0006_m_000018_0
2013-08-16 09:41:43,382 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13950562, inMemoryMapOutputs.size() -> 3, commitMemory -> 27877932, usedMemory ->55779576
2013-08-16 09:41:43,474 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000013_0 decomp: 13874850 len: 13874854 to MEMORY
2013-08-16 09:41:45,026 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13951082 bytes from map-output for attempt_1376644707246_0006_m_000037_0
2013-08-16 09:41:45,026 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13951082, inMemoryMapOutputs.size() -> 4, commitMemory -> 41828494, usedMemory ->69654426
2013-08-16 09:41:45,030 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376644707246_0006_m_000016_0 decomp: 13970218 len: 13970222 to MEMORY
2013-08-16 09:41:47,545 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970218 bytes from map-output for attempt_1376644707246_0006_m_000016_0
2013-08-16 09:41:47,545 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970218, inMemoryMapOutputs.size() -> 5, commitMemory -> 55779576, usedMemory ->83624644
2013-08-16 09:41:47,550 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376644707246_0006_m_000001_0 decomp: 13884626 len: 13884630 to MEMORY
2013-08-16 09:41:50,078 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13884626 bytes from map-output for attempt_1376644707246_0006_m_000001_0
2013-08-16 09:41:50,079 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13884626, inMemoryMapOutputs.size() -> 6, commitMemory -> 69749794, usedMemory ->97509270
2013-08-16 09:41:50,190 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376644707246_0006_m_000015_0 decomp: 13891698 len: 13891702 to MEMORY
2013-08-16 09:41:52,490 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13891698 bytes from map-output for attempt_1376644707246_0006_m_000015_0
2013-08-16 09:41:52,490 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13891698, inMemoryMapOutputs.size() -> 7, commitMemory -> 83634420, usedMemory ->111400968
2013-08-16 09:41:52,490 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97526118 > mergeThreshold=86139864. Current usedMemory=111400968
2013-08-16 09:41:52,491 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 09:41:52,491 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#2 in 100661s
2013-08-16 09:41:52,681 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 09:41:52,682 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 09:41:52,682 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97526027 bytes
2013-08-16 09:41:54,055 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376644707246_0006_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376644707246_0006/output/attempt_1376644707246_0006_r_000006_1/map_1.out.merged of size 97526110
2013-08-16 09:42:25,835 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13874850 bytes from map-output for attempt_1376644707246_0006_m_000013_0
2013-08-16 09:42:25,835 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13874850, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13874850
2013-08-16 09:42:25,840 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000022_0 decomp: 13956594 len: 13956598 to MEMORY
2013-08-16 09:42:41,747 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13956594 bytes from map-output for attempt_1376644707246_0006_m_000022_0
2013-08-16 09:42:41,748 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13956594, inMemoryMapOutputs.size() -> 2, commitMemory -> 13874850, usedMemory ->27831444
2013-08-16 09:42:41,752 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000027_0 decomp: 13895234 len: 13895238 to MEMORY
2013-08-16 09:42:54,878 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13895234 bytes from map-output for attempt_1376644707246_0006_m_000027_0
2013-08-16 09:42:54,879 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13895234, inMemoryMapOutputs.size() -> 3, commitMemory -> 27831444, usedMemory ->41726678
2013-08-16 09:42:54,884 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000031_0 decomp: 13942866 len: 13942870 to MEMORY
2013-08-16 09:43:11,151 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13942866 bytes from map-output for attempt_1376644707246_0006_m_000031_0
2013-08-16 09:43:11,151 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13942866, inMemoryMapOutputs.size() -> 4, commitMemory -> 41726678, usedMemory ->55669544
2013-08-16 09:43:11,155 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376644707246_0006_m_000038_0 decomp: 13966890 len: 13966894 to MEMORY
2013-08-16 09:43:21,193 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13966890 bytes from map-output for attempt_1376644707246_0006_m_000038_0
2013-08-16 09:43:21,194 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13966890, inMemoryMapOutputs.size() -> 5, commitMemory -> 55669544, usedMemory ->69636434
2013-08-16 09:43:21,194 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#1 in 144972s
2013-08-16 09:43:21,194 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-16 09:43:21,201 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-16 09:43:21,358 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-16 09:43:21,359 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69636369 bytes
2013-08-16 09:43:22,040 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69636434 bytes to disk to satisfy reduce memory limit
2013-08-16 09:43:22,042 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 556847132 bytes from disk
2013-08-16 09:43:22,043 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-16 09:43:22,043 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-16 09:43:22,054 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 556847030 bytes
2013-08-16 09:43:22,218 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-16 09:43:27,445 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-5/_temporary/1/_temporary/attempt_1376644707246_0006_r_000006_1/part-r-00006
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-5/_temporary/1/_temporary/attempt_1376644707246_0006_r_000006_1/part-r-00006: File does not exist. Holder DFSClient_attempt_1376644707246_0006_r_000006_1_891719032_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-16 09:43:27,447 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-16 09:43:27,449 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

