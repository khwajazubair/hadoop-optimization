2013-08-16 11:26:33,379 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-16 11:26:33,429 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-16 11:26:33,632 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-16 11:26:33,779 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-16 11:26:33,779 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-16 11:26:33,802 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-16 11:26:33,802 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1376651007637_0010, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-16 11:26:33,933 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-16 11:26:34,653 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010
2013-08-16 11:26:34,988 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-16 11:26:34,988 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-16 11:26:34,989 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-16 11:26:34,990 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-16 11:26:34,992 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-16 11:26:34,992 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-16 11:26:34,993 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-16 11:26:34,994 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-16 11:26:34,994 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-16 11:26:35,268 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-16 11:26:35,960 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-16 11:26:36,129 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13eeba25
2013-08-16 11:26:36,180 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-16 11:26:36,186 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376651007637_0010_r_000008_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-16 11:26:36,217 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 1 to fetcher#5
2013-08-16 11:26:36,218 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-4:8080 to fetcher#5
2013-08-16 11:26:36,218 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 1 to fetcher#1
2013-08-16 11:26:36,219 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-7:8080 to fetcher#1
2013-08-16 11:26:36,220 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 1 to fetcher#4
2013-08-16 11:26:36,220 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-5:8080 to fetcher#4
2013-08-16 11:26:36,228 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 1 to fetcher#2
2013-08-16 11:26:36,228 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-2:8080 to fetcher#2
2013-08-16 11:26:36,237 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#3
2013-08-16 11:26:36,237 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-6:8080 to fetcher#3
2013-08-16 11:26:36,243 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376651007637_0010_r_000008_1: Got 40 new map-outputs
2013-08-16 11:26:36,453 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000007_0 sent hash and received reply
2013-08-16 11:26:36,454 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000002_0 sent hash and received reply
2013-08-16 11:26:36,456 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000000_0 sent hash and received reply
2013-08-16 11:26:36,467 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000011_0 sent hash and received reply
2013-08-16 11:26:36,467 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000007_0 decomp: 13922794 len: 13922798 to MEMORY
2013-08-16 11:26:36,515 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000011_0 decomp: 13926642 len: 13926646 to MEMORY
2013-08-16 11:26:36,523 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000000_0 decomp: 13944010 len: 13944014 to MEMORY
2013-08-16 11:26:36,527 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000002_0 decomp: 13864450 len: 13864454 to MEMORY
2013-08-16 11:26:36,736 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922794 bytes from map-output for attempt_1376651007637_0010_m_000007_0
2013-08-16 11:26:36,739 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922794, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55657896
2013-08-16 11:26:36,741 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#2 in 513s
2013-08-16 11:26:36,741 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 3 to fetcher#2
2013-08-16 11:26:36,741 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-3:8080 to fetcher#2
2013-08-16 11:26:36,747 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000028_0,attempt_1376651007637_0010_m_000035_0,attempt_1376651007637_0010_m_000036_0 sent hash and received reply
2013-08-16 11:26:36,762 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000028_0 decomp: 13887642 len: 13887646 to MEMORY
2013-08-16 11:26:37,316 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13887642 bytes from map-output for attempt_1376651007637_0010_m_000028_0
2013-08-16 11:26:37,316 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13887642, inMemoryMapOutputs.size() -> 2, commitMemory -> 13922794, usedMemory ->69545538
2013-08-16 11:26:37,563 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000035_0 decomp: 13892634 len: 13892638 to MEMORY
2013-08-16 11:26:38,603 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13926642 bytes from map-output for attempt_1376651007637_0010_m_000011_0
2013-08-16 11:26:38,604 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13926642, inMemoryMapOutputs.size() -> 3, commitMemory -> 27810436, usedMemory ->83438172
2013-08-16 11:26:38,605 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#3 in 2368s
2013-08-16 11:26:38,605 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 6 to fetcher#3
2013-08-16 11:26:38,605 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-2:8080 to fetcher#3
2013-08-16 11:26:38,611 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000016_0,attempt_1376651007637_0010_m_000021_0,attempt_1376651007637_0010_m_000027_0,attempt_1376651007637_0010_m_000030_0,attempt_1376651007637_0010_m_000031_0,attempt_1376651007637_0010_m_000033_0 sent hash and received reply
2013-08-16 11:26:38,617 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000016_0 decomp: 13898770 len: 13898774 to MEMORY
2013-08-16 11:26:38,967 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13898770 bytes from map-output for attempt_1376651007637_0010_m_000016_0
2013-08-16 11:26:38,967 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13898770, inMemoryMapOutputs.size() -> 4, commitMemory -> 41737078, usedMemory ->97336942
2013-08-16 11:26:38,972 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000021_0 decomp: 13878386 len: 13878390 to MEMORY
2013-08-16 11:26:39,023 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13878386 bytes from map-output for attempt_1376651007637_0010_m_000021_0
2013-08-16 11:26:39,024 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13878386, inMemoryMapOutputs.size() -> 5, commitMemory -> 55635848, usedMemory ->111215328
2013-08-16 11:26:39,028 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000027_0 decomp: 13907090 len: 13907094 to MEMORY
2013-08-16 11:26:39,261 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13892634 bytes from map-output for attempt_1376651007637_0010_m_000035_0
2013-08-16 11:26:39,261 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13892634, inMemoryMapOutputs.size() -> 6, commitMemory -> 69514234, usedMemory ->125122418
2013-08-16 11:26:39,381 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000036_0 decomp: 13877762 len: 13877766 to MEMORY
2013-08-16 11:26:39,628 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13907090 bytes from map-output for attempt_1376651007637_0010_m_000027_0
2013-08-16 11:26:39,628 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13907090, inMemoryMapOutputs.size() -> 7, commitMemory -> 83406868, usedMemory ->139000180
2013-08-16 11:26:39,628 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97313958 > mergeThreshold=86139864. Current usedMemory=139000180
2013-08-16 11:26:39,629 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:26:39,630 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 11:26:39,630 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#3 in 1025s
2013-08-16 11:26:39,947 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13877762 bytes from map-output for attempt_1376651007637_0010_m_000036_0
2013-08-16 11:26:39,947 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13877762, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139000180
2013-08-16 11:26:39,948 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#2 in 3207s
2013-08-16 11:26:40,013 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:26:40,023 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:26:40,024 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97313867 bytes
2013-08-16 11:26:41,612 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0010_r_000008_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010/output/attempt_1376651007637_0010_r_000008_1/map_21.out.merged of size 97313950
2013-08-16 11:26:41,613 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 3 to fetcher#2
2013-08-16 11:26:41,613 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-2:8080 to fetcher#2
2013-08-16 11:26:41,616 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000033_0,attempt_1376651007637_0010_m_000030_0,attempt_1376651007637_0010_m_000031_0 sent hash and received reply
2013-08-16 11:26:41,620 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000033_0 decomp: 13921754 len: 13921758 to MEMORY
2013-08-16 11:26:41,942 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13921754 bytes from map-output for attempt_1376651007637_0010_m_000033_0
2013-08-16 11:26:41,942 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13921754, inMemoryMapOutputs.size() -> 2, commitMemory -> 13877762, usedMemory ->55607976
2013-08-16 11:26:42,023 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000030_0 decomp: 13866010 len: 13866014 to MEMORY
2013-08-16 11:26:42,080 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13866010 bytes from map-output for attempt_1376651007637_0010_m_000030_0
2013-08-16 11:26:42,080 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13866010, inMemoryMapOutputs.size() -> 3, commitMemory -> 27799516, usedMemory ->69473986
2013-08-16 11:26:42,085 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0010_m_000031_0 decomp: 13896378 len: 13896382 to MEMORY
2013-08-16 11:26:42,136 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896378 bytes from map-output for attempt_1376651007637_0010_m_000031_0
2013-08-16 11:26:42,136 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896378, inMemoryMapOutputs.size() -> 4, commitMemory -> 41665526, usedMemory ->83370364
2013-08-16 11:26:42,136 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#2 in 523s
2013-08-16 11:26:42,983 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944010 bytes from map-output for attempt_1376651007637_0010_m_000000_0
2013-08-16 11:26:42,983 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944010, inMemoryMapOutputs.size() -> 5, commitMemory -> 55561904, usedMemory ->83370364
2013-08-16 11:26:42,983 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#1 in 6764s
2013-08-16 11:26:42,983 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 9 to fetcher#1
2013-08-16 11:26:42,984 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-512-7:8080 to fetcher#1
2013-08-16 11:26:51,980 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13864450 bytes from map-output for attempt_1376651007637_0010_m_000002_0
2013-08-16 11:26:51,980 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13864450, inMemoryMapOutputs.size() -> 6, commitMemory -> 69505914, usedMemory ->83370364
2013-08-16 11:26:51,981 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#5 in 15764s
2013-08-16 11:26:51,981 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 11 to fetcher#5
2013-08-16 11:26:51,981 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 11 of 11 to hadoop-512-4:8080 to fetcher#5
2013-08-16 11:26:53,300 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000005_0,attempt_1376651007637_0010_m_000004_0,attempt_1376651007637_0010_m_000006_0,attempt_1376651007637_0010_m_000010_0,attempt_1376651007637_0010_m_000019_0,attempt_1376651007637_0010_m_000022_0,attempt_1376651007637_0010_m_000026_0,attempt_1376651007637_0010_m_000029_0,attempt_1376651007637_0010_m_000032_0,attempt_1376651007637_0010_m_000034_0,attempt_1376651007637_0010_m_000039_0 sent hash and received reply
2013-08-16 11:26:53,305 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000005_0 decomp: 13898354 len: 13898358 to MEMORY
2013-08-16 11:26:58,486 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000003_0,attempt_1376651007637_0010_m_000013_0,attempt_1376651007637_0010_m_000008_0,attempt_1376651007637_0010_m_000014_0,attempt_1376651007637_0010_m_000017_0,attempt_1376651007637_0010_m_000018_0,attempt_1376651007637_0010_m_000025_0,attempt_1376651007637_0010_m_000023_0,attempt_1376651007637_0010_m_000037_0 sent hash and received reply
2013-08-16 11:26:58,588 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000003_0 decomp: 13918426 len: 13918430 to MEMORY
2013-08-16 11:27:03,000 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13898354 bytes from map-output for attempt_1376651007637_0010_m_000005_0
2013-08-16 11:27:03,001 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13898354, inMemoryMapOutputs.size() -> 7, commitMemory -> 83370364, usedMemory ->111187144
2013-08-16 11:27:03,001 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97268718 > mergeThreshold=86139864. Current usedMemory=111187144
2013-08-16 11:27:03,001 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:27:03,009 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000004_0 decomp: 13863826 len: 13863830 to MEMORY
2013-08-16 11:27:03,226 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:27:03,227 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:27:03,227 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97268627 bytes
2013-08-16 11:27:05,096 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0010_r_000008_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010/output/attempt_1376651007637_0010_r_000008_1/map_2.out.merged of size 97268710
2013-08-16 11:27:10,401 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000001_0 sent hash and received reply
2013-08-16 11:27:10,407 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0010_m_000001_0 decomp: 13886394 len: 13886398 to MEMORY
2013-08-16 11:27:13,375 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13863826 bytes from map-output for attempt_1376651007637_0010_m_000004_0
2013-08-16 11:27:13,375 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13863826, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41668646
2013-08-16 11:27:13,380 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000006_0 decomp: 13833458 len: 13833462 to MEMORY
2013-08-16 11:27:23,059 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13918426 bytes from map-output for attempt_1376651007637_0010_m_000003_0
2013-08-16 11:27:23,060 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13918426, inMemoryMapOutputs.size() -> 2, commitMemory -> 13863826, usedMemory ->55502104
2013-08-16 11:27:23,083 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000013_0 decomp: 13971986 len: 13971990 to MEMORY
2013-08-16 11:27:23,649 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13833458 bytes from map-output for attempt_1376651007637_0010_m_000006_0
2013-08-16 11:27:23,649 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13833458, inMemoryMapOutputs.size() -> 3, commitMemory -> 27782252, usedMemory ->69474090
2013-08-16 11:27:23,654 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000010_0 decomp: 13893050 len: 13893054 to MEMORY
2013-08-16 11:27:29,754 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13971986 bytes from map-output for attempt_1376651007637_0010_m_000013_0
2013-08-16 11:27:29,754 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13971986, inMemoryMapOutputs.size() -> 4, commitMemory -> 41615710, usedMemory ->83367140
2013-08-16 11:27:29,759 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000008_0 decomp: 13921858 len: 13921862 to MEMORY
2013-08-16 11:27:34,246 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13893050 bytes from map-output for attempt_1376651007637_0010_m_000010_0
2013-08-16 11:27:34,247 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13893050, inMemoryMapOutputs.size() -> 5, commitMemory -> 55587696, usedMemory ->97288998
2013-08-16 11:27:34,395 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000019_0 decomp: 13933402 len: 13933406 to MEMORY
2013-08-16 11:27:39,161 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13921858 bytes from map-output for attempt_1376651007637_0010_m_000008_0
2013-08-16 11:27:39,161 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13921858, inMemoryMapOutputs.size() -> 6, commitMemory -> 69480746, usedMemory ->111222400
2013-08-16 11:27:39,166 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000014_0 decomp: 13899186 len: 13899190 to MEMORY
2013-08-16 11:27:42,967 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13933402 bytes from map-output for attempt_1376651007637_0010_m_000019_0
2013-08-16 11:27:42,967 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13933402, inMemoryMapOutputs.size() -> 7, commitMemory -> 83402604, usedMemory ->125121586
2013-08-16 11:27:42,967 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97336006 > mergeThreshold=86139864. Current usedMemory=125121586
2013-08-16 11:27:42,967 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:27:42,974 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000022_0 decomp: 13949834 len: 13949838 to MEMORY
2013-08-16 11:27:43,279 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:27:43,280 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:27:43,280 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97335915 bytes
2013-08-16 11:27:44,800 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13886394 bytes from map-output for attempt_1376651007637_0010_m_000001_0
2013-08-16 11:27:44,800 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13886394, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139071420
2013-08-16 11:27:44,801 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#4 in 68581s
2013-08-16 11:27:44,801 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 6 to fetcher#2
2013-08-16 11:27:44,801 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-5:8080 to fetcher#2
2013-08-16 11:27:44,817 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000009_0,attempt_1376651007637_0010_m_000012_0,attempt_1376651007637_0010_m_000015_0,attempt_1376651007637_0010_m_000020_0,attempt_1376651007637_0010_m_000024_0,attempt_1376651007637_0010_m_000038_0 sent hash and received reply
2013-08-16 11:27:44,825 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 11:27:44,825 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#2 in 24s
2013-08-16 11:27:44,825 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 6 to fetcher#3
2013-08-16 11:27:44,825 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-512-5:8080 to fetcher#3
2013-08-16 11:27:45,007 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0010_r_000008_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010/output/attempt_1376651007637_0010_r_000008_1/map_6.out.merged of size 97335998
2013-08-16 11:27:46,084 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0010&reduce=8&map=attempt_1376651007637_0010_m_000009_0,attempt_1376651007637_0010_m_000015_0,attempt_1376651007637_0010_m_000012_0,attempt_1376651007637_0010_m_000038_0,attempt_1376651007637_0010_m_000020_0,attempt_1376651007637_0010_m_000024_0 sent hash and received reply
2013-08-16 11:27:46,089 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000009_0 decomp: 13899914 len: 13899918 to MEMORY
2013-08-16 11:27:50,777 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13949834 bytes from map-output for attempt_1376651007637_0010_m_000022_0
2013-08-16 11:27:50,777 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13949834, inMemoryMapOutputs.size() -> 2, commitMemory -> 13886394, usedMemory ->55635328
2013-08-16 11:27:50,876 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000026_0 decomp: 13823786 len: 13823790 to MEMORY
2013-08-16 11:27:57,301 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13899186 bytes from map-output for attempt_1376651007637_0010_m_000014_0
2013-08-16 11:27:57,302 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13899186, inMemoryMapOutputs.size() -> 3, commitMemory -> 27836228, usedMemory ->69459114
2013-08-16 11:27:57,307 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000017_0 decomp: 13965746 len: 13965750 to MEMORY
2013-08-16 11:28:05,168 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13823786 bytes from map-output for attempt_1376651007637_0010_m_000026_0
2013-08-16 11:28:05,168 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13823786, inMemoryMapOutputs.size() -> 4, commitMemory -> 41735414, usedMemory ->83424860
2013-08-16 11:28:05,259 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000029_0 decomp: 13932570 len: 13932574 to MEMORY
2013-08-16 11:28:10,834 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13965746 bytes from map-output for attempt_1376651007637_0010_m_000017_0
2013-08-16 11:28:10,835 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13965746, inMemoryMapOutputs.size() -> 5, commitMemory -> 55559200, usedMemory ->97357430
2013-08-16 11:28:10,841 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000018_0 decomp: 13946194 len: 13946198 to MEMORY
2013-08-16 11:28:14,197 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13932570 bytes from map-output for attempt_1376651007637_0010_m_000029_0
2013-08-16 11:28:14,198 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13932570, inMemoryMapOutputs.size() -> 6, commitMemory -> 69524946, usedMemory ->111303624
2013-08-16 11:28:14,202 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000032_0 decomp: 13929138 len: 13929142 to MEMORY
2013-08-16 11:28:18,568 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13946194 bytes from map-output for attempt_1376651007637_0010_m_000018_0
2013-08-16 11:28:18,569 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13946194, inMemoryMapOutputs.size() -> 7, commitMemory -> 83457516, usedMemory ->125232762
2013-08-16 11:28:18,569 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97403710 > mergeThreshold=86139864. Current usedMemory=125232762
2013-08-16 11:28:18,569 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:28:18,674 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000025_0 decomp: 13944738 len: 13944742 to MEMORY
2013-08-16 11:28:18,939 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:28:18,940 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:28:18,940 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97403619 bytes
2013-08-16 11:28:20,841 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0010_r_000008_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010/output/attempt_1376651007637_0010_r_000008_1/map_26.out.merged of size 97403702
2013-08-16 11:28:22,941 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944738 bytes from map-output for attempt_1376651007637_0010_m_000025_0
2013-08-16 11:28:22,942 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944738, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41773790
2013-08-16 11:28:22,945 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000023_0 decomp: 13999754 len: 13999758 to MEMORY
2013-08-16 11:28:23,192 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13929138 bytes from map-output for attempt_1376651007637_0010_m_000032_0
2013-08-16 11:28:23,193 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13929138, inMemoryMapOutputs.size() -> 2, commitMemory -> 13944738, usedMemory ->55773544
2013-08-16 11:28:23,197 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000034_0 decomp: 13871730 len: 13871734 to MEMORY
2013-08-16 11:28:27,664 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13999754 bytes from map-output for attempt_1376651007637_0010_m_000023_0
2013-08-16 11:28:27,665 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13999754, inMemoryMapOutputs.size() -> 3, commitMemory -> 27873876, usedMemory ->69645274
2013-08-16 11:28:27,670 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0010_m_000037_0 decomp: 13908026 len: 13908030 to MEMORY
2013-08-16 11:28:31,398 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13871730 bytes from map-output for attempt_1376651007637_0010_m_000034_0
2013-08-16 11:28:31,399 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13871730, inMemoryMapOutputs.size() -> 4, commitMemory -> 41873630, usedMemory ->83553300
2013-08-16 11:28:31,404 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0010_m_000039_0 decomp: 13866114 len: 13866118 to MEMORY
2013-08-16 11:28:34,746 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13908026 bytes from map-output for attempt_1376651007637_0010_m_000037_0
2013-08-16 11:28:34,746 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13908026, inMemoryMapOutputs.size() -> 5, commitMemory -> 55745360, usedMemory ->97419414
2013-08-16 11:28:34,747 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#1 in 111763s
2013-08-16 11:28:43,348 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13866114 bytes from map-output for attempt_1376651007637_0010_m_000039_0
2013-08-16 11:28:43,348 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13866114, inMemoryMapOutputs.size() -> 6, commitMemory -> 69653386, usedMemory ->97419414
2013-08-16 11:28:43,349 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#5 in 111368s
2013-08-16 11:28:44,491 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13899914 bytes from map-output for attempt_1376651007637_0010_m_000009_0
2013-08-16 11:28:44,491 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13899914, inMemoryMapOutputs.size() -> 7, commitMemory -> 83519500, usedMemory ->97419414
2013-08-16 11:28:44,491 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97419414 > mergeThreshold=86139864. Current usedMemory=97419414
2013-08-16 11:28:44,491 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:28:44,500 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000015_0 decomp: 13833874 len: 13833878 to MEMORY
2013-08-16 11:28:45,152 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:28:45,157 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:28:45,158 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97419323 bytes
2013-08-16 11:28:46,850 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0010_r_000008_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0010/output/attempt_1376651007637_0010_r_000008_1/map_39.out.merged of size 97419406
2013-08-16 11:28:56,949 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13833874 bytes from map-output for attempt_1376651007637_0010_m_000015_0
2013-08-16 11:28:56,949 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13833874, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13833874
2013-08-16 11:28:57,041 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000012_0 decomp: 13947338 len: 13947342 to MEMORY
2013-08-16 11:29:00,413 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 7180 may have finished in the interim.
2013-08-16 11:29:06,626 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13947338 bytes from map-output for attempt_1376651007637_0010_m_000012_0
2013-08-16 11:29:06,626 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13947338, inMemoryMapOutputs.size() -> 2, commitMemory -> 13833874, usedMemory ->27781212
2013-08-16 11:29:06,631 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000038_0 decomp: 13949002 len: 13949006 to MEMORY
2013-08-16 11:29:12,204 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13949002 bytes from map-output for attempt_1376651007637_0010_m_000038_0
2013-08-16 11:29:12,204 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13949002, inMemoryMapOutputs.size() -> 3, commitMemory -> 27781212, usedMemory ->41730214
2013-08-16 11:29:12,289 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000020_0 decomp: 13881506 len: 13881510 to MEMORY
2013-08-16 11:29:17,831 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13881506 bytes from map-output for attempt_1376651007637_0010_m_000020_0
2013-08-16 11:29:17,831 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13881506, inMemoryMapOutputs.size() -> 4, commitMemory -> 41730214, usedMemory ->55611720
2013-08-16 11:29:17,835 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0010_m_000024_0 decomp: 13872666 len: 13872670 to MEMORY
2013-08-16 11:29:27,898 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13872666 bytes from map-output for attempt_1376651007637_0010_m_000024_0
2013-08-16 11:29:27,898 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13872666, inMemoryMapOutputs.size() -> 5, commitMemory -> 55611720, usedMemory ->69484386
2013-08-16 11:29:27,898 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#3 in 103073s
2013-08-16 11:29:27,899 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-16 11:29:27,905 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-16 11:29:28,143 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-16 11:29:28,143 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69484321 bytes
2013-08-16 11:29:29,220 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69484386 bytes to disk to satisfy reduce memory limit
2013-08-16 11:29:29,221 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 556226148 bytes from disk
2013-08-16 11:29:29,223 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-16 11:29:29,223 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-16 11:29:30,178 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 556226046 bytes
2013-08-16 11:29:30,493 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-16 11:29:30,607 WARN [Thread-18] org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1376651007637_0010_r_000008_1/part-r-00008: File does not exist. Holder DFSClient_attempt_1376651007637_0010_r_000008_1_-1577213947_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)
2013-08-16 11:29:30,608 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1376651007637_0010_r_000008_1/part-r-00008
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1376651007637_0010_r_000008_1/part-r-00008: File does not exist. Holder DFSClient_attempt_1376651007637_0010_r_000008_1_-1577213947_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)
2013-08-16 11:29:30,609 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1376651007637_0010_r_000008_1/part-r-00008: File does not exist. Holder DFSClient_attempt_1376651007637_0010_r_000008_1_-1577213947_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

2013-08-16 11:29:30,610 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1376651007637_0010_r_000008_1/part-r-00008: File does not exist. Holder DFSClient_attempt_1376651007637_0010_r_000008_1_-1577213947_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)

2013-08-16 11:29:30,618 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
