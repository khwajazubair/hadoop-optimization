2013-08-10 09:50:36,996 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobHistoryServer
STARTUP_MSG:   host = hadoop-220-1.novalocal/192.168.100.10
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.0.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/ubuntu/hadoop-3.0.0-SNAPSHOT/etc/hadoop:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-compress-1.4.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/hadoop-auth-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jersey-json-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-lang-2.5.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/slf4j-log4j12-1.6.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jets3t-0.6.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/protobuf-java-2.4.0a.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/hadoop-annotations-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jersey-core-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/slf4j-api-1.6.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-io-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/zookeeper-3.4.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/stax-api-1.0.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-logging-1.1.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/avro-1.5.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-math-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/snappy-java-1.0.3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jersey-server-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/hadoop-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/common/hadoop-common-3.0.0-SNAPSHOT-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-lang-2.5.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/protobuf-java-2.4.0a.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jersey-core-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-io-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/commons-logging-1.1.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jersey-server-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-3.0.0-SNAPSHOT-tests.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/hdfs/hadoop-hdfs-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/protobuf-java-2.4.0a.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/jersey-guice-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/hadoop-annotations-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/jersey-core-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/netty-3.5.11.Final.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/commons-io-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/junit-4.8.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/avro-1.5.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/snappy-java-1.0.3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/jersey-server-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-client-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-site-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-api-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/protobuf-java-2.4.0a.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-guice-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/hadoop-annotations-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-core-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/netty-3.5.11.Final.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/junit-4.8.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/avro-1.5.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/snappy-java-1.0.3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-server-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT-tests.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-SNAPSHOT-tests.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-api-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-client-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-site-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/avro-1.5.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/commons-io-2.1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/hadoop-annotations-3.0.0-SNAPSHOT.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-core-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-guice-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/jersey-server-1.8.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/junit-4.8.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/netty-3.5.11.Final.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/protobuf-java-2.4.0a.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/mapreduce/lib/snappy-java-1.0.3.2.jar:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/modules/*.jar
STARTUP_MSG:   build = https://github.com/lalithsuresh/hadoop-common -r 0cb423bd4868928bb06cd93f882bb0913172fd17; compiled by 'lsuresh' on 2013-04-08T15:47Z
STARTUP_MSG:   java = 1.7.0_17
************************************************************/
2013-08-10 09:50:37,011 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for [TERM, HUP, INT]
2013-08-10 09:50:38,018 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-10 09:50:38,324 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init
2013-08-10 09:50:39,207 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating 504, Expected: 504
2013-08-10 09:50:39,227 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating 493, Expected: 1023
2013-08-10 09:50:39,227 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Explicitly setting permissions to : 1023, rwxrwxrwt
2013-08-10 09:50:39,262 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager is inited.
2013-08-10 09:50:39,262 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs...
2013-08-10 09:50:39,283 INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init
2013-08-10 09:50:39,285 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage is inited.
2013-08-10 09:50:39,285 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.JobHistory is inited.
2013-08-10 09:50:39,285 INFO org.apache.hadoop.yarn.service.AbstractService: Service:HistoryClientService is inited.
2013-08-10 09:50:39,285 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService is inited.
2013-08-10 09:50:39,285 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer is inited.
2013-08-10 09:50:39,390 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-10 09:50:39,525 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-10 09:50:39,525 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: JobHistoryServer metrics system started
2013-08-10 09:50:39,539 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2013-08-10 09:50:39,543 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager is started.
2013-08-10 09:50:39,543 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage is started.
2013-08-10 09:50:39,543 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2013-08-10 09:50:39,543 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2013-08-10 09:50:39,552 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.JobHistory is started.
2013-08-10 09:50:39,673 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2013-08-10 09:50:39,792 INFO org.apache.hadoop.http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2013-08-10 09:50:39,797 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context jobhistory
2013-08-10 09:50:39,797 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2013-08-10 09:50:39,797 INFO org.apache.hadoop.http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2013-08-10 09:50:39,805 INFO org.apache.hadoop.http.HttpServer: adding path spec: /jobhistory
2013-08-10 09:50:39,805 INFO org.apache.hadoop.http.HttpServer: adding path spec: /jobhistory/*
2013-08-10 09:50:39,806 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws
2013-08-10 09:50:39,806 INFO org.apache.hadoop.http.HttpServer: adding path spec: /ws/*
2013-08-10 09:50:39,808 INFO org.apache.hadoop.http.HttpServer: Added global filter 'guice' (class=com.google.inject.servlet.GuiceFilter)
2013-08-10 09:50:39,813 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 19888
2013-08-10 09:50:39,813 INFO org.mortbay.log: jetty-6.1.26
2013-08-10 09:50:39,874 INFO org.mortbay.log: Extract jar:file:/home/ubuntu/hadoop-3.0.0-SNAPSHOT/share/hadoop/yarn/hadoop-yarn-common-3.0.0-SNAPSHOT.jar!/webapps/jobhistory to /tmp/Jetty_0_0_0_0_19888_jobhistory____.djq1tw/webapp
2013-08-10 09:50:40,357 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:19888
2013-08-10 09:50:40,357 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /jobhistory started at 19888
2013-08-10 09:50:41,218 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2013-08-10 09:50:41,269 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 10020
2013-08-10 09:50:41,316 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB to the server
2013-08-10 09:50:41,318 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2013-08-10 09:50:41,318 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 10020: starting
2013-08-10 09:50:41,334 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryClientService: Instantiated MRClientService at hadoop-220-1.novalocal/192.168.100.10:10020
2013-08-10 09:50:41,334 INFO org.apache.hadoop.yarn.service.AbstractService: Service:HistoryClientService is started.
2013-08-10 09:50:41,334 INFO org.apache.hadoop.yarn.service.AbstractService: Service:org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer is started.
2013-08-10 09:51:09,552 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: History Cleaner started
2013-08-10 09:51:09,564 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: History Cleaner complete
2013-08-10 09:53:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 09:56:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 09:56:39,892 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0001,submitTime=1376128248457,launchTime=1376128258919,firstMapTaskLaunchTime=1376128261249,firstReduceTaskLaunchTime=0,finishTime=1376128433481,resourcesPerMap=1024,resourcesPerReduce=0,numMaps=2,numReduces=0,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=339,reduceSlotSeconds=0,jobName=TeraGen
2013-08-10 09:56:39,892 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0001.summary]
2013-08-10 09:56:39,915 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Perms after creating 504, Expected: 504
2013-08-10 09:56:39,916 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0001-1376128248457-ubuntu-TeraGen-1376128433481-2-0-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0001-1376128248457-ubuntu-TeraGen-1376128433481-2-0-SUCCEEDED-default.jhist
2013-08-10 09:56:39,929 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0001_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0001_conf.xml
2013-08-10 09:59:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 09:59:39,599 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0002,submitTime=1376128440857,launchTime=1376128449666,firstMapTaskLaunchTime=1376128452002,firstReduceTaskLaunchTime=0,finishTime=1376128613337,resourcesPerMap=1024,resourcesPerReduce=0,numMaps=2,numReduces=0,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=320,reduceSlotSeconds=0,jobName=TeraGen
2013-08-10 09:59:39,599 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0002.summary]
2013-08-10 09:59:39,608 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0002-1376128440857-ubuntu-TeraGen-1376128613337-2-0-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0002-1376128440857-ubuntu-TeraGen-1376128613337-2-0-SUCCEEDED-default.jhist
2013-08-10 09:59:39,613 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0002_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0002_conf.xml
2013-08-10 10:02:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:02:39,586 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0003,submitTime=1376128622104,launchTime=1376128634212,firstMapTaskLaunchTime=1376128636535,firstReduceTaskLaunchTime=0,finishTime=1376128810505,resourcesPerMap=1024,resourcesPerReduce=0,numMaps=2,numReduces=0,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=327,reduceSlotSeconds=0,jobName=TeraGen
2013-08-10 10:02:39,587 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0003.summary]
2013-08-10 10:02:39,595 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0003-1376128622104-ubuntu-TeraGen-1376128810505-2-0-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0003-1376128622104-ubuntu-TeraGen-1376128810505-2-0-SUCCEEDED-default.jhist
2013-08-10 10:02:39,599 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0003_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0003_conf.xml
2013-08-10 10:05:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:05:39,579 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0004,submitTime=1376128818993,launchTime=1376128826117,firstMapTaskLaunchTime=1376128828403,firstReduceTaskLaunchTime=0,finishTime=1376129007674,resourcesPerMap=1024,resourcesPerReduce=0,numMaps=2,numReduces=0,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=333,reduceSlotSeconds=0,jobName=TeraGen
2013-08-10 10:05:39,579 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0004.summary]
2013-08-10 10:05:39,588 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0004-1376128818993-ubuntu-TeraGen-1376129007674-2-0-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0004-1376128818993-ubuntu-TeraGen-1376129007674-2-0-SUCCEEDED-default.jhist
2013-08-10 10:05:39,592 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0004_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0004_conf.xml
2013-08-10 10:08:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:08:41,563 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0005,submitTime=1376129016736,launchTime=1376129024526,firstMapTaskLaunchTime=1376129026872,firstReduceTaskLaunchTime=0,finishTime=1376129195736,resourcesPerMap=1024,resourcesPerReduce=0,numMaps=2,numReduces=0,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=328,reduceSlotSeconds=0,jobName=TeraGen
2013-08-10 10:08:41,563 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0005.summary]
2013-08-10 10:08:41,573 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0005-1376129016736-ubuntu-TeraGen-1376129195736-2-0-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0005-1376129016736-ubuntu-TeraGen-1376129195736-2-0-SUCCEEDED-default.jhist
2013-08-10 10:08:41,577 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0005_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0005_conf.xml
2013-08-10 10:11:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:14:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:17:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:20:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:20:39,572 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0007,submitTime=1376129209940,launchTime=1376129216650,firstMapTaskLaunchTime=1376129297577,firstReduceTaskLaunchTime=1376129342047,finishTime=1376130022754,resourcesPerMap=1024,resourcesPerReduce=1024,numMaps=40,numReduces=1,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=2812,reduceSlotSeconds=680,jobName=TeraSort
2013-08-10 10:20:39,572 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0007.summary]
2013-08-10 10:20:39,580 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0007-1376129209940-ubuntu-TeraSort-1376130022754-40-1-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0007-1376129209940-ubuntu-TeraSort-1376130022754-40-1-SUCCEEDED-default.jhist
2013-08-10 10:20:39,584 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0007_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0007_conf.xml
2013-08-10 10:23:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:23:42,571 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.26:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:23:42,575 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:23:42,575 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 914.1141908498574 msec.
2013-08-10 10:23:45,568 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.26:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:23:45,570 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:23:45,570 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 5929.4877040115825 msec.
2013-08-10 10:23:54,500 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.26:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:23:54,509 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:23:54,509 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 14043.869343801773 msec.
2013-08-10 10:24:11,561 WARN org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.26:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:24:11,563 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:24:11,563 ERROR org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Error while trying to move a job to done
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:26:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:29:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:32:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:35:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:35:39,570 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:35:39,570 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:35:39,570 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 736.7582693768211 msec.
2013-08-10 10:35:39,576 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1376128223647_0008,submitTime=1376129209941,launchTime=1376129214859,firstMapTaskLaunchTime=1376129217320,firstReduceTaskLaunchTime=1376129386347,finishTime=1376130822655,resourcesPerMap=1024,resourcesPerReduce=1024,numMaps=40,numReduces=1,user=ubuntu,queue=default,status=SUCCEEDED,mapSlotSeconds=2152,reduceSlotSeconds=1436,jobName=TeraSort
2013-08-10 10:35:39,576 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file: [hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0008.summary]
2013-08-10 10:35:39,584 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0008-1376129209941-ubuntu-TeraSort-1376130822655-40-1-SUCCEEDED-default.jhist to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0008-1376129209941-ubuntu-TeraSort-1376130822655-40-1-SUCCEEDED-default.jhist
2013-08-10 10:35:39,587 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0008_conf.xml to hdfs://hadoop-220-1:54310/tmp/hadoop-yarn/staging/history/done/2013/08/10/000000/job_1376128223647_0008_conf.xml
2013-08-10 10:35:40,311 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:35:40,311 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:35:40,311 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 3748.4727705713194 msec.
2013-08-10 10:35:44,063 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:35:44,064 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:35:44,064 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 14605.121408620953 msec.
2013-08-10 10:35:58,682 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:35:58,683 ERROR org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Error while trying to move a job to done
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:38:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2013-08-10 10:38:39,576 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:38:39,576 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:38:39,576 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 2031.7096206518659 msec.
2013-08-10 10:38:41,611 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:38:41,612 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:38:41,612 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 2 IOException, will wait for 6354.801436051727 msec.
2013-08-10 10:38:47,969 INFO org.apache.hadoop.hdfs.DFSClient: No node available for BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
2013-08-10 10:38:47,970 INFO org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-10 10:38:47,970 WARN org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 3 IOException, will wait for 13259.51538802806 msec.
2013-08-10 10:39:01,237 WARN org.apache.hadoop.hdfs.DFSClient: DFS Read
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:39:01,238 ERROR org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Error while trying to move a job to done
org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1178826852-192.168.100.10-1376128199101:blk_6093557166451487328_1515 file=/tmp/hadoop-yarn/staging/history/done_intermediate/ubuntu/job_1376128223647_0010.summary
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:738)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:448)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:337)
	at java.io.DataInputStream.readUTF(DataInputStream.java:589)
	at java.io.DataInputStream.readUTF(DataInputStream.java:564)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:770)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$500(HistoryFileManager.java:74)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:289)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1600(HistoryFileManager.java:226)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:662)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:722)
2013-08-10 10:41:39,549 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
