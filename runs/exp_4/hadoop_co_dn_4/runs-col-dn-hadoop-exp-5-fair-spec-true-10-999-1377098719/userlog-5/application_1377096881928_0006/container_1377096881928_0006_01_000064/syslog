2013-08-21 15:17:22,146 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-21 15:17:22,205 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-21 15:17:22,440 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-21 15:17:22,597 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-21 15:17:22,597 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-21 15:17:22,622 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-21 15:17:22,623 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377096881928_0006, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-21 15:17:22,757 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-21 15:17:23,503 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006
2013-08-21 15:17:23,834 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-21 15:17:23,835 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-21 15:17:23,836 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-21 15:17:23,837 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-21 15:17:23,841 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-21 15:17:23,842 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-21 15:17:23,842 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-21 15:17:23,843 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-21 15:17:23,843 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-21 15:17:24,100 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-21 15:17:24,652 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-21 15:17:24,736 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@535265e
2013-08-21 15:17:24,782 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-21 15:17:24,788 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377096881928_0006_r_000002_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-21 15:17:24,809 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 1 to fetcher#5
2013-08-21 15:17:24,810 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-7:8080 to fetcher#5
2013-08-21 15:17:24,810 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#1
2013-08-21 15:17:24,811 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#1
2013-08-21 15:17:24,811 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 1 to fetcher#2
2013-08-21 15:17:24,811 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-4:8080 to fetcher#2
2013-08-21 15:17:24,813 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 1 to fetcher#4
2013-08-21 15:17:24,813 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-3:8080 to fetcher#4
2013-08-21 15:17:24,813 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 1 to fetcher#3
2013-08-21 15:17:24,814 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-2:8080 to fetcher#3
2013-08-21 15:17:24,836 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377096881928_0006_r_000002_1: Got 40 new map-outputs
2013-08-21 15:17:25,066 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000005_0 sent hash and received reply
2013-08-21 15:17:25,066 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000000_0 sent hash and received reply
2013-08-21 15:17:25,068 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000001_0 sent hash and received reply
2013-08-21 15:17:25,069 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000006_0 sent hash and received reply
2013-08-21 15:17:25,105 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000005_0 decomp: 14106978 len: 14106982 to MEMORY
2013-08-21 15:17:25,117 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000006_0 decomp: 14176346 len: 14176350 to MEMORY
2013-08-21 15:17:25,122 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000000_0 decomp: 14139426 len: 14139430 to MEMORY
2013-08-21 15:17:25,135 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000001_0 decomp: 14169274 len: 14169278 to MEMORY
2013-08-21 15:17:26,730 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14176346 bytes from map-output for attempt_1377096881928_0006_m_000006_0
2013-08-21 15:17:26,732 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14176346, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->56592024
2013-08-21 15:17:26,734 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#3 in 1920s
2013-08-21 15:17:26,735 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#3
2013-08-21 15:17:26,735 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#3
2013-08-21 15:17:26,740 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000012_0,attempt_1377096881928_0006_m_000019_0,attempt_1377096881928_0006_m_000022_0,attempt_1377096881928_0006_m_000023_0,attempt_1377096881928_0006_m_000037_0 sent hash and received reply
2013-08-21 15:17:26,931 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000012_0 decomp: 14202034 len: 14202038 to MEMORY
2013-08-21 15:17:28,180 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14202034 bytes from map-output for attempt_1377096881928_0006_m_000012_0
2013-08-21 15:17:28,180 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14202034, inMemoryMapOutputs.size() -> 2, commitMemory -> 14176346, usedMemory ->70794058
2013-08-21 15:17:28,183 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000019_0 decomp: 14122474 len: 14122478 to MEMORY
2013-08-21 15:17:28,702 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000004_0 sent hash and received reply
2013-08-21 15:17:28,715 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377096881928_0006_m_000004_0 decomp: 14162930 len: 14162934 to MEMORY
2013-08-21 15:17:29,037 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14169274 bytes from map-output for attempt_1377096881928_0006_m_000001_0
2013-08-21 15:17:29,038 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14169274, inMemoryMapOutputs.size() -> 3, commitMemory -> 28378380, usedMemory ->99079462
2013-08-21 15:17:29,038 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#1 in 4227s
2013-08-21 15:17:29,039 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 6 to fetcher#1
2013-08-21 15:17:29,039 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-5:8080 to fetcher#1
2013-08-21 15:17:29,042 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000003_0,attempt_1377096881928_0006_m_000009_0,attempt_1377096881928_0006_m_000014_0,attempt_1377096881928_0006_m_000017_0,attempt_1377096881928_0006_m_000026_0,attempt_1377096881928_0006_m_000033_0 sent hash and received reply
2013-08-21 15:17:29,048 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000003_0 decomp: 14132562 len: 14132566 to MEMORY
2013-08-21 15:17:29,703 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14122474 bytes from map-output for attempt_1377096881928_0006_m_000019_0
2013-08-21 15:17:29,704 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14122474, inMemoryMapOutputs.size() -> 4, commitMemory -> 42547654, usedMemory ->113212024
2013-08-21 15:17:29,848 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000022_0 decomp: 14068498 len: 14068502 to MEMORY
2013-08-21 15:17:31,073 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14139426 bytes from map-output for attempt_1377096881928_0006_m_000000_0
2013-08-21 15:17:31,158 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14139426, inMemoryMapOutputs.size() -> 5, commitMemory -> 56670128, usedMemory ->127280522
2013-08-21 15:17:31,114 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14068498 bytes from map-output for attempt_1377096881928_0006_m_000022_0
2013-08-21 15:17:31,158 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#5 in 6349s
2013-08-21 15:17:31,159 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 6 to fetcher#5
2013-08-21 15:17:31,159 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-7:8080 to fetcher#5
2013-08-21 15:17:31,159 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14068498, inMemoryMapOutputs.size() -> 6, commitMemory -> 70809554, usedMemory ->127280522
2013-08-21 15:17:31,164 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000023_0 decomp: 14191322 len: 14191326 to MEMORY
2013-08-21 15:17:31,165 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000008_0,attempt_1377096881928_0006_m_000018_0,attempt_1377096881928_0006_m_000028_0,attempt_1377096881928_0006_m_000030_0,attempt_1377096881928_0006_m_000035_0,attempt_1377096881928_0006_m_000036_0 sent hash and received reply
2013-08-21 15:17:31,166 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-21 15:17:31,166 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#5 in 7s
2013-08-21 15:17:31,167 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 5 to fetcher#5
2013-08-21 15:17:31,167 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-6:8080 to fetcher#5
2013-08-21 15:17:31,173 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000010_0,attempt_1377096881928_0006_m_000020_0,attempt_1377096881928_0006_m_000027_0,attempt_1377096881928_0006_m_000032_0,attempt_1377096881928_0006_m_000039_0 sent hash and received reply
2013-08-21 15:17:31,174 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-21 15:17:31,174 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#5 in 7s
2013-08-21 15:17:31,174 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 5 to fetcher#5
2013-08-21 15:17:31,174 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-6:8080 to fetcher#5
2013-08-21 15:17:32,539 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14191322 bytes from map-output for attempt_1377096881928_0006_m_000023_0
2013-08-21 15:17:32,540 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14191322, inMemoryMapOutputs.size() -> 7, commitMemory -> 84878052, usedMemory ->141471844
2013-08-21 15:17:32,540 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=99069374 > mergeThreshold=86139864. Current usedMemory=141471844
2013-08-21 15:17:32,540 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 15:17:32,541 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-21 15:17:32,542 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#3 in 5807s
2013-08-21 15:17:32,859 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 15:17:32,867 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 15:17:32,868 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 99069283 bytes
2013-08-21 15:17:32,937 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14132562 bytes from map-output for attempt_1377096881928_0006_m_000003_0
2013-08-21 15:17:32,937 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14132562, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->141471844
2013-08-21 15:17:32,938 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-21 15:17:32,938 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#1 in 3899s
2013-08-21 15:17:34,535 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14106978 bytes from map-output for attempt_1377096881928_0006_m_000005_0
2013-08-21 15:17:34,536 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14106978, inMemoryMapOutputs.size() -> 2, commitMemory -> 14132562, usedMemory ->141471844
2013-08-21 15:17:34,536 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#2 in 9725s
2013-08-21 15:17:34,957 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377096881928_0006_r_000002_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006/output/attempt_1377096881928_0006_r_000002_1/map_22.out.merged of size 99069366
2013-08-21 15:17:34,958 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 6 to fetcher#2
2013-08-21 15:17:34,958 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-7:8080 to fetcher#2
2013-08-21 15:17:34,958 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 7 to fetcher#3
2013-08-21 15:17:34,958 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-999-4:8080 to fetcher#3
2013-08-21 15:17:34,960 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 1 to fetcher#1
2013-08-21 15:17:34,960 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-2:8080 to fetcher#1
2013-08-21 15:17:34,963 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000036_0,attempt_1377096881928_0006_m_000008_0,attempt_1377096881928_0006_m_000035_0,attempt_1377096881928_0006_m_000030_0,attempt_1377096881928_0006_m_000018_0,attempt_1377096881928_0006_m_000028_0 sent hash and received reply
2013-08-21 15:17:35,043 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000037_0 sent hash and received reply
2013-08-21 15:17:35,047 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000036_0 decomp: 14182378 len: 14182382 to MEMORY
2013-08-21 15:17:35,051 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000037_0 decomp: 14103650 len: 14103654 to MEMORY
2013-08-21 15:17:35,572 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14103650 bytes from map-output for attempt_1377096881928_0006_m_000037_0
2013-08-21 15:17:35,572 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14103650, inMemoryMapOutputs.size() -> 3, commitMemory -> 28239540, usedMemory ->70688498
2013-08-21 15:17:35,573 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 613s
2013-08-21 15:17:35,573 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 5 to fetcher#1
2013-08-21 15:17:35,573 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-5:8080 to fetcher#1
2013-08-21 15:17:35,577 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000033_0,attempt_1377096881928_0006_m_000009_0,attempt_1377096881928_0006_m_000026_0,attempt_1377096881928_0006_m_000014_0,attempt_1377096881928_0006_m_000017_0 sent hash and received reply
2013-08-21 15:17:35,582 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000033_0 decomp: 14118834 len: 14118838 to MEMORY
2013-08-21 15:17:37,525 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14118834 bytes from map-output for attempt_1377096881928_0006_m_000033_0
2013-08-21 15:17:37,525 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14118834, inMemoryMapOutputs.size() -> 4, commitMemory -> 42343190, usedMemory ->84807332
2013-08-21 15:17:37,627 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000009_0 decomp: 14139946 len: 14139950 to MEMORY
2013-08-21 15:17:38,305 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14182378 bytes from map-output for attempt_1377096881928_0006_m_000036_0
2013-08-21 15:17:38,306 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14182378, inMemoryMapOutputs.size() -> 5, commitMemory -> 56462024, usedMemory ->98947278
2013-08-21 15:17:38,310 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000008_0 decomp: 14138594 len: 14138598 to MEMORY
2013-08-21 15:17:39,545 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14139946 bytes from map-output for attempt_1377096881928_0006_m_000009_0
2013-08-21 15:17:39,545 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14139946, inMemoryMapOutputs.size() -> 6, commitMemory -> 70644402, usedMemory ->113085872
2013-08-21 15:17:39,549 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000026_0 decomp: 14116442 len: 14116446 to MEMORY
2013-08-21 15:17:41,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14162930 bytes from map-output for attempt_1377096881928_0006_m_000004_0
2013-08-21 15:17:41,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14162930, inMemoryMapOutputs.size() -> 7, commitMemory -> 84784348, usedMemory ->127202314
2013-08-21 15:17:41,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=98947278 > mergeThreshold=86139864. Current usedMemory=127202314
2013-08-21 15:17:41,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 15:17:41,930 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#4 in 17117s
2013-08-21 15:17:42,242 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 15:17:42,243 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 15:17:42,243 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 98947187 bytes
2013-08-21 15:17:42,521 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14116442 bytes from map-output for attempt_1377096881928_0006_m_000026_0
2013-08-21 15:17:42,521 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14116442, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->127202314
2013-08-21 15:17:42,526 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000014_0 decomp: 14161682 len: 14161686 to MEMORY
2013-08-21 15:17:43,631 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14138594 bytes from map-output for attempt_1377096881928_0006_m_000008_0
2013-08-21 15:17:43,631 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14138594, inMemoryMapOutputs.size() -> 2, commitMemory -> 14116442, usedMemory ->141363996
2013-08-21 15:17:43,633 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-21 15:17:43,638 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#2 in 8680s
2013-08-21 15:17:43,927 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377096881928_0006_r_000002_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006/output/attempt_1377096881928_0006_r_000002_1/map_37.out.merged of size 98947270
2013-08-21 15:17:43,927 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 6 to fetcher#2
2013-08-21 15:17:43,927 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-3:8080 to fetcher#2
2013-08-21 15:17:43,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 4 to fetcher#4
2013-08-21 15:17:43,928 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-999-7:8080 to fetcher#4
2013-08-21 15:17:43,932 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000035_0,attempt_1377096881928_0006_m_000018_0,attempt_1377096881928_0006_m_000030_0,attempt_1377096881928_0006_m_000028_0 sent hash and received reply
2013-08-21 15:17:43,937 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377096881928_0006_m_000035_0 decomp: 14134954 len: 14134958 to MEMORY
2013-08-21 15:17:44,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14161682 bytes from map-output for attempt_1377096881928_0006_m_000014_0
2013-08-21 15:17:44,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14161682, inMemoryMapOutputs.size() -> 3, commitMemory -> 28255036, usedMemory ->56551672
2013-08-21 15:17:44,599 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377096881928_0006_m_000017_0 decomp: 14179154 len: 14179158 to MEMORY
2013-08-21 15:17:46,647 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14179154 bytes from map-output for attempt_1377096881928_0006_m_000017_0
2013-08-21 15:17:46,647 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14179154, inMemoryMapOutputs.size() -> 4, commitMemory -> 42416718, usedMemory ->70730826
2013-08-21 15:17:46,649 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#1 in 11076s
2013-08-21 15:17:46,831 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000002_0,attempt_1377096881928_0006_m_000011_0,attempt_1377096881928_0006_m_000016_0,attempt_1377096881928_0006_m_000021_0,attempt_1377096881928_0006_m_000024_0,attempt_1377096881928_0006_m_000031_0,attempt_1377096881928_0006_m_000034_0 sent hash and received reply
2013-08-21 15:17:46,928 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000002_0 decomp: 14220130 len: 14220134 to MEMORY
2013-08-21 15:17:47,427 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14134954 bytes from map-output for attempt_1377096881928_0006_m_000035_0
2013-08-21 15:17:47,428 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14134954, inMemoryMapOutputs.size() -> 5, commitMemory -> 56595872, usedMemory ->84950956
2013-08-21 15:17:47,432 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377096881928_0006_m_000018_0 decomp: 14198290 len: 14198294 to MEMORY
2013-08-21 15:17:48,877 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14198290 bytes from map-output for attempt_1377096881928_0006_m_000018_0
2013-08-21 15:17:48,877 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14198290, inMemoryMapOutputs.size() -> 6, commitMemory -> 70730826, usedMemory ->99149246
2013-08-21 15:17:48,881 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377096881928_0006_m_000030_0 decomp: 14127050 len: 14127054 to MEMORY
2013-08-21 15:17:50,604 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000007_0,attempt_1377096881928_0006_m_000015_0,attempt_1377096881928_0006_m_000013_0,attempt_1377096881928_0006_m_000025_0,attempt_1377096881928_0006_m_000029_0,attempt_1377096881928_0006_m_000038_0 sent hash and received reply
2013-08-21 15:17:50,696 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000007_0 decomp: 14126634 len: 14126638 to MEMORY
2013-08-21 15:17:51,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14127050 bytes from map-output for attempt_1377096881928_0006_m_000030_0
2013-08-21 15:17:51,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14127050, inMemoryMapOutputs.size() -> 7, commitMemory -> 84929116, usedMemory ->127402930
2013-08-21 15:17:51,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=99056166 > mergeThreshold=86139864. Current usedMemory=127402930
2013-08-21 15:17:51,022 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 15:17:51,026 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377096881928_0006_m_000028_0 decomp: 14139842 len: 14139846 to MEMORY
2013-08-21 15:17:51,237 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 15:17:51,237 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 15:17:51,237 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 99056075 bytes
2013-08-21 15:17:51,957 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14139842 bytes from map-output for attempt_1377096881928_0006_m_000028_0
2013-08-21 15:17:51,957 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14139842, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->141542772
2013-08-21 15:17:51,957 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#4 in 8029s
2013-08-21 15:17:52,786 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377096881928_0006_r_000002_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006/output/attempt_1377096881928_0006_r_000002_1/map_26.out.merged of size 99056158
2013-08-21 15:18:02,739 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14220130 bytes from map-output for attempt_1377096881928_0006_m_000002_0
2013-08-21 15:18:02,739 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14220130, inMemoryMapOutputs.size() -> 2, commitMemory -> 14139842, usedMemory ->42486606
2013-08-21 15:18:02,746 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000011_0 decomp: 14125698 len: 14125702 to MEMORY
2013-08-21 15:18:04,585 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14125698 bytes from map-output for attempt_1377096881928_0006_m_000011_0
2013-08-21 15:18:04,585 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14125698, inMemoryMapOutputs.size() -> 3, commitMemory -> 28359972, usedMemory ->56612304
2013-08-21 15:18:04,589 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000016_0 decomp: 14161058 len: 14161062 to MEMORY
2013-08-21 15:18:11,781 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14161058 bytes from map-output for attempt_1377096881928_0006_m_000016_0
2013-08-21 15:18:11,782 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14161058, inMemoryMapOutputs.size() -> 4, commitMemory -> 42485670, usedMemory ->70773362
2013-08-21 15:18:11,786 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000021_0 decomp: 14142962 len: 14142966 to MEMORY
2013-08-21 15:18:17,647 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14142962 bytes from map-output for attempt_1377096881928_0006_m_000021_0
2013-08-21 15:18:17,648 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14142962, inMemoryMapOutputs.size() -> 5, commitMemory -> 56646728, usedMemory ->84916324
2013-08-21 15:18:17,799 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000024_0 decomp: 14180818 len: 14180822 to MEMORY
2013-08-21 15:18:25,858 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14180818 bytes from map-output for attempt_1377096881928_0006_m_000024_0
2013-08-21 15:18:25,858 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14180818, inMemoryMapOutputs.size() -> 6, commitMemory -> 70789690, usedMemory ->99097142
2013-08-21 15:18:25,862 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000031_0 decomp: 14161578 len: 14161582 to MEMORY
2013-08-21 15:18:36,016 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14161578 bytes from map-output for attempt_1377096881928_0006_m_000031_0
2013-08-21 15:18:36,016 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14161578, inMemoryMapOutputs.size() -> 7, commitMemory -> 84970508, usedMemory ->113258720
2013-08-21 15:18:36,016 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=99132086 > mergeThreshold=86139864. Current usedMemory=113258720
2013-08-21 15:18:36,017 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 15:18:36,122 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377096881928_0006_m_000034_0 decomp: 14169274 len: 14169278 to MEMORY
2013-08-21 15:18:36,310 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 15:18:36,311 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 15:18:36,311 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 99131995 bytes
2013-08-21 15:18:37,739 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377096881928_0006_r_000002_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006/output/attempt_1377096881928_0006_r_000002_1/map_11.out.merged of size 99132078
2013-08-21 15:18:42,685 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14169274 bytes from map-output for attempt_1377096881928_0006_m_000034_0
2013-08-21 15:18:42,685 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14169274, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28295908
2013-08-21 15:18:42,686 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#3 in 67728s
2013-08-21 15:18:44,838 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377096881928_0006&reduce=2&map=attempt_1377096881928_0006_m_000039_0,attempt_1377096881928_0006_m_000032_0,attempt_1377096881928_0006_m_000020_0,attempt_1377096881928_0006_m_000027_0,attempt_1377096881928_0006_m_000010_0 sent hash and received reply
2013-08-21 15:18:44,848 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000039_0 decomp: 14181338 len: 14181342 to MEMORY
2013-08-21 15:19:18,324 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14181338 bytes from map-output for attempt_1377096881928_0006_m_000039_0
2013-08-21 15:19:18,325 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14181338, inMemoryMapOutputs.size() -> 2, commitMemory -> 14169274, usedMemory ->42477246
2013-08-21 15:19:18,330 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000032_0 decomp: 14166466 len: 14166470 to MEMORY
2013-08-21 15:19:31,834 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14126634 bytes from map-output for attempt_1377096881928_0006_m_000007_0
2013-08-21 15:19:31,834 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14126634, inMemoryMapOutputs.size() -> 3, commitMemory -> 28350612, usedMemory ->56643712
2013-08-21 15:19:31,956 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000015_0 decomp: 14147538 len: 14147542 to MEMORY
2013-08-21 15:19:38,570 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14147538 bytes from map-output for attempt_1377096881928_0006_m_000015_0
2013-08-21 15:19:38,570 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14147538, inMemoryMapOutputs.size() -> 4, commitMemory -> 42477246, usedMemory ->70791250
2013-08-21 15:19:38,575 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000013_0 decomp: 14138282 len: 14138286 to MEMORY
2013-08-21 15:19:38,917 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14166466 bytes from map-output for attempt_1377096881928_0006_m_000032_0
2013-08-21 15:19:38,917 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14166466, inMemoryMapOutputs.size() -> 5, commitMemory -> 56624784, usedMemory ->84929532
2013-08-21 15:19:38,922 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000020_0 decomp: 14130898 len: 14130902 to MEMORY
2013-08-21 15:19:44,088 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14130898 bytes from map-output for attempt_1377096881928_0006_m_000020_0
2013-08-21 15:19:44,088 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14130898, inMemoryMapOutputs.size() -> 6, commitMemory -> 70791250, usedMemory ->99060430
2013-08-21 15:19:44,094 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000027_0 decomp: 14192466 len: 14192470 to MEMORY
2013-08-21 15:19:48,647 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14192466 bytes from map-output for attempt_1377096881928_0006_m_000027_0
2013-08-21 15:19:48,648 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14192466, inMemoryMapOutputs.size() -> 7, commitMemory -> 84922148, usedMemory ->113252896
2013-08-21 15:19:48,648 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=99114614 > mergeThreshold=86139864. Current usedMemory=113252896
2013-08-21 15:19:48,648 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 15:19:48,654 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377096881928_0006_m_000010_0 decomp: 14192778 len: 14192782 to MEMORY
2013-08-21 15:19:49,045 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 15:19:49,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 15:19:49,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 99114523 bytes
2013-08-21 15:19:50,641 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14138282 bytes from map-output for attempt_1377096881928_0006_m_000013_0
2013-08-21 15:19:50,641 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14138282, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->127445674
2013-08-21 15:19:50,645 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000025_0 decomp: 14172810 len: 14172814 to MEMORY
2013-08-21 15:19:50,762 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377096881928_0006_r_000002_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377096881928_0006/output/attempt_1377096881928_0006_r_000002_1/map_7.out.merged of size 99114606
2013-08-21 15:19:54,436 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14192778 bytes from map-output for attempt_1377096881928_0006_m_000010_0
2013-08-21 15:19:54,436 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14192778, inMemoryMapOutputs.size() -> 2, commitMemory -> 14138282, usedMemory ->42503870
2013-08-21 15:19:54,437 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#5 in 143263s
2013-08-21 15:20:02,808 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14172810 bytes from map-output for attempt_1377096881928_0006_m_000025_0
2013-08-21 15:20:02,808 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14172810, inMemoryMapOutputs.size() -> 3, commitMemory -> 28331060, usedMemory ->42503870
2013-08-21 15:20:02,814 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000029_0 decomp: 14148266 len: 14148270 to MEMORY
2013-08-21 15:20:07,261 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14148266 bytes from map-output for attempt_1377096881928_0006_m_000029_0
2013-08-21 15:20:07,261 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14148266, inMemoryMapOutputs.size() -> 4, commitMemory -> 42503870, usedMemory ->56652136
2013-08-21 15:20:07,343 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377096881928_0006_m_000038_0 decomp: 14112802 len: 14112806 to MEMORY
2013-08-21 15:20:11,842 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14112802 bytes from map-output for attempt_1377096881928_0006_m_000038_0
2013-08-21 15:20:11,842 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14112802, inMemoryMapOutputs.size() -> 5, commitMemory -> 56652136, usedMemory ->70764938
2013-08-21 15:20:11,843 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#2 in 147916s
2013-08-21 15:20:11,843 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-21 15:20:11,850 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-21 15:20:11,990 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-21 15:20:11,990 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 70764873 bytes
2013-08-21 15:20:13,145 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 70764938 bytes to disk to satisfy reduce memory limit
2013-08-21 15:20:13,148 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 566084412 bytes from disk
2013-08-21 15:20:13,151 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-21 15:20:13,151 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-21 15:20:13,156 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 566084310 bytes
2013-08-21 15:20:13,357 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-21 15:20:19,390 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-21 15:20:19,391 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-21 15:20:19,392 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-2/_temporary/1/_temporary/attempt_1377096881928_0006_r_000002_1/part-r-00002
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-2/_temporary/1/_temporary/attempt_1377096881928_0006_r_000002_1/part-r-00002: File does not exist. Holder DFSClient_attempt_1377096881928_0006_r_000002_1_252535160_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
