2013-08-21 13:37:03,134 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-21 13:37:03,191 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-21 13:37:03,392 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-21 13:37:03,550 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-21 13:37:03,551 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-21 13:37:03,574 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-21 13:37:03,574 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377090872829_0008, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-21 13:37:03,718 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-21 13:37:04,582 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008
2013-08-21 13:37:05,510 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-21 13:37:05,511 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-21 13:37:05,512 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-21 13:37:05,513 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-21 13:37:05,514 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-21 13:37:05,515 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-21 13:37:05,517 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-21 13:37:05,521 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-21 13:37:05,521 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-21 13:37:05,795 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-21 13:37:06,374 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-21 13:37:06,487 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@683fbf43
2013-08-21 13:37:06,521 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-21 13:37:06,526 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377090872829_0008_r_000005_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-21 13:37:06,548 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#5
2013-08-21 13:37:06,548 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#5
2013-08-21 13:37:06,549 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 1 to fetcher#1
2013-08-21 13:37:06,549 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-2:8080 to fetcher#1
2013-08-21 13:37:06,551 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 1 to fetcher#2
2013-08-21 13:37:06,551 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-4:8080 to fetcher#2
2013-08-21 13:37:06,551 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 3 to fetcher#3
2013-08-21 13:37:06,551 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-6:8080 to fetcher#3
2013-08-21 13:37:06,552 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 1 to fetcher#4
2013-08-21 13:37:06,552 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-7:8080 to fetcher#4
2013-08-21 13:37:06,581 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377090872829_0008_r_000005_1: Got 40 new map-outputs
2013-08-21 13:37:06,815 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000001_0 sent hash and received reply
2013-08-21 13:37:06,820 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000006_0 sent hash and received reply
2013-08-21 13:37:06,824 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000003_0 sent hash and received reply
2013-08-21 13:37:06,916 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000001_0 decomp: 13978226 len: 13978230 to MEMORY
2013-08-21 13:37:06,922 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000003_0 decomp: 13956178 len: 13956182 to MEMORY
2013-08-21 13:37:06,927 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000006_0 decomp: 13931738 len: 13931742 to MEMORY
2013-08-21 13:37:07,535 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13978226 bytes from map-output for attempt_1377090872829_0008_m_000001_0
2013-08-21 13:37:07,538 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13978226, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41866142
2013-08-21 13:37:07,544 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#5 in 996s
2013-08-21 13:37:07,544 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 3 to fetcher#5
2013-08-21 13:37:07,545 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-3:8080 to fetcher#5
2013-08-21 13:37:07,553 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000016_0,attempt_1377090872829_0008_m_000023_0,attempt_1377090872829_0008_m_000027_0 sent hash and received reply
2013-08-21 13:37:07,558 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000016_0 decomp: 13932258 len: 13932262 to MEMORY
2013-08-21 13:37:07,562 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13956178 bytes from map-output for attempt_1377090872829_0008_m_000003_0
2013-08-21 13:37:07,563 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13956178, inMemoryMapOutputs.size() -> 2, commitMemory -> 13978226, usedMemory ->55798400
2013-08-21 13:37:07,568 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#2 in 1017s
2013-08-21 13:37:07,569 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 6 to fetcher#2
2013-08-21 13:37:07,569 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-4:8080 to fetcher#2
2013-08-21 13:37:07,575 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000010_0,attempt_1377090872829_0008_m_000017_0,attempt_1377090872829_0008_m_000019_0,attempt_1377090872829_0008_m_000025_0,attempt_1377090872829_0008_m_000034_0,attempt_1377090872829_0008_m_000038_0 sent hash and received reply
2013-08-21 13:37:07,596 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000010_0 decomp: 13959090 len: 13959094 to MEMORY
2013-08-21 13:37:07,869 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13932258 bytes from map-output for attempt_1377090872829_0008_m_000016_0
2013-08-21 13:37:07,869 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13932258, inMemoryMapOutputs.size() -> 3, commitMemory -> 27934404, usedMemory ->69757490
2013-08-21 13:37:08,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000023_0 decomp: 13902826 len: 13902830 to MEMORY
2013-08-21 13:37:08,158 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000000_0,attempt_1377090872829_0008_m_000005_0,attempt_1377090872829_0008_m_000009_0 sent hash and received reply
2013-08-21 13:37:08,167 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377090872829_0008_m_000000_0 decomp: 13923938 len: 13923942 to MEMORY
2013-08-21 13:37:08,326 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13959090 bytes from map-output for attempt_1377090872829_0008_m_000010_0
2013-08-21 13:37:08,326 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13959090, inMemoryMapOutputs.size() -> 4, commitMemory -> 41866662, usedMemory ->97584254
2013-08-21 13:37:08,330 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000017_0 decomp: 13982490 len: 13982494 to MEMORY
2013-08-21 13:37:08,656 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13982490 bytes from map-output for attempt_1377090872829_0008_m_000017_0
2013-08-21 13:37:08,656 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13982490, inMemoryMapOutputs.size() -> 5, commitMemory -> 55825752, usedMemory ->111566744
2013-08-21 13:37:08,661 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000019_0 decomp: 13925082 len: 13925086 to MEMORY
2013-08-21 13:37:08,727 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000002_0 sent hash and received reply
2013-08-21 13:37:08,837 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377090872829_0008_m_000002_0 decomp: 13948274 len: 13948278 to MEMORY
2013-08-21 13:37:09,063 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13931738 bytes from map-output for attempt_1377090872829_0008_m_000006_0
2013-08-21 13:37:09,063 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13931738, inMemoryMapOutputs.size() -> 6, commitMemory -> 69808242, usedMemory ->139440100
2013-08-21 13:37:09,064 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 2515s
2013-08-21 13:37:09,064 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#1
2013-08-21 13:37:09,064 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#1
2013-08-21 13:37:09,068 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000007_0,attempt_1377090872829_0008_m_000012_0,attempt_1377090872829_0008_m_000020_0,attempt_1377090872829_0008_m_000029_0,attempt_1377090872829_0008_m_000036_0 sent hash and received reply
2013-08-21 13:37:09,069 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-21 13:37:09,070 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 6s
2013-08-21 13:37:09,070 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 9 to fetcher#1
2013-08-21 13:37:09,070 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-999-5:8080 to fetcher#1
2013-08-21 13:37:09,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925082 bytes from map-output for attempt_1377090872829_0008_m_000019_0
2013-08-21 13:37:09,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925082, inMemoryMapOutputs.size() -> 7, commitMemory -> 83739980, usedMemory ->139440100
2013-08-21 13:37:09,075 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97665062 > mergeThreshold=86139864. Current usedMemory=139440100
2013-08-21 13:37:09,076 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 13:37:09,077 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-21 13:37:09,077 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#2 in 1508s
2013-08-21 13:37:09,077 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000004_0,attempt_1377090872829_0008_m_000008_0,attempt_1377090872829_0008_m_000015_0,attempt_1377090872829_0008_m_000014_0,attempt_1377090872829_0008_m_000018_0,attempt_1377090872829_0008_m_000028_0,attempt_1377090872829_0008_m_000032_0,attempt_1377090872829_0008_m_000031_0,attempt_1377090872829_0008_m_000037_0 sent hash and received reply
2013-08-21 13:37:09,078 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-21 13:37:09,078 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#1 in 8s
2013-08-21 13:37:09,363 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 13:37:09,371 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 13:37:09,372 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97664971 bytes
2013-08-21 13:37:10,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13902826 bytes from map-output for attempt_1377090872829_0008_m_000023_0
2013-08-21 13:37:10,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13902826, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139440100
2013-08-21 13:37:10,105 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-21 13:37:10,105 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#5 in 2561s
2013-08-21 13:37:10,924 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377090872829_0008_r_000005_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008/output/attempt_1377090872829_0008_r_000005_1/map_19.out.merged of size 97665054
2013-08-21 13:37:10,924 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 9 to fetcher#5
2013-08-21 13:37:10,925 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#2
2013-08-21 13:37:10,925 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#2
2013-08-21 13:37:10,925 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-999-5:8080 to fetcher#5
2013-08-21 13:37:10,927 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 1 to fetcher#1
2013-08-21 13:37:10,927 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-3:8080 to fetcher#1
2013-08-21 13:37:10,930 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000036_0,attempt_1377090872829_0008_m_000012_0,attempt_1377090872829_0008_m_000029_0,attempt_1377090872829_0008_m_000020_0,attempt_1377090872829_0008_m_000007_0 sent hash and received reply
2013-08-21 13:37:10,931 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000027_0 sent hash and received reply
2013-08-21 13:37:10,931 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000015_0,attempt_1377090872829_0008_m_000032_0,attempt_1377090872829_0008_m_000008_0,attempt_1377090872829_0008_m_000014_0,attempt_1377090872829_0008_m_000018_0,attempt_1377090872829_0008_m_000037_0,attempt_1377090872829_0008_m_000031_0,attempt_1377090872829_0008_m_000028_0,attempt_1377090872829_0008_m_000004_0 sent hash and received reply
2013-08-21 13:37:10,936 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000027_0 decomp: 13924458 len: 13924462 to MEMORY
2013-08-21 13:37:11,032 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000015_0 decomp: 13869754 len: 13869758 to MEMORY
2013-08-21 13:37:11,032 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000036_0 decomp: 13964914 len: 13964918 to MEMORY
2013-08-21 13:37:11,331 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13924458 bytes from map-output for attempt_1377090872829_0008_m_000027_0
2013-08-21 13:37:11,331 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13924458, inMemoryMapOutputs.size() -> 2, commitMemory -> 13902826, usedMemory ->83534164
2013-08-21 13:37:11,334 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13964914 bytes from map-output for attempt_1377090872829_0008_m_000036_0
2013-08-21 13:37:11,349 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13964914, inMemoryMapOutputs.size() -> 3, commitMemory -> 27827284, usedMemory ->83534164
2013-08-21 13:37:11,349 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#1 in 422s
2013-08-21 13:37:11,349 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 3 to fetcher#1
2013-08-21 13:37:11,349 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-4:8080 to fetcher#1
2013-08-21 13:37:11,355 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000012_0 decomp: 13925914 len: 13925918 to MEMORY
2013-08-21 13:37:11,488 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925914 bytes from map-output for attempt_1377090872829_0008_m_000012_0
2013-08-21 13:37:11,488 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925914, inMemoryMapOutputs.size() -> 4, commitMemory -> 41792198, usedMemory ->97460078
2013-08-21 13:37:11,493 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000029_0 decomp: 13939018 len: 13939022 to MEMORY
2013-08-21 13:37:11,632 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13939018 bytes from map-output for attempt_1377090872829_0008_m_000029_0
2013-08-21 13:37:11,633 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13939018, inMemoryMapOutputs.size() -> 5, commitMemory -> 55718112, usedMemory ->111399096
2013-08-21 13:37:11,724 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000020_0 decomp: 14033242 len: 14033246 to MEMORY
2013-08-21 13:37:11,884 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14033242 bytes from map-output for attempt_1377090872829_0008_m_000020_0
2013-08-21 13:37:11,884 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14033242, inMemoryMapOutputs.size() -> 6, commitMemory -> 69657130, usedMemory ->125432338
2013-08-21 13:37:11,888 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000007_0 decomp: 14005890 len: 14005894 to MEMORY
2013-08-21 13:37:12,349 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14005890 bytes from map-output for attempt_1377090872829_0008_m_000007_0
2013-08-21 13:37:12,349 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14005890, inMemoryMapOutputs.size() -> 7, commitMemory -> 83690372, usedMemory ->139438228
2013-08-21 13:37:12,349 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97696262 > mergeThreshold=86139864. Current usedMemory=139438228
2013-08-21 13:37:12,350 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 13:37:12,351 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#2 in 1426s
2013-08-21 13:37:12,627 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 13:37:12,628 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 13:37:12,628 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97696171 bytes
2013-08-21 13:37:14,518 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377090872829_0008_r_000005_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008/output/attempt_1377090872829_0008_r_000005_1/map_23.out.merged of size 97696254
2013-08-21 13:37:15,343 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000038_0,attempt_1377090872829_0008_m_000034_0,attempt_1377090872829_0008_m_000025_0 sent hash and received reply
2013-08-21 13:37:15,405 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000038_0 decomp: 13932154 len: 13932158 to MEMORY
2013-08-21 13:37:15,785 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13923938 bytes from map-output for attempt_1377090872829_0008_m_000000_0
2013-08-21 13:37:15,785 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13923938, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55674120
2013-08-21 13:37:15,789 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377090872829_0008_m_000005_0 decomp: 13987794 len: 13987798 to MEMORY
2013-08-21 13:37:15,837 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13987794 bytes from map-output for attempt_1377090872829_0008_m_000005_0
2013-08-21 13:37:15,837 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13987794, inMemoryMapOutputs.size() -> 2, commitMemory -> 13923938, usedMemory ->69661914
2013-08-21 13:37:15,840 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377090872829_0008_m_000009_0 decomp: 13944218 len: 13944222 to MEMORY
2013-08-21 13:37:15,916 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944218 bytes from map-output for attempt_1377090872829_0008_m_000009_0
2013-08-21 13:37:15,917 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13932154 bytes from map-output for attempt_1377090872829_0008_m_000038_0
2013-08-21 13:37:15,917 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944218, inMemoryMapOutputs.size() -> 3, commitMemory -> 27911732, usedMemory ->83606132
2013-08-21 13:37:15,918 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13932154, inMemoryMapOutputs.size() -> 4, commitMemory -> 41855950, usedMemory ->83606132
2013-08-21 13:37:15,923 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000034_0 decomp: 13933610 len: 13933614 to MEMORY
2013-08-21 13:37:15,923 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#3 in 9372s
2013-08-21 13:37:15,924 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 5 to fetcher#2
2013-08-21 13:37:15,924 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-6:8080 to fetcher#2
2013-08-21 13:37:16,409 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13869754 bytes from map-output for attempt_1377090872829_0008_m_000015_0
2013-08-21 13:37:16,409 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13869754, inMemoryMapOutputs.size() -> 5, commitMemory -> 55788104, usedMemory ->97539742
2013-08-21 13:37:16,769 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000032_0 decomp: 14008074 len: 14008078 to MEMORY
2013-08-21 13:37:17,741 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13933610 bytes from map-output for attempt_1377090872829_0008_m_000034_0
2013-08-21 13:37:17,741 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13933610, inMemoryMapOutputs.size() -> 6, commitMemory -> 69657858, usedMemory ->111547816
2013-08-21 13:37:17,746 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000025_0 decomp: 14011922 len: 14011926 to MEMORY
2013-08-21 13:37:18,289 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14011922 bytes from map-output for attempt_1377090872829_0008_m_000025_0
2013-08-21 13:37:18,289 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14011922, inMemoryMapOutputs.size() -> 7, commitMemory -> 83591468, usedMemory ->125559738
2013-08-21 13:37:18,289 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97603390 > mergeThreshold=86139864. Current usedMemory=125559738
2013-08-21 13:37:18,290 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 13:37:18,291 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#1 in 6942s
2013-08-21 13:37:18,587 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 13:37:18,588 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 13:37:18,588 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97603299 bytes
2013-08-21 13:37:20,064 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377090872829_0008_r_000005_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008/output/attempt_1377090872829_0008_r_000005_1/map_15.out.merged of size 97603382
2013-08-21 13:37:23,100 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13948274 bytes from map-output for attempt_1377090872829_0008_m_000002_0
2013-08-21 13:37:23,101 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13948274, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27956348
2013-08-21 13:37:23,103 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#4 in 16551s
2013-08-21 13:37:23,103 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 5 to fetcher#1
2013-08-21 13:37:23,103 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-7:8080 to fetcher#1
2013-08-21 13:37:26,239 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000011_0,attempt_1377090872829_0008_m_000013_0,attempt_1377090872829_0008_m_000021_0,attempt_1377090872829_0008_m_000026_0,attempt_1377090872829_0008_m_000033_0 sent hash and received reply
2013-08-21 13:37:26,245 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000011_0 decomp: 13978330 len: 13978334 to MEMORY
2013-08-21 13:37:27,583 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14008074 bytes from map-output for attempt_1377090872829_0008_m_000032_0
2013-08-21 13:37:27,583 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14008074, inMemoryMapOutputs.size() -> 2, commitMemory -> 13948274, usedMemory ->41934678
2013-08-21 13:37:27,588 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000008_0 decomp: 13944842 len: 13944846 to MEMORY
2013-08-21 13:37:28,543 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944842 bytes from map-output for attempt_1377090872829_0008_m_000008_0
2013-08-21 13:37:28,544 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944842, inMemoryMapOutputs.size() -> 3, commitMemory -> 27956348, usedMemory ->55879520
2013-08-21 13:37:28,548 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000014_0 decomp: 13965850 len: 13965854 to MEMORY
2013-08-21 13:37:30,820 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000022_0,attempt_1377090872829_0008_m_000024_0,attempt_1377090872829_0008_m_000030_0,attempt_1377090872829_0008_m_000035_0,attempt_1377090872829_0008_m_000039_0 sent hash and received reply
2013-08-21 13:37:30,926 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000022_0 decomp: 13942970 len: 13942974 to MEMORY
2013-08-21 13:37:34,981 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13965850 bytes from map-output for attempt_1377090872829_0008_m_000014_0
2013-08-21 13:37:34,981 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13965850, inMemoryMapOutputs.size() -> 4, commitMemory -> 41901190, usedMemory ->83788340
2013-08-21 13:37:34,986 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000018_0 decomp: 13939018 len: 13939022 to MEMORY
2013-08-21 13:37:35,544 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13939018 bytes from map-output for attempt_1377090872829_0008_m_000018_0
2013-08-21 13:37:35,544 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13939018, inMemoryMapOutputs.size() -> 5, commitMemory -> 55867040, usedMemory ->97727358
2013-08-21 13:37:35,549 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000037_0 decomp: 13940578 len: 13940582 to MEMORY
2013-08-21 13:37:36,027 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13940578 bytes from map-output for attempt_1377090872829_0008_m_000037_0
2013-08-21 13:37:36,027 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13940578, inMemoryMapOutputs.size() -> 6, commitMemory -> 69806058, usedMemory ->111667936
2013-08-21 13:37:36,172 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000031_0 decomp: 13976458 len: 13976462 to MEMORY
2013-08-21 13:37:36,370 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976458 bytes from map-output for attempt_1377090872829_0008_m_000031_0
2013-08-21 13:37:36,370 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976458, inMemoryMapOutputs.size() -> 7, commitMemory -> 83746636, usedMemory ->125644394
2013-08-21 13:37:36,370 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97723094 > mergeThreshold=86139864. Current usedMemory=125644394
2013-08-21 13:37:36,370 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 13:37:36,376 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000028_0 decomp: 13895546 len: 13895550 to MEMORY
2013-08-21 13:37:36,576 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 13:37:36,577 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 13:37:36,577 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97723003 bytes
2013-08-21 13:37:36,604 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13895546 bytes from map-output for attempt_1377090872829_0008_m_000028_0
2013-08-21 13:37:36,607 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13895546, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139539940
2013-08-21 13:37:36,607 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-21 13:37:36,608 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#5 in 25684s
2013-08-21 13:37:36,608 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#4
2013-08-21 13:37:36,608 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#4
2013-08-21 13:37:36,618 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000004_0 sent hash and received reply
2013-08-21 13:37:36,622 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-21 13:37:36,623 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#4 in 15s
2013-08-21 13:37:36,623 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#3
2013-08-21 13:37:36,623 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#3
2013-08-21 13:37:36,634 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000004_0 sent hash and received reply
2013-08-21 13:37:36,638 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-21 13:37:36,639 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#3 in 16s
2013-08-21 13:37:38,217 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377090872829_0008_r_000005_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008/output/attempt_1377090872829_0008_r_000005_1/map_18.out.merged of size 97723086
2013-08-21 13:37:38,217 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#3
2013-08-21 13:37:38,218 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#3
2013-08-21 13:37:38,228 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000004_0 sent hash and received reply
2013-08-21 13:37:38,344 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377090872829_0008_m_000004_0 decomp: 13967722 len: 13967726 to MEMORY
2013-08-21 13:37:39,151 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13967722 bytes from map-output for attempt_1377090872829_0008_m_000004_0
2013-08-21 13:37:39,151 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13967722, inMemoryMapOutputs.size() -> 2, commitMemory -> 13895546, usedMemory ->55784568
2013-08-21 13:37:39,151 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#3 in 934s
2013-08-21 13:37:41,287 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13942970 bytes from map-output for attempt_1377090872829_0008_m_000022_0
2013-08-21 13:37:41,288 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13942970, inMemoryMapOutputs.size() -> 3, commitMemory -> 27863268, usedMemory ->55784568
2013-08-21 13:37:41,292 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000024_0 decomp: 13968658 len: 13968662 to MEMORY
2013-08-21 13:37:41,346 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13968658 bytes from map-output for attempt_1377090872829_0008_m_000024_0
2013-08-21 13:37:41,346 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13968658, inMemoryMapOutputs.size() -> 4, commitMemory -> 41806238, usedMemory ->69753226
2013-08-21 13:37:41,350 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000030_0 decomp: 13938394 len: 13938398 to MEMORY
2013-08-21 13:37:41,396 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13938394 bytes from map-output for attempt_1377090872829_0008_m_000030_0
2013-08-21 13:37:41,397 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13938394, inMemoryMapOutputs.size() -> 5, commitMemory -> 55774896, usedMemory ->83691620
2013-08-21 13:37:41,524 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000035_0 decomp: 13969802 len: 13969806 to MEMORY
2013-08-21 13:37:51,322 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13978330 bytes from map-output for attempt_1377090872829_0008_m_000011_0
2013-08-21 13:37:51,322 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13978330, inMemoryMapOutputs.size() -> 6, commitMemory -> 69713290, usedMemory ->97661422
2013-08-21 13:37:51,327 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000013_0 decomp: 13906986 len: 13906990 to MEMORY
2013-08-21 13:37:51,410 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13906986 bytes from map-output for attempt_1377090872829_0008_m_000013_0
2013-08-21 13:37:51,410 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13906986, inMemoryMapOutputs.size() -> 7, commitMemory -> 83691620, usedMemory ->111568408
2013-08-21 13:37:51,410 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97598606 > mergeThreshold=86139864. Current usedMemory=111568408
2013-08-21 13:37:51,411 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-21 13:37:51,417 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000021_0 decomp: 13984154 len: 13984158 to MEMORY
2013-08-21 13:37:51,689 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13984154 bytes from map-output for attempt_1377090872829_0008_m_000021_0
2013-08-21 13:37:51,690 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13984154, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->125552562
2013-08-21 13:37:51,694 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377090872829_0008_m_000026_0 decomp: 13982282 len: 13982286 to MEMORY
2013-08-21 13:37:51,770 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13982282 bytes from map-output for attempt_1377090872829_0008_m_000026_0
2013-08-21 13:37:51,771 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13982282, inMemoryMapOutputs.size() -> 2, commitMemory -> 13984154, usedMemory ->139534844
2013-08-21 13:37:51,771 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-21 13:37:51,772 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#2 in 35848s
2013-08-21 13:37:51,772 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 1 to fetcher#3
2013-08-21 13:37:51,772 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-6:8080 to fetcher#3
2013-08-21 13:37:51,781 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000033_0 sent hash and received reply
2013-08-21 13:37:51,781 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-21 13:37:51,781 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#3 in 9s
2013-08-21 13:37:51,782 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 1 to fetcher#4
2013-08-21 13:37:51,782 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-6:8080 to fetcher#4
2013-08-21 13:37:51,789 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000033_0 sent hash and received reply
2013-08-21 13:37:51,789 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-21 13:37:51,790 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#4 in 8s
2013-08-21 13:37:51,790 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 1 to fetcher#5
2013-08-21 13:37:51,790 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-6:8080 to fetcher#5
2013-08-21 13:37:51,795 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000033_0 sent hash and received reply
2013-08-21 13:37:51,796 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-21 13:37:51,796 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#5 in 6s
2013-08-21 13:37:51,884 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-21 13:37:51,884 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-21 13:37:51,885 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97598515 bytes
2013-08-21 13:37:54,553 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377090872829_0008_r_000005_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377090872829_0008/output/attempt_1377090872829_0008_r_000005_1/map_28.out.merged of size 97598598
2013-08-21 13:37:54,554 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 1 to fetcher#5
2013-08-21 13:37:54,554 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-6:8080 to fetcher#5
2013-08-21 13:37:54,559 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377090872829_0008&reduce=5&map=attempt_1377090872829_0008_m_000033_0 sent hash and received reply
2013-08-21 13:37:54,564 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377090872829_0008_m_000033_0 decomp: 13995594 len: 13995598 to MEMORY
2013-08-21 13:38:02,805 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13995594 bytes from map-output for attempt_1377090872829_0008_m_000033_0
2013-08-21 13:38:02,805 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13995594, inMemoryMapOutputs.size() -> 3, commitMemory -> 27966436, usedMemory ->55931832
2013-08-21 13:38:02,806 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#5 in 8252s
2013-08-21 13:38:03,477 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13969802 bytes from map-output for attempt_1377090872829_0008_m_000035_0
2013-08-21 13:38:03,477 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13969802, inMemoryMapOutputs.size() -> 4, commitMemory -> 41962030, usedMemory ->55931832
2013-08-21 13:38:03,481 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377090872829_0008_m_000039_0 decomp: 13914370 len: 13914374 to MEMORY
2013-08-21 13:38:06,621 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13914370 bytes from map-output for attempt_1377090872829_0008_m_000039_0
2013-08-21 13:38:06,621 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13914370, inMemoryMapOutputs.size() -> 5, commitMemory -> 55931832, usedMemory ->69846202
2013-08-21 13:38:06,621 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#1 in 43518s
2013-08-21 13:38:06,622 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-21 13:38:06,635 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-21 13:38:06,817 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-21 13:38:06,818 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69846137 bytes
2013-08-21 13:38:08,011 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69846202 bytes to disk to satisfy reduce memory limit
2013-08-21 13:38:08,016 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 558132572 bytes from disk
2013-08-21 13:38:08,018 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-21 13:38:08,019 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-21 13:38:08,028 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 558132470 bytes
2013-08-21 13:38:08,237 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-21 13:38:24,293 WARN [DataStreamer for file /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005] org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005: File does not exist. Holder DFSClient_attempt_1377090872829_0008_r_000005_1_-2078154767_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)
2013-08-21 13:38:24,294 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005: File does not exist. Holder DFSClient_attempt_1377090872829_0008_r_000005_1_-2078154767_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)
2013-08-21 13:38:24,295 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005: File does not exist. Holder DFSClient_attempt_1377090872829_0008_r_000005_1_-2078154767_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

2013-08-21 13:38:24,297 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377090872829_0008_r_000005_1/part-r-00005: File does not exist. Holder DFSClient_attempt_1377090872829_0008_r_000005_1_-2078154767_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2298)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2212)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:498)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40979)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:315)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1178)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1031)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:482)

