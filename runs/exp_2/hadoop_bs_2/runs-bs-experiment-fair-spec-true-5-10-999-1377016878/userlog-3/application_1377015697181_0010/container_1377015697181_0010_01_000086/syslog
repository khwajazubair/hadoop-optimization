2013-08-20 16:39:50,944 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-20 16:39:50,977 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-20 16:39:51,104 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-20 16:39:51,203 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-20 16:39:51,203 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-20 16:39:51,215 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-20 16:39:51,215 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377015697181_0010, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-20 16:39:51,286 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-20 16:39:52,099 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010
2013-08-20 16:39:52,441 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-20 16:39:52,441 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-20 16:39:52,442 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-20 16:39:52,442 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-20 16:39:52,443 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-20 16:39:52,443 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-20 16:39:52,444 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-20 16:39:52,444 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-20 16:39:52,444 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-20 16:39:52,629 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-20 16:39:52,929 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-20 16:39:53,076 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a6b22fa
2013-08-20 16:39:53,127 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-20 16:39:53,149 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377015697181_0010_r_000006_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-20 16:39:53,162 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 1 to fetcher#2
2013-08-20 16:39:53,163 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-4:8080 to fetcher#2
2013-08-20 16:39:53,172 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377015697181_0010_r_000006_1: Got 40 new map-outputs
2013-08-20 16:39:53,172 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 6 to fetcher#5
2013-08-20 16:39:53,173 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 6 to fetcher#3
2013-08-20 16:39:53,173 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-5:8080 to fetcher#3
2013-08-20 16:39:53,175 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-7:8080 to fetcher#5
2013-08-20 16:39:53,183 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 8 to fetcher#4
2013-08-20 16:39:53,183 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 8 to fetcher#1
2013-08-20 16:39:53,183 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-999-6:8080 to fetcher#1
2013-08-20 16:39:53,185 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-999-3:8080 to fetcher#4
2013-08-20 16:39:53,401 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000006_0,attempt_1377015697181_0010_m_000000_0,attempt_1377015697181_0010_m_000012_0,attempt_1377015697181_0010_m_000022_0,attempt_1377015697181_0010_m_000024_0,attempt_1377015697181_0010_m_000028_0,attempt_1377015697181_0010_m_000034_0,attempt_1377015697181_0010_m_000035_0 sent hash and received reply
2013-08-20 16:39:53,402 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000002_0 sent hash and received reply
2013-08-20 16:39:53,403 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000004_0,attempt_1377015697181_0010_m_000014_0,attempt_1377015697181_0010_m_000018_0,attempt_1377015697181_0010_m_000027_0,attempt_1377015697181_0010_m_000029_0,attempt_1377015697181_0010_m_000036_0 sent hash and received reply
2013-08-20 16:39:53,403 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000003_0,attempt_1377015697181_0010_m_000008_0,attempt_1377015697181_0010_m_000009_0,attempt_1377015697181_0010_m_000015_0,attempt_1377015697181_0010_m_000017_0,attempt_1377015697181_0010_m_000023_0,attempt_1377015697181_0010_m_000031_0,attempt_1377015697181_0010_m_000032_0 sent hash and received reply
2013-08-20 16:39:53,409 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000002_0 decomp: 13993098 len: 13993102 to MEMORY
2013-08-20 16:39:53,450 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000004_0 decomp: 13941930 len: 13941934 to MEMORY
2013-08-20 16:39:53,454 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000003_0 decomp: 13930386 len: 13930390 to MEMORY
2013-08-20 16:39:53,459 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000006_0 decomp: 14055706 len: 14055710 to MEMORY
2013-08-20 16:39:53,459 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000010_0,attempt_1377015697181_0010_m_000019_0,attempt_1377015697181_0010_m_000026_0,attempt_1377015697181_0010_m_000030_0,attempt_1377015697181_0010_m_000033_0,attempt_1377015697181_0010_m_000037_0 sent hash and received reply
2013-08-20 16:39:53,481 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377015697181_0010_m_000010_0 decomp: 14001730 len: 14001734 to MEMORY
2013-08-20 16:39:53,690 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14055706 bytes from map-output for attempt_1377015697181_0010_m_000006_0
2013-08-20 16:39:53,691 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14055706, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->69922850
2013-08-20 16:39:53,898 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000000_0 decomp: 13974378 len: 13974382 to MEMORY
2013-08-20 16:39:53,937 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13974378 bytes from map-output for attempt_1377015697181_0010_m_000000_0
2013-08-20 16:39:53,937 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13974378, inMemoryMapOutputs.size() -> 2, commitMemory -> 14055706, usedMemory ->83897228
2013-08-20 16:39:53,941 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000012_0 decomp: 14028770 len: 14028774 to MEMORY
2013-08-20 16:39:53,978 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14028770 bytes from map-output for attempt_1377015697181_0010_m_000012_0
2013-08-20 16:39:53,978 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14028770, inMemoryMapOutputs.size() -> 3, commitMemory -> 28030084, usedMemory ->97925998
2013-08-20 16:39:53,981 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000022_0 decomp: 14013066 len: 14013070 to MEMORY
2013-08-20 16:39:54,020 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14013066 bytes from map-output for attempt_1377015697181_0010_m_000022_0
2013-08-20 16:39:54,020 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14013066, inMemoryMapOutputs.size() -> 4, commitMemory -> 42058854, usedMemory ->111939064
2013-08-20 16:39:54,023 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000024_0 decomp: 14013274 len: 14013278 to MEMORY
2013-08-20 16:39:54,058 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14013274 bytes from map-output for attempt_1377015697181_0010_m_000024_0
2013-08-20 16:39:54,059 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14013274, inMemoryMapOutputs.size() -> 5, commitMemory -> 56071920, usedMemory ->125952338
2013-08-20 16:39:54,204 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000028_0 decomp: 14040106 len: 14040110 to MEMORY
2013-08-20 16:39:54,200 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13941930 bytes from map-output for attempt_1377015697181_0010_m_000004_0
2013-08-20 16:39:54,204 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13941930, inMemoryMapOutputs.size() -> 6, commitMemory -> 70085194, usedMemory ->139992444
2013-08-20 16:39:54,205 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 16:39:54,206 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#5 in 1033s
2013-08-20 16:39:54,206 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#5
2013-08-20 16:39:54,206 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#5
2013-08-20 16:39:54,212 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000013_0,attempt_1377015697181_0010_m_000020_0,attempt_1377015697181_0010_m_000025_0,attempt_1377015697181_0010_m_000038_0,attempt_1377015697181_0010_m_000039_0 sent hash and received reply
2013-08-20 16:39:54,212 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 16:39:54,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#5 in 7s
2013-08-20 16:39:54,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 5 to fetcher#5
2013-08-20 16:39:54,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-7:8080 to fetcher#5
2013-08-20 16:39:54,215 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13993098 bytes from map-output for attempt_1377015697181_0010_m_000002_0
2013-08-20 16:39:54,215 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13993098, inMemoryMapOutputs.size() -> 7, commitMemory -> 84027124, usedMemory ->139992444
2013-08-20 16:39:54,215 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=98020222 > mergeThreshold=86139864. Current usedMemory=139992444
2013-08-20 16:39:54,216 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 16:39:54,216 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#2 in 1053s
2013-08-20 16:39:54,219 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000018_0,attempt_1377015697181_0010_m_000014_0,attempt_1377015697181_0010_m_000027_0,attempt_1377015697181_0010_m_000036_0,attempt_1377015697181_0010_m_000029_0 sent hash and received reply
2013-08-20 16:39:54,219 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 16:39:54,219 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#5 in 6s
2013-08-20 16:39:54,249 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14040106 bytes from map-output for attempt_1377015697181_0010_m_000028_0
2013-08-20 16:39:54,249 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14040106, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139992444
2013-08-20 16:39:54,249 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:54,250 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#4 in 1067s
2013-08-20 16:39:54,546 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 16:39:54,553 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 16:39:54,554 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 98020131 bytes
2013-08-20 16:39:55,127 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930386 bytes from map-output for attempt_1377015697181_0010_m_000003_0
2013-08-20 16:39:55,128 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930386, inMemoryMapOutputs.size() -> 2, commitMemory -> 14040106, usedMemory ->139992444
2013-08-20 16:39:55,129 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-20 16:39:55,130 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#1 in 1947s
2013-08-20 16:39:56,210 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377015697181_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010/output/attempt_1377015697181_0010_r_000006_1/map_4.out.merged of size 98020214
2013-08-20 16:39:56,210 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#1
2013-08-20 16:39:56,210 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#1
2013-08-20 16:39:56,211 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 7 to fetcher#2
2013-08-20 16:39:56,211 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-999-6:8080 to fetcher#2
2013-08-20 16:39:56,212 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 6 to fetcher#4
2013-08-20 16:39:56,212 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-4:8080 to fetcher#4
2013-08-20 16:39:56,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 5 to fetcher#5
2013-08-20 16:39:56,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-7:8080 to fetcher#5
2013-08-20 16:39:56,216 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000001_0,attempt_1377015697181_0010_m_000007_0,attempt_1377015697181_0010_m_000005_0,attempt_1377015697181_0010_m_000011_0,attempt_1377015697181_0010_m_000016_0,attempt_1377015697181_0010_m_000021_0 sent hash and received reply
2013-08-20 16:39:56,217 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000018_0,attempt_1377015697181_0010_m_000014_0,attempt_1377015697181_0010_m_000027_0,attempt_1377015697181_0010_m_000036_0,attempt_1377015697181_0010_m_000029_0 sent hash and received reply
2013-08-20 16:39:56,217 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000031_0,attempt_1377015697181_0010_m_000008_0,attempt_1377015697181_0010_m_000015_0,attempt_1377015697181_0010_m_000017_0,attempt_1377015697181_0010_m_000009_0,attempt_1377015697181_0010_m_000023_0,attempt_1377015697181_0010_m_000032_0 sent hash and received reply
2013-08-20 16:39:56,219 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000001_0 decomp: 13957114 len: 13957118 to MEMORY
2013-08-20 16:39:56,305 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000039_0,attempt_1377015697181_0010_m_000020_0,attempt_1377015697181_0010_m_000038_0,attempt_1377015697181_0010_m_000025_0,attempt_1377015697181_0010_m_000013_0 sent hash and received reply
2013-08-20 16:39:56,315 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000031_0 decomp: 14022322 len: 14022326 to MEMORY
2013-08-20 16:39:56,318 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000018_0 decomp: 14039378 len: 14039382 to MEMORY
2013-08-20 16:39:56,319 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000039_0 decomp: 14064130 len: 14064134 to MEMORY
2013-08-20 16:39:56,655 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13957114 bytes from map-output for attempt_1377015697181_0010_m_000001_0
2013-08-20 16:39:56,655 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13957114, inMemoryMapOutputs.size() -> 3, commitMemory -> 27970492, usedMemory ->98055166
2013-08-20 16:39:56,662 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000007_0 decomp: 13994138 len: 13994142 to MEMORY
2013-08-20 16:39:56,689 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14039378 bytes from map-output for attempt_1377015697181_0010_m_000018_0
2013-08-20 16:39:56,690 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14039378, inMemoryMapOutputs.size() -> 4, commitMemory -> 41927606, usedMemory ->112049304
2013-08-20 16:39:56,747 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000014_0 decomp: 14022842 len: 14022846 to MEMORY
2013-08-20 16:39:56,886 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14064130 bytes from map-output for attempt_1377015697181_0010_m_000039_0
2013-08-20 16:39:56,887 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14064130, inMemoryMapOutputs.size() -> 5, commitMemory -> 55966984, usedMemory ->126072146
2013-08-20 16:39:56,896 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000020_0 decomp: 14021386 len: 14021390 to MEMORY
2013-08-20 16:39:57,080 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13994138 bytes from map-output for attempt_1377015697181_0010_m_000007_0
2013-08-20 16:39:57,080 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13994138, inMemoryMapOutputs.size() -> 6, commitMemory -> 70031114, usedMemory ->140093532
2013-08-20 16:39:57,081 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,082 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#4 in 870s
2013-08-20 16:39:57,082 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 2 to fetcher#4
2013-08-20 16:39:57,082 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-3:8080 to fetcher#4
2013-08-20 16:39:57,086 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000034_0,attempt_1377015697181_0010_m_000035_0 sent hash and received reply
2013-08-20 16:39:57,087 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,087 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#4 in 5s
2013-08-20 16:39:57,088 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 2 to fetcher#4
2013-08-20 16:39:57,088 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-3:8080 to fetcher#4
2013-08-20 16:39:57,094 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000034_0,attempt_1377015697181_0010_m_000035_0 sent hash and received reply
2013-08-20 16:39:57,094 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,094 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#4 in 6s
2013-08-20 16:39:57,095 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 4 to fetcher#4
2013-08-20 16:39:57,095 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-999-4:8080 to fetcher#4
2013-08-20 16:39:57,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14022842 bytes from map-output for attempt_1377015697181_0010_m_000014_0
2013-08-20 16:39:57,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14022842, inMemoryMapOutputs.size() -> 7, commitMemory -> 84025252, usedMemory ->140093532
2013-08-20 16:39:57,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=98048094 > mergeThreshold=86139864. Current usedMemory=140093532
2013-08-20 16:39:57,098 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 16:39:57,110 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000021_0,attempt_1377015697181_0010_m_000011_0,attempt_1377015697181_0010_m_000005_0,attempt_1377015697181_0010_m_000016_0 sent hash and received reply
2013-08-20 16:39:57,111 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,111 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#5 in 898s
2013-08-20 16:39:57,111 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,112 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#4 in 17s
2013-08-20 16:39:57,257 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14021386 bytes from map-output for attempt_1377015697181_0010_m_000020_0
2013-08-20 16:39:57,257 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14021386, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140093532
2013-08-20 16:39:57,257 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-20 16:39:57,258 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 1048s
2013-08-20 16:39:57,320 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 16:39:57,321 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 16:39:57,321 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 98048003 bytes
2013-08-20 16:39:58,124 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14001730 bytes from map-output for attempt_1377015697181_0010_m_000010_0
2013-08-20 16:39:58,456 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14001730, inMemoryMapOutputs.size() -> 2, commitMemory -> 14021386, usedMemory ->140093532
2013-08-20 16:39:58,457 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-20 16:39:58,457 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#3 in 5284s
2013-08-20 16:39:58,537 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14022322 bytes from map-output for attempt_1377015697181_0010_m_000031_0
2013-08-20 16:39:58,537 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14022322, inMemoryMapOutputs.size() -> 3, commitMemory -> 28023116, usedMemory ->140093532
2013-08-20 16:39:58,539 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-20 16:39:58,540 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#2 in 2329s
2013-08-20 16:39:58,838 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377015697181_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010/output/attempt_1377015697181_0010_r_000006_1/map_3.out.merged of size 98048086
2013-08-20 16:39:58,838 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 2 to fetcher#3
2013-08-20 16:39:58,838 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-3:8080 to fetcher#3
2013-08-20 16:39:58,840 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 5 to fetcher#1
2013-08-20 16:39:58,840 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-5:8080 to fetcher#1
2013-08-20 16:39:58,840 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 3 to fetcher#4
2013-08-20 16:39:58,841 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-7:8080 to fetcher#4
2013-08-20 16:39:58,841 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 4 to fetcher#2
2013-08-20 16:39:58,842 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-999-4:8080 to fetcher#2
2013-08-20 16:39:58,842 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 3 to fetcher#5
2013-08-20 16:39:58,842 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-2:8080 to fetcher#5
2013-08-20 16:39:58,843 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000034_0,attempt_1377015697181_0010_m_000035_0 sent hash and received reply
2013-08-20 16:39:58,913 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000027_0,attempt_1377015697181_0010_m_000036_0,attempt_1377015697181_0010_m_000029_0 sent hash and received reply
2013-08-20 16:39:58,915 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000038_0,attempt_1377015697181_0010_m_000013_0,attempt_1377015697181_0010_m_000025_0 sent hash and received reply
2013-08-20 16:39:58,916 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000021_0,attempt_1377015697181_0010_m_000011_0,attempt_1377015697181_0010_m_000005_0,attempt_1377015697181_0010_m_000016_0 sent hash and received reply
2013-08-20 16:39:58,917 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377015697181_0010_m_000034_0 decomp: 14016914 len: 14016918 to MEMORY
2013-08-20 16:39:58,921 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000021_0 decomp: 14016290 len: 14016294 to MEMORY
2013-08-20 16:39:58,926 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000038_0 decomp: 14045930 len: 14045934 to MEMORY
2013-08-20 16:39:59,024 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000027_0 decomp: 13961274 len: 13961278 to MEMORY
2013-08-20 16:39:59,361 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13961274 bytes from map-output for attempt_1377015697181_0010_m_000027_0
2013-08-20 16:39:59,362 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13961274, inMemoryMapOutputs.size() -> 4, commitMemory -> 42045438, usedMemory ->98085846
2013-08-20 16:39:59,373 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14016290 bytes from map-output for attempt_1377015697181_0010_m_000021_0
2013-08-20 16:39:59,373 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14016290, inMemoryMapOutputs.size() -> 5, commitMemory -> 56006712, usedMemory ->112144672
2013-08-20 16:39:59,374 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000036_0 decomp: 14058826 len: 14058830 to MEMORY
2013-08-20 16:39:59,377 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000011_0 decomp: 14007970 len: 14007974 to MEMORY
2013-08-20 16:39:59,566 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14007970 bytes from map-output for attempt_1377015697181_0010_m_000011_0
2013-08-20 16:39:59,566 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14007970, inMemoryMapOutputs.size() -> 6, commitMemory -> 70023002, usedMemory ->126152642
2013-08-20 16:39:59,663 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000005_0 decomp: 14006098 len: 14006102 to MEMORY
2013-08-20 16:39:59,824 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14045930 bytes from map-output for attempt_1377015697181_0010_m_000038_0
2013-08-20 16:39:59,825 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14045930, inMemoryMapOutputs.size() -> 7, commitMemory -> 84030972, usedMemory ->140158740
2013-08-20 16:39:59,825 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=98076902 > mergeThreshold=86139864. Current usedMemory=140158740
2013-08-20 16:39:59,825 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 16:39:59,826 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 16:39:59,826 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#5 in 984s
2013-08-20 16:39:59,849 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14006098 bytes from map-output for attempt_1377015697181_0010_m_000005_0
2013-08-20 16:39:59,849 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14006098, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140158740
2013-08-20 16:39:59,851 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-20 16:39:59,852 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#2 in 1011s
2013-08-20 16:39:59,884 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14058826 bytes from map-output for attempt_1377015697181_0010_m_000036_0
2013-08-20 16:39:59,884 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14058826, inMemoryMapOutputs.size() -> 2, commitMemory -> 14006098, usedMemory ->140158740
2013-08-20 16:39:59,885 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 16:39:59,885 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#4 in 1045s
2013-08-20 16:40:00,045 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 16:40:00,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 16:40:00,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 98076811 bytes
2013-08-20 16:40:00,058 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14016914 bytes from map-output for attempt_1377015697181_0010_m_000034_0
2013-08-20 16:40:00,058 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14016914, inMemoryMapOutputs.size() -> 3, commitMemory -> 28064924, usedMemory ->140158740
2013-08-20 16:40:00,059 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-20 16:40:00,059 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#3 in 1221s
2013-08-20 16:40:01,726 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377015697181_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010/output/attempt_1377015697181_0010_r_000006_1/map_27.out.merged of size 98076894
2013-08-20 16:40:01,726 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 1 to fetcher#3
2013-08-20 16:40:01,727 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-7:8080 to fetcher#3
2013-08-20 16:40:01,728 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 1 to fetcher#4
2013-08-20 16:40:01,728 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-4:8080 to fetcher#4
2013-08-20 16:40:01,729 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 1 to fetcher#2
2013-08-20 16:40:01,729 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-3:8080 to fetcher#2
2013-08-20 16:40:01,729 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 2 to fetcher#5
2013-08-20 16:40:01,729 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-2:8080 to fetcher#5
2013-08-20 16:40:01,732 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000029_0 sent hash and received reply
2013-08-20 16:40:01,733 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000016_0 sent hash and received reply
2013-08-20 16:40:01,734 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000035_0 sent hash and received reply
2013-08-20 16:40:01,734 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000025_0,attempt_1377015697181_0010_m_000013_0 sent hash and received reply
2013-08-20 16:40:01,736 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377015697181_0010_m_000029_0 decomp: 13931634 len: 13931638 to MEMORY
2013-08-20 16:40:01,817 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000025_0 decomp: 13946610 len: 13946614 to MEMORY
2013-08-20 16:40:01,821 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000035_0 decomp: 14060282 len: 14060286 to MEMORY
2013-08-20 16:40:01,824 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377015697181_0010_m_000016_0 decomp: 14052586 len: 14052590 to MEMORY
2013-08-20 16:40:01,938 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14060282 bytes from map-output for attempt_1377015697181_0010_m_000035_0
2013-08-20 16:40:01,938 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14060282, inMemoryMapOutputs.size() -> 4, commitMemory -> 42081838, usedMemory ->98072950
2013-08-20 16:40:01,939 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#2 in 210s
2013-08-20 16:40:01,939 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 6 to fetcher#2
2013-08-20 16:40:01,939 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-6:8080 to fetcher#2
2013-08-20 16:40:01,950 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000008_0,attempt_1377015697181_0010_m_000015_0,attempt_1377015697181_0010_m_000017_0,attempt_1377015697181_0010_m_000009_0,attempt_1377015697181_0010_m_000023_0,attempt_1377015697181_0010_m_000032_0 sent hash and received reply
2013-08-20 16:40:02,057 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000008_0 decomp: 13996530 len: 13996534 to MEMORY
2013-08-20 16:40:02,210 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13931634 bytes from map-output for attempt_1377015697181_0010_m_000029_0
2013-08-20 16:40:02,210 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13931634, inMemoryMapOutputs.size() -> 5, commitMemory -> 56142120, usedMemory ->112069480
2013-08-20 16:40:02,210 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#3 in 483s
2013-08-20 16:40:02,316 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13946610 bytes from map-output for attempt_1377015697181_0010_m_000025_0
2013-08-20 16:40:02,317 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13946610, inMemoryMapOutputs.size() -> 6, commitMemory -> 70073754, usedMemory ->112069480
2013-08-20 16:40:02,321 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377015697181_0010_m_000013_0 decomp: 13952018 len: 13952022 to MEMORY
2013-08-20 16:40:02,416 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14052586 bytes from map-output for attempt_1377015697181_0010_m_000016_0
2013-08-20 16:40:02,416 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14052586, inMemoryMapOutputs.size() -> 7, commitMemory -> 84020364, usedMemory ->126021498
2013-08-20 16:40:02,416 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=98072950 > mergeThreshold=86139864. Current usedMemory=126021498
2013-08-20 16:40:02,416 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 16:40:02,417 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#4 in 689s
2013-08-20 16:40:02,553 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13952018 bytes from map-output for attempt_1377015697181_0010_m_000013_0
2013-08-20 16:40:02,553 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13952018, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->126021498
2013-08-20 16:40:02,554 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#5 in 825s
2013-08-20 16:40:02,653 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 16:40:02,653 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 16:40:02,653 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 98072859 bytes
2013-08-20 16:40:03,822 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377015697181_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010/output/attempt_1377015697181_0010_r_000006_1/map_29.out.merged of size 98072942
2013-08-20 16:40:04,397 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13996530 bytes from map-output for attempt_1377015697181_0010_m_000008_0
2013-08-20 16:40:04,397 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13996530, inMemoryMapOutputs.size() -> 2, commitMemory -> 13952018, usedMemory ->27948548
2013-08-20 16:40:04,482 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000015_0 decomp: 13971570 len: 13971574 to MEMORY
2013-08-20 16:40:04,917 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13971570 bytes from map-output for attempt_1377015697181_0010_m_000015_0
2013-08-20 16:40:04,917 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13971570, inMemoryMapOutputs.size() -> 3, commitMemory -> 27948548, usedMemory ->41920118
2013-08-20 16:40:04,922 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000017_0 decomp: 13989978 len: 13989982 to MEMORY
2013-08-20 16:40:05,469 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13989978 bytes from map-output for attempt_1377015697181_0010_m_000017_0
2013-08-20 16:40:05,469 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13989978, inMemoryMapOutputs.size() -> 4, commitMemory -> 41920118, usedMemory ->55910096
2013-08-20 16:40:05,473 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000009_0 decomp: 14005370 len: 14005374 to MEMORY
2013-08-20 16:40:05,973 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14005370 bytes from map-output for attempt_1377015697181_0010_m_000009_0
2013-08-20 16:40:05,974 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14005370, inMemoryMapOutputs.size() -> 5, commitMemory -> 55910096, usedMemory ->69915466
2013-08-20 16:40:06,062 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000023_0 decomp: 14016394 len: 14016398 to MEMORY
2013-08-20 16:40:06,377 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14016394 bytes from map-output for attempt_1377015697181_0010_m_000023_0
2013-08-20 16:40:06,377 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14016394, inMemoryMapOutputs.size() -> 6, commitMemory -> 69915466, usedMemory ->83931860
2013-08-20 16:40:06,383 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377015697181_0010_m_000032_0 decomp: 14002562 len: 14002566 to MEMORY
2013-08-20 16:40:07,003 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14002562 bytes from map-output for attempt_1377015697181_0010_m_000032_0
2013-08-20 16:40:07,003 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14002562, inMemoryMapOutputs.size() -> 7, commitMemory -> 83931860, usedMemory ->97934422
2013-08-20 16:40:07,004 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97934422 > mergeThreshold=86139864. Current usedMemory=97934422
2013-08-20 16:40:07,004 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 16:40:07,006 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#2 in 5067s
2013-08-20 16:40:07,202 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 16:40:07,203 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 16:40:07,203 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97934331 bytes
2013-08-20 16:40:08,454 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377015697181_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377015697181_0010/output/attempt_1377015697181_0010_r_000006_1/map_13.out.merged of size 97934414
2013-08-20 16:40:08,976 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377015697181_0010&reduce=6&map=attempt_1377015697181_0010_m_000037_0,attempt_1377015697181_0010_m_000033_0,attempt_1377015697181_0010_m_000030_0,attempt_1377015697181_0010_m_000026_0,attempt_1377015697181_0010_m_000019_0 sent hash and received reply
2013-08-20 16:40:09,082 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000037_0 decomp: 14036154 len: 14036158 to MEMORY
2013-08-20 16:40:29,980 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14036154 bytes from map-output for attempt_1377015697181_0010_m_000037_0
2013-08-20 16:40:29,980 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14036154, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14036154
2013-08-20 16:40:29,984 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000033_0 decomp: 14000586 len: 14000590 to MEMORY
2013-08-20 16:40:30,143 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14000586 bytes from map-output for attempt_1377015697181_0010_m_000033_0
2013-08-20 16:40:30,144 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14000586, inMemoryMapOutputs.size() -> 2, commitMemory -> 14036154, usedMemory ->28036740
2013-08-20 16:40:30,261 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000030_0 decomp: 13960650 len: 13960654 to MEMORY
2013-08-20 16:40:32,394 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960650 bytes from map-output for attempt_1377015697181_0010_m_000030_0
2013-08-20 16:40:32,394 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960650, inMemoryMapOutputs.size() -> 3, commitMemory -> 28036740, usedMemory ->41997390
2013-08-20 16:40:32,399 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000026_0 decomp: 13979058 len: 13979062 to MEMORY
2013-08-20 16:40:33,425 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13979058 bytes from map-output for attempt_1377015697181_0010_m_000026_0
2013-08-20 16:40:33,426 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13979058, inMemoryMapOutputs.size() -> 4, commitMemory -> 41997390, usedMemory ->55976448
2013-08-20 16:40:33,430 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377015697181_0010_m_000019_0 decomp: 14024610 len: 14024614 to MEMORY
2013-08-20 16:40:34,108 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14024610 bytes from map-output for attempt_1377015697181_0010_m_000019_0
2013-08-20 16:40:34,108 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14024610, inMemoryMapOutputs.size() -> 5, commitMemory -> 55976448, usedMemory ->70001058
2013-08-20 16:40:34,109 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#1 in 35269s
2013-08-20 16:40:34,109 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-20 16:40:34,116 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-20 16:40:34,376 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-20 16:40:34,377 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 70000993 bytes
2013-08-20 16:40:35,220 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 70001058 bytes to disk to satisfy reduce memory limit
2013-08-20 16:40:35,222 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 560153604 bytes from disk
2013-08-20 16:40:35,223 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-20 16:40:35,223 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-20 16:40:35,226 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 560153502 bytes
2013-08-20 16:40:35,359 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-20 16:40:39,048 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377015697181_0010_r_000006_1/part-r-00006
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377015697181_0010_r_000006_1/part-r-00006: File does not exist. Holder DFSClient_attempt_1377015697181_0010_r_000006_1_-967248375_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-20 16:40:39,048 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-20 16:40:39,050 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

