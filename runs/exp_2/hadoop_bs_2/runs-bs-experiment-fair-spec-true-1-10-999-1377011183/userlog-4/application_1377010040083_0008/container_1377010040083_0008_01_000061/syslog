2013-08-20 15:03:04,042 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-20 15:03:04,125 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-20 15:03:04,396 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-20 15:03:04,610 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-20 15:03:04,610 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-20 15:03:04,636 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-20 15:03:04,636 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377010040083_0008, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@4a1fc79a)
2013-08-20 15:03:04,786 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-20 15:03:05,721 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008
2013-08-20 15:03:06,069 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-20 15:03:06,070 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-20 15:03:06,071 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-20 15:03:06,072 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-20 15:03:06,072 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-20 15:03:06,073 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-20 15:03:06,073 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-20 15:03:06,073 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-20 15:03:06,073 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-20 15:03:06,207 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-20 15:03:06,507 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-20 15:03:06,626 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@77e2b807
2013-08-20 15:03:06,670 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-20 15:03:06,676 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377010040083_0008_r_000009_0 Thread started: EventFetcher for fetching Map Completion Events
2013-08-20 15:03:06,722 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 1 to fetcher#5
2013-08-20 15:03:06,723 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-6:8080 to fetcher#5
2013-08-20 15:03:06,724 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 1 to fetcher#1
2013-08-20 15:03:06,725 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-2:8080 to fetcher#1
2013-08-20 15:03:06,729 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 1 to fetcher#4
2013-08-20 15:03:06,729 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-3:8080 to fetcher#4
2013-08-20 15:03:06,730 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 2 to fetcher#3
2013-08-20 15:03:06,730 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-4:8080 to fetcher#3
2013-08-20 15:03:06,730 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 1 to fetcher#2
2013-08-20 15:03:06,730 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-7:8080 to fetcher#2
2013-08-20 15:03:06,738 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377010040083_0008_r_000009_0: Got 38 new map-outputs
2013-08-20 15:03:07,178 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000000_0 sent hash and received reply
2013-08-20 15:03:07,212 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000007_0 sent hash and received reply
2013-08-20 15:03:07,194 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000006_0 sent hash and received reply
2013-08-20 15:03:07,322 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000006_0 decomp: 13905010 len: 13905014 to MEMORY
2013-08-20 15:03:07,337 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000007_0 decomp: 13959610 len: 13959614 to MEMORY
2013-08-20 15:03:07,338 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000000_0 decomp: 14012546 len: 14012550 to MEMORY
2013-08-20 15:03:07,844 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000005_0,attempt_1377010040083_0008_m_000003_0 sent hash and received reply
2013-08-20 15:03:07,849 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000005_0 decomp: 13925706 len: 13925710 to MEMORY
2013-08-20 15:03:08,864 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13959610 bytes from map-output for attempt_1377010040083_0008_m_000007_0
2013-08-20 15:03:08,867 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13959610, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55802872
2013-08-20 15:03:08,869 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#4 in 2140s
2013-08-20 15:03:08,870 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 3 to fetcher#4
2013-08-20 15:03:08,870 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-999-5:8080 to fetcher#4
2013-08-20 15:03:08,878 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000023_0,attempt_1377010040083_0008_m_000028_0,attempt_1377010040083_0008_m_000032_0 sent hash and received reply
2013-08-20 15:03:08,902 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000023_0 decomp: 13901162 len: 13901166 to MEMORY
2013-08-20 15:03:08,952 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925706 bytes from map-output for attempt_1377010040083_0008_m_000005_0
2013-08-20 15:03:08,952 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925706, inMemoryMapOutputs.size() -> 2, commitMemory -> 13959610, usedMemory ->69704034
2013-08-20 15:03:09,274 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000003_0 decomp: 13996010 len: 13996014 to MEMORY
2013-08-20 15:03:10,033 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13996010 bytes from map-output for attempt_1377010040083_0008_m_000003_0
2013-08-20 15:03:10,033 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13996010, inMemoryMapOutputs.size() -> 3, commitMemory -> 27885316, usedMemory ->83700044
2013-08-20 15:03:10,034 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#3 in 3304s
2013-08-20 15:03:10,034 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 7 to fetcher#3
2013-08-20 15:03:10,034 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-999-4:8080 to fetcher#3
2013-08-20 15:03:10,039 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000009_0,attempt_1377010040083_0008_m_000010_0,attempt_1377010040083_0008_m_000018_0,attempt_1377010040083_0008_m_000024_0,attempt_1377010040083_0008_m_000026_0,attempt_1377010040083_0008_m_000031_0,attempt_1377010040083_0008_m_000037_0 sent hash and received reply
2013-08-20 15:03:10,044 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000009_0 decomp: 13925914 len: 13925918 to MEMORY
2013-08-20 15:03:10,240 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13905010 bytes from map-output for attempt_1377010040083_0008_m_000006_0
2013-08-20 15:03:10,241 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13905010, inMemoryMapOutputs.size() -> 4, commitMemory -> 41881326, usedMemory ->97625958
2013-08-20 15:03:10,241 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 3516s
2013-08-20 15:03:10,241 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 8 to fetcher#1
2013-08-20 15:03:10,242 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-999-2:8080 to fetcher#1
2013-08-20 15:03:10,252 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000002_0,attempt_1377010040083_0008_m_000004_0,attempt_1377010040083_0008_m_000014_0,attempt_1377010040083_0008_m_000016_0,attempt_1377010040083_0008_m_000019_0,attempt_1377010040083_0008_m_000029_0,attempt_1377010040083_0008_m_000034_0,attempt_1377010040083_0008_m_000036_0 sent hash and received reply
2013-08-20 15:03:10,260 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000002_0 decomp: 13937250 len: 13937254 to MEMORY
2013-08-20 15:03:10,693 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925914 bytes from map-output for attempt_1377010040083_0008_m_000009_0
2013-08-20 15:03:10,693 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925914, inMemoryMapOutputs.size() -> 5, commitMemory -> 55786336, usedMemory ->111563208
2013-08-20 15:03:10,697 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000010_0 decomp: 13967514 len: 13967518 to MEMORY
2013-08-20 15:03:10,897 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13967514 bytes from map-output for attempt_1377010040083_0008_m_000010_0
2013-08-20 15:03:10,897 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13967514, inMemoryMapOutputs.size() -> 6, commitMemory -> 69712250, usedMemory ->125530722
2013-08-20 15:03:11,090 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000018_0 decomp: 13930906 len: 13930910 to MEMORY
2013-08-20 15:03:11,147 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13937250 bytes from map-output for attempt_1377010040083_0008_m_000002_0
2013-08-20 15:03:11,148 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13937250, inMemoryMapOutputs.size() -> 7, commitMemory -> 83679764, usedMemory ->139461628
2013-08-20 15:03:11,148 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97617014 > mergeThreshold=86139864. Current usedMemory=139461628
2013-08-20 15:03:11,148 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 15:03:11,148 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-20 15:03:11,151 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#1 in 909s
2013-08-20 15:03:11,721 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14012546 bytes from map-output for attempt_1377010040083_0008_m_000000_0
2013-08-20 15:03:11,721 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14012546, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139461628
2013-08-20 15:03:11,722 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#2 in 4992s
2013-08-20 15:03:11,951 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901162 bytes from map-output for attempt_1377010040083_0008_m_000023_0
2013-08-20 15:03:11,951 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901162, inMemoryMapOutputs.size() -> 2, commitMemory -> 14012546, usedMemory ->139461628
2013-08-20 15:03:11,952 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 15:03:11,952 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#4 in 3082s
2013-08-20 15:03:12,152 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 15:03:12,160 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 15:03:12,175 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97616923 bytes
2013-08-20 15:03:12,605 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930906 bytes from map-output for attempt_1377010040083_0008_m_000018_0
2013-08-20 15:03:12,605 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930906, inMemoryMapOutputs.size() -> 3, commitMemory -> 27913708, usedMemory ->139461628
2013-08-20 15:03:12,606 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-20 15:03:12,606 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#3 in 2572s
2013-08-20 15:03:13,895 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377010040083_0008_r_000009_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008/output/attempt_1377010040083_0008_r_000009_0/map_6.out.merged of size 97617006
2013-08-20 15:03:13,895 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 7 to fetcher#3
2013-08-20 15:03:13,895 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-999-2:8080 to fetcher#3
2013-08-20 15:03:13,895 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 4 to fetcher#1
2013-08-20 15:03:13,896 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-999-7:8080 to fetcher#1
2013-08-20 15:03:13,896 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 6 to fetcher#2
2013-08-20 15:03:13,897 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-999-3:8080 to fetcher#2
2013-08-20 15:03:13,898 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 4 to fetcher#4
2013-08-20 15:03:13,898 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-999-4:8080 to fetcher#4
2013-08-20 15:03:13,902 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000031_0,attempt_1377010040083_0008_m_000024_0,attempt_1377010040083_0008_m_000037_0,attempt_1377010040083_0008_m_000026_0 sent hash and received reply
2013-08-20 15:03:13,907 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000031_0 decomp: 13987586 len: 13987590 to MEMORY
2013-08-20 15:03:13,907 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000012_0,attempt_1377010040083_0008_m_000013_0,attempt_1377010040083_0008_m_000021_0,attempt_1377010040083_0008_m_000033_0 sent hash and received reply
2013-08-20 15:03:13,908 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000015_0,attempt_1377010040083_0008_m_000017_0,attempt_1377010040083_0008_m_000022_0,attempt_1377010040083_0008_m_000027_0,attempt_1377010040083_0008_m_000030_0,attempt_1377010040083_0008_m_000035_0 sent hash and received reply
2013-08-20 15:03:14,035 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000015_0 decomp: 14000378 len: 14000382 to MEMORY
2013-08-20 15:03:14,039 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000012_0 decomp: 13835850 len: 13835854 to MEMORY
2013-08-20 15:03:14,794 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13987586 bytes from map-output for attempt_1377010040083_0008_m_000031_0
2013-08-20 15:03:14,794 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13987586, inMemoryMapOutputs.size() -> 4, commitMemory -> 41844614, usedMemory ->83668428
2013-08-20 15:03:14,799 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000024_0 decomp: 13962314 len: 13962318 to MEMORY
2013-08-20 15:03:15,535 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13835850 bytes from map-output for attempt_1377010040083_0008_m_000012_0
2013-08-20 15:03:15,535 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13835850, inMemoryMapOutputs.size() -> 5, commitMemory -> 55832200, usedMemory ->97630742
2013-08-20 15:03:15,540 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000013_0 decomp: 13960338 len: 13960342 to MEMORY
2013-08-20 15:03:16,069 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13962314 bytes from map-output for attempt_1377010040083_0008_m_000024_0
2013-08-20 15:03:16,069 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13962314, inMemoryMapOutputs.size() -> 6, commitMemory -> 69668050, usedMemory ->111591080
2013-08-20 15:03:16,257 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000037_0 decomp: 13917074 len: 13917078 to MEMORY
2013-08-20 15:03:16,292 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14000378 bytes from map-output for attempt_1377010040083_0008_m_000015_0
2013-08-20 15:03:16,292 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14000378, inMemoryMapOutputs.size() -> 7, commitMemory -> 83630364, usedMemory ->125508154
2013-08-20 15:03:16,292 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97630742 > mergeThreshold=86139864. Current usedMemory=125508154
2013-08-20 15:03:16,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 15:03:16,317 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000017_0 decomp: 13969698 len: 13969702 to MEMORY
2013-08-20 15:03:16,319 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13917074 bytes from map-output for attempt_1377010040083_0008_m_000037_0
2013-08-20 15:03:16,319 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13917074, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139477852
2013-08-20 15:03:16,319 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 15:03:16,320 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#4 in 2422s
2013-08-20 15:03:16,592 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 15:03:16,593 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 15:03:16,593 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97630651 bytes
2013-08-20 15:03:16,597 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960338 bytes from map-output for attempt_1377010040083_0008_m_000013_0
2013-08-20 15:03:16,598 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960338, inMemoryMapOutputs.size() -> 2, commitMemory -> 13917074, usedMemory ->139477852
2013-08-20 15:03:16,598 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-20 15:03:16,599 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#1 in 2704s
2013-08-20 15:03:17,157 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13969698 bytes from map-output for attempt_1377010040083_0008_m_000017_0
2013-08-20 15:03:17,158 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13969698, inMemoryMapOutputs.size() -> 3, commitMemory -> 27877412, usedMemory ->139477852
2013-08-20 15:03:17,158 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-20 15:03:17,159 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#2 in 3262s
2013-08-20 15:03:17,789 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000004_0,attempt_1377010040083_0008_m_000034_0,attempt_1377010040083_0008_m_000016_0,attempt_1377010040083_0008_m_000036_0,attempt_1377010040083_0008_m_000019_0,attempt_1377010040083_0008_m_000029_0,attempt_1377010040083_0008_m_000014_0 sent hash and received reply
2013-08-20 15:03:17,790 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-20 15:03:18,102 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#3 in 4207s
2013-08-20 15:03:18,110 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377010040083_0008_r_000009_0: Got 1 new map-outputs
2013-08-20 15:03:18,350 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377010040083_0008_r_000009_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008/output/attempt_1377010040083_0008_r_000009_0/map_12.out.merged of size 97630734
2013-08-20 15:03:18,350 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 2 to fetcher#3
2013-08-20 15:03:18,350 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-7:8080 to fetcher#3
2013-08-20 15:03:18,352 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-4:8080 with 1 to fetcher#1
2013-08-20 15:03:18,353 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-4:8080 to fetcher#1
2013-08-20 15:03:18,353 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 2 to fetcher#4
2013-08-20 15:03:18,353 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-5:8080 to fetcher#4
2013-08-20 15:03:18,355 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 7 to fetcher#2
2013-08-20 15:03:18,355 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-999-2:8080 to fetcher#2
2013-08-20 15:03:18,359 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000021_0,attempt_1377010040083_0008_m_000033_0 sent hash and received reply
2013-08-20 15:03:18,464 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000028_0,attempt_1377010040083_0008_m_000032_0 sent hash and received reply
2013-08-20 15:03:18,465 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000004_0,attempt_1377010040083_0008_m_000034_0,attempt_1377010040083_0008_m_000016_0,attempt_1377010040083_0008_m_000019_0,attempt_1377010040083_0008_m_000036_0,attempt_1377010040083_0008_m_000014_0,attempt_1377010040083_0008_m_000029_0 sent hash and received reply
2013-08-20 15:03:18,467 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000026_0 sent hash and received reply
2013-08-20 15:03:18,470 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000021_0 decomp: 13919778 len: 13919782 to MEMORY
2013-08-20 15:03:18,473 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000026_0 decomp: 13950978 len: 13950982 to MEMORY
2013-08-20 15:03:18,477 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000004_0 decomp: 13960650 len: 13960654 to MEMORY
2013-08-20 15:03:18,481 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000028_0 decomp: 13917490 len: 13917494 to MEMORY
2013-08-20 15:03:19,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960650 bytes from map-output for attempt_1377010040083_0008_m_000004_0
2013-08-20 15:03:19,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960650, inMemoryMapOutputs.size() -> 4, commitMemory -> 41847110, usedMemory ->97596006
2013-08-20 15:03:19,466 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000034_0 decomp: 13909170 len: 13909174 to MEMORY
2013-08-20 15:03:19,503 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13950978 bytes from map-output for attempt_1377010040083_0008_m_000026_0
2013-08-20 15:03:19,504 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13950978, inMemoryMapOutputs.size() -> 5, commitMemory -> 55807760, usedMemory ->111505176
2013-08-20 15:03:19,504 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-4:8080 freed by fetcher#1 in 1152s
2013-08-20 15:03:19,504 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 5 to fetcher#1
2013-08-20 15:03:19,504 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-3:8080 to fetcher#1
2013-08-20 15:03:19,510 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000022_0,attempt_1377010040083_0008_m_000027_0,attempt_1377010040083_0008_m_000030_0,attempt_1377010040083_0008_m_000035_0,attempt_1377010040083_0008_m_000038_0 sent hash and received reply
2013-08-20 15:03:19,516 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000022_0 decomp: 13962730 len: 13962734 to MEMORY
2013-08-20 15:03:19,645 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13919778 bytes from map-output for attempt_1377010040083_0008_m_000021_0
2013-08-20 15:03:19,645 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13919778, inMemoryMapOutputs.size() -> 6, commitMemory -> 69758738, usedMemory ->125467906
2013-08-20 15:03:19,656 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000033_0 decomp: 13918842 len: 13918846 to MEMORY
2013-08-20 15:03:20,350 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13918842 bytes from map-output for attempt_1377010040083_0008_m_000033_0
2013-08-20 15:03:20,352 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13918842, inMemoryMapOutputs.size() -> 7, commitMemory -> 83678516, usedMemory ->139386748
2013-08-20 15:03:20,352 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97597358 > mergeThreshold=86139864. Current usedMemory=139386748
2013-08-20 15:03:20,353 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 15:03:20,355 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#3 in 2005s
2013-08-20 15:03:20,358 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909170 bytes from map-output for attempt_1377010040083_0008_m_000034_0
2013-08-20 15:03:20,359 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909170, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139386748
2013-08-20 15:03:20,359 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-20 15:03:20,359 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#2 in 2004s
2013-08-20 15:03:20,429 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000001_0 sent hash and received reply
2013-08-20 15:03:20,431 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 15:03:20,431 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#5 in 13709s
2013-08-20 15:03:20,653 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 15:03:20,654 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 15:03:20,654 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97597267 bytes
2013-08-20 15:03:21,502 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13917490 bytes from map-output for attempt_1377010040083_0008_m_000028_0
2013-08-20 15:03:21,502 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13917490, inMemoryMapOutputs.size() -> 2, commitMemory -> 13909170, usedMemory ->139386748
2013-08-20 15:03:21,505 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-20 15:03:21,506 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#4 in 3153s
2013-08-20 15:03:22,384 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377010040083_0008_r_000009_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008/output/attempt_1377010040083_0008_r_000009_0/map_37.out.merged of size 97597350
2013-08-20 15:03:22,545 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-6:8080 with 5 to fetcher#4
2013-08-20 15:03:22,545 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-6:8080 to fetcher#4
2013-08-20 15:03:22,546 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-5:8080 with 1 to fetcher#3
2013-08-20 15:03:22,546 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-5:8080 to fetcher#3
2013-08-20 15:03:22,547 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 5 to fetcher#2
2013-08-20 15:03:22,547 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-999-2:8080 to fetcher#2
2013-08-20 15:03:22,550 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000032_0 sent hash and received reply
2013-08-20 15:03:22,552 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000016_0,attempt_1377010040083_0008_m_000036_0,attempt_1377010040083_0008_m_000019_0,attempt_1377010040083_0008_m_000029_0,attempt_1377010040083_0008_m_000014_0 sent hash and received reply
2013-08-20 15:03:22,663 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000032_0 decomp: 13952018 len: 13952022 to MEMORY
2013-08-20 15:03:22,667 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000016_0 decomp: 13946922 len: 13946926 to MEMORY
2013-08-20 15:03:23,120 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13952018 bytes from map-output for attempt_1377010040083_0008_m_000032_0
2013-08-20 15:03:23,121 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13952018, inMemoryMapOutputs.size() -> 3, commitMemory -> 27826660, usedMemory ->69688330
2013-08-20 15:03:23,121 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-5:8080 freed by fetcher#3 in 575s
2013-08-20 15:03:23,174 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13962730 bytes from map-output for attempt_1377010040083_0008_m_000022_0
2013-08-20 15:03:23,174 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13962730, inMemoryMapOutputs.size() -> 4, commitMemory -> 41778678, usedMemory ->69688330
2013-08-20 15:03:23,180 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000027_0 decomp: 13976666 len: 13976670 to MEMORY
2013-08-20 15:03:26,717 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13946922 bytes from map-output for attempt_1377010040083_0008_m_000016_0
2013-08-20 15:03:26,717 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13946922, inMemoryMapOutputs.size() -> 5, commitMemory -> 55741408, usedMemory ->83664996
2013-08-20 15:03:26,721 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000036_0 decomp: 13961898 len: 13961902 to MEMORY
2013-08-20 15:03:30,123 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13961898 bytes from map-output for attempt_1377010040083_0008_m_000036_0
2013-08-20 15:03:30,123 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13961898, inMemoryMapOutputs.size() -> 6, commitMemory -> 69688330, usedMemory ->97626894
2013-08-20 15:03:30,233 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000019_0 decomp: 13970426 len: 13970430 to MEMORY
2013-08-20 15:03:31,138 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976666 bytes from map-output for attempt_1377010040083_0008_m_000027_0
2013-08-20 15:03:31,138 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976666, inMemoryMapOutputs.size() -> 7, commitMemory -> 83650228, usedMemory ->111597320
2013-08-20 15:03:31,138 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97626894 > mergeThreshold=86139864. Current usedMemory=111597320
2013-08-20 15:03:31,139 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 15:03:31,144 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377010040083_0008_m_000030_0 decomp: 13961274 len: 13961278 to MEMORY
2013-08-20 15:03:31,236 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377010040083_0008_r_000009_0: Got 1 new map-outputs
2013-08-20 15:03:31,236 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-7:8080 with 1 to fetcher#3
2013-08-20 15:03:31,237 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-999-7:8080 to fetcher#3
2013-08-20 15:03:31,261 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000039_0 sent hash and received reply
2013-08-20 15:03:31,266 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000039_0 decomp: 13998506 len: 13998510 to MEMORY
2013-08-20 15:03:31,523 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 15:03:31,524 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 15:03:31,524 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97626803 bytes
2013-08-20 15:03:31,602 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970426 bytes from map-output for attempt_1377010040083_0008_m_000019_0
2013-08-20 15:03:31,605 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970426, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139557100
2013-08-20 15:03:31,608 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-20 15:03:31,611 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#2 in 9064s
2013-08-20 15:03:31,611 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 2 to fetcher#5
2013-08-20 15:03:31,612 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-2:8080 to fetcher#5
2013-08-20 15:03:31,617 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000014_0,attempt_1377010040083_0008_m_000029_0 sent hash and received reply
2013-08-20 15:03:31,618 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-20 15:03:31,619 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#5 in 7s
2013-08-20 15:03:32,932 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13998506 bytes from map-output for attempt_1377010040083_0008_m_000039_0
2013-08-20 15:03:32,933 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13998506, inMemoryMapOutputs.size() -> 2, commitMemory -> 13970426, usedMemory ->139557100
2013-08-20 15:03:32,935 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-7:8080 freed by fetcher#3 in 1698s
2013-08-20 15:03:33,643 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13961274 bytes from map-output for attempt_1377010040083_0008_m_000030_0
2013-08-20 15:03:33,643 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13961274, inMemoryMapOutputs.size() -> 3, commitMemory -> 27968932, usedMemory ->139557100
2013-08-20 15:03:33,644 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-20 15:03:33,644 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#1 in 14140s
2013-08-20 15:03:33,762 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377010040083_0008_r_000009_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008/output/attempt_1377010040083_0008_r_000009_0/map_34.out.merged of size 97626886
2013-08-20 15:03:33,763 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-3:8080 with 2 to fetcher#3
2013-08-20 15:03:33,763 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-3:8080 to fetcher#3
2013-08-20 15:03:33,763 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-999-2:8080 with 2 to fetcher#2
2013-08-20 15:03:33,763 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-999-2:8080 to fetcher#2
2013-08-20 15:03:33,769 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000029_0,attempt_1377010040083_0008_m_000014_0 sent hash and received reply
2013-08-20 15:03:33,776 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000038_0,attempt_1377010040083_0008_m_000035_0 sent hash and received reply
2013-08-20 15:03:33,778 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000029_0 decomp: 13960442 len: 13960446 to MEMORY
2013-08-20 15:03:33,785 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000038_0 decomp: 13912290 len: 13912294 to MEMORY
2013-08-20 15:03:34,280 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13912290 bytes from map-output for attempt_1377010040083_0008_m_000038_0
2013-08-20 15:03:34,280 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13912290, inMemoryMapOutputs.size() -> 4, commitMemory -> 41930206, usedMemory ->69802938
2013-08-20 15:03:34,283 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377010040083_0008_m_000035_0 decomp: 13906570 len: 13906574 to MEMORY
2013-08-20 15:03:35,305 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13906570 bytes from map-output for attempt_1377010040083_0008_m_000035_0
2013-08-20 15:03:35,305 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13906570, inMemoryMapOutputs.size() -> 5, commitMemory -> 55842496, usedMemory ->83709508
2013-08-20 15:03:35,305 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-3:8080 freed by fetcher#3 in 1542s
2013-08-20 15:03:37,524 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377010040083_0008&reduce=9&map=attempt_1377010040083_0008_m_000008_0,attempt_1377010040083_0008_m_000011_0,attempt_1377010040083_0008_m_000020_0,attempt_1377010040083_0008_m_000025_0,attempt_1377010040083_0008_m_000001_0 sent hash and received reply
2013-08-20 15:03:37,708 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000008_0 decomp: 13989874 len: 13989878 to MEMORY
2013-08-20 15:03:38,336 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960442 bytes from map-output for attempt_1377010040083_0008_m_000029_0
2013-08-20 15:03:38,336 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960442, inMemoryMapOutputs.size() -> 6, commitMemory -> 69749066, usedMemory ->97699382
2013-08-20 15:03:38,340 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377010040083_0008_m_000014_0 decomp: 13933298 len: 13933302 to MEMORY
2013-08-20 15:03:39,725 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13933298 bytes from map-output for attempt_1377010040083_0008_m_000014_0
2013-08-20 15:03:39,726 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13933298, inMemoryMapOutputs.size() -> 7, commitMemory -> 83709508, usedMemory ->111632680
2013-08-20 15:03:39,726 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97642806 > mergeThreshold=86139864. Current usedMemory=111632680
2013-08-20 15:03:39,726 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-20 15:03:39,727 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-2:8080 freed by fetcher#2 in 5964s
2013-08-20 15:03:40,160 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-20 15:03:40,160 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-20 15:03:40,161 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97642715 bytes
2013-08-20 15:03:41,252 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377010040083_0008_r_000009_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377010040083_0008/output/attempt_1377010040083_0008_r_000009_0/map_35.out.merged of size 97642798
2013-08-20 15:04:13,000 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13989874 bytes from map-output for attempt_1377010040083_0008_m_000008_0
2013-08-20 15:04:13,000 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13989874, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13989874
2013-08-20 15:04:13,085 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000011_0 decomp: 13916138 len: 13916142 to MEMORY
2013-08-20 15:04:22,119 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13916138 bytes from map-output for attempt_1377010040083_0008_m_000011_0
2013-08-20 15:04:22,120 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13916138, inMemoryMapOutputs.size() -> 2, commitMemory -> 13989874, usedMemory ->27906012
2013-08-20 15:04:22,124 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000020_0 decomp: 13913850 len: 13913854 to MEMORY
2013-08-20 15:04:41,449 WARN [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: Error reading the stream java.io.IOException: No such process
2013-08-20 15:04:41,465 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 6678 may have finished in the interim.
2013-08-20 15:04:41,465 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 6681 may have finished in the interim.
2013-08-20 15:04:41,465 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 6683 may have finished in the interim.
2013-08-20 15:04:41,466 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 6684 may have finished in the interim.
2013-08-20 15:04:41,466 INFO [communication thread] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: The process 6685 may have finished in the interim.
2013-08-20 15:04:57,376 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13913850 bytes from map-output for attempt_1377010040083_0008_m_000020_0
2013-08-20 15:04:57,376 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13913850, inMemoryMapOutputs.size() -> 3, commitMemory -> 27906012, usedMemory ->41819862
2013-08-20 15:04:57,381 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000025_0 decomp: 13947858 len: 13947862 to MEMORY
2013-08-20 15:04:59,975 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13947858 bytes from map-output for attempt_1377010040083_0008_m_000025_0
2013-08-20 15:04:59,975 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13947858, inMemoryMapOutputs.size() -> 4, commitMemory -> 41819862, usedMemory ->55767720
2013-08-20 15:04:59,980 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377010040083_0008_m_000001_0 decomp: 13896690 len: 13896694 to MEMORY
2013-08-20 15:05:06,314 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896690 bytes from map-output for attempt_1377010040083_0008_m_000001_0
2013-08-20 15:05:06,314 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896690, inMemoryMapOutputs.size() -> 5, commitMemory -> 55767720, usedMemory ->69664410
2013-08-20 15:05:06,315 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-999-6:8080 freed by fetcher#4 in 103770s
2013-08-20 15:05:06,315 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-20 15:05:06,322 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-20 15:05:06,601 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-20 15:05:06,601 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69664345 bytes
2013-08-20 15:05:08,568 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69664410 bytes to disk to satisfy reduce memory limit
2013-08-20 15:05:08,569 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 557779180 bytes from disk
2013-08-20 15:05:08,571 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-20 15:05:08,571 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-20 15:05:08,879 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 557779078 bytes
2013-08-20 15:05:08,993 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-20 15:05:21,663 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-20 15:05:21,664 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-20 15:05:21,666 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1377010040083_0008_r_000009_0/part-r-00009
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1377010040083_0008_r_000009_0/part-r-00009: File does not exist. Holder DFSClient_attempt_1377010040083_0008_r_000009_0_-1143035252_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-20 15:05:21,668 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
