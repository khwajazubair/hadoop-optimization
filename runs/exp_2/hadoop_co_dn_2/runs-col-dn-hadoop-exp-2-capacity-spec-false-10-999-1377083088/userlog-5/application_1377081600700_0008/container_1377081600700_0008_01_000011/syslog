2013-08-21 10:54:25,911 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-21 10:54:25,965 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-21 10:54:26,329 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-21 10:54:26,522 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-21 10:54:26,522 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started
2013-08-21 10:54:26,546 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-21 10:54:26,547 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377081600700_0008, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-21 10:54:26,634 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-21 10:54:27,033 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377081600700_0008
2013-08-21 10:54:27,253 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-21 10:54:27,253 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-21 10:54:27,253 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-21 10:54:27,254 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-21 10:54:27,255 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-21 10:54:27,255 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-21 10:54:27,255 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-21 10:54:27,256 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-21 10:54:27,420 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-21 10:54:27,741 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-21 10:54:27,913 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.17:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,914 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.18:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,915 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.15:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,915 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.9:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,916 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.19:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,917 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /192.168.100.13:50010 for block, add to deadNodes and continue. java.net.SocketException: Network is unreachable
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:364)
	at sun.nio.ch.Net.connect(Net.java:356)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:623)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:526)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:931)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:455)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:649)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:693)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:522)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:725)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:339)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-21 10:54:27,917 INFO [main] org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-2042408596-192.168.100.6-1377081576620:blk_-7923240208173237676_1355 from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry...
2013-08-21 10:54:27,917 WARN [main] org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for 306.8053931425041 msec.
2013-08-21 10:54:28,316 INFO [main] org.apache.hadoop.hdfs.DFSClient: Successfully connected to /192.168.100.17:50010 for BP-2042408596-192.168.100.6-1377081576620:blk_-7923240208173237676_1355
2013-08-21 10:54:28,339 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://hadoop-999-1:54310/user/hduser/terasort-input-4/part-m-00000 from 1073741824 length 134217728
2013-08-21 10:54:28,355 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2013-08-21 10:54:28,491 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2013-08-21 10:54:28,491 INFO [main] org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2013-08-21 10:54:28,491 INFO [main] org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2013-08-21 10:54:28,491 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2013-08-21 10:54:28,491 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2013-08-21 10:54:50,390 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2013-08-21 10:54:50,391 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 72511698; bufvoid = 104857600
2013-08-21 10:54:50,391 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 23370804(93483216); length = 2843593/6553600
2013-08-21 10:54:50,392 INFO [main] org.apache.hadoop.mapred.MapTask: (EQUATOR) 75355282 kvi 18838816(75355264)
2013-08-21 10:54:56,744 INFO [SpillThread] org.apache.hadoop.mapred.MapTask: Finished spill 0
2013-08-21 10:54:56,745 INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator 75355282 kv 18838816(75355264) kvi 18127932(72511728)
2013-08-21 10:55:10,963 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
2013-08-21 10:55:10,963 INFO [main] org.apache.hadoop.mapred.MapTask: Spilling map output
2013-08-21 10:55:10,963 INFO [main] org.apache.hadoop.mapred.MapTask: bufstart = 75355282; bufend = 34888038; bufvoid = 104857600
2013-08-21 10:55:10,963 INFO [main] org.apache.hadoop.mapred.MapTask: kvstart = 18838816(75355264); kvend = 16313708(65254832); length = 2525109/6553600
2013-08-21 10:55:15,856 INFO [main] org.apache.hadoop.mapred.MapTask: Finished spill 1
2013-08-21 10:55:15,936 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:15,950 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13866514 bytes
2013-08-21 10:55:16,648 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:16,648 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 14159690 bytes
2013-08-21 10:55:16,932 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:16,932 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 14125058 bytes
2013-08-21 10:55:17,328 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:17,335 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13867970 bytes
2013-08-21 10:55:17,698 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:17,698 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 14009930 bytes
2013-08-21 10:55:17,905 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:17,905 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13845610 bytes
2013-08-21 10:55:18,860 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:18,861 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13985178 bytes
2013-08-21 10:55:19,038 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:19,038 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13828762 bytes
2013-08-21 10:55:19,233 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:19,234 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13972282 bytes
2013-08-21 10:55:19,456 INFO [main] org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2013-08-21 10:55:19,457 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13925274 bytes
2013-08-21 10:55:21,223 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1377081600700_0008_m_000009_0 is done. And is in the process of committing
2013-08-21 10:55:21,317 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1377081600700_0008_m_000009_0' done.
2013-08-21 10:55:21,418 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...
2013-08-21 10:55:21,419 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.
