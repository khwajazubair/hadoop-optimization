2013-08-28 00:29:07,158 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-28 00:29:07,225 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-28 00:29:07,472 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-28 00:29:07,633 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-28 00:29:07,634 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-28 00:29:07,660 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-28 00:29:07,660 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377648003102_0010, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-28 00:29:07,787 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-28 00:29:08,497 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010
2013-08-28 00:29:08,863 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-28 00:29:08,864 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-28 00:29:08,865 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-28 00:29:08,866 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-28 00:29:08,867 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-28 00:29:08,868 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-28 00:29:08,869 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-28 00:29:08,870 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-28 00:29:08,870 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-28 00:29:09,201 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-28 00:29:09,876 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-28 00:29:10,026 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e0b62b2
2013-08-28 00:29:10,064 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-28 00:29:10,068 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377648003102_0010_r_000006_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-28 00:29:10,085 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 1 to fetcher#4
2013-08-28 00:29:10,086 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-2:8080 to fetcher#4
2013-08-28 00:29:10,090 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 3 to fetcher#3
2013-08-28 00:29:10,100 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-3:8080 to fetcher#3
2013-08-28 00:29:10,100 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 6 to fetcher#5
2013-08-28 00:29:10,100 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-4:8080 to fetcher#5
2013-08-28 00:29:10,101 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 1 to fetcher#1
2013-08-28 00:29:10,101 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-5:8080 to fetcher#1
2013-08-28 00:29:10,101 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 4 to fetcher#2
2013-08-28 00:29:10,101 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-7:8080 to fetcher#2
2013-08-28 00:29:10,105 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377648003102_0010_r_000006_1: Got 40 new map-outputs
2013-08-28 00:29:10,239 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000000_0 sent hash and received reply
2013-08-28 00:29:10,239 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000022_0 sent hash and received reply
2013-08-28 00:29:10,242 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000002_0,attempt_1377648003102_0010_m_000010_0,attempt_1377648003102_0010_m_000013_0 sent hash and received reply
2013-08-28 00:29:10,246 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000000_0 decomp: 13943386 len: 13943390 to MEMORY
2013-08-28 00:29:10,319 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000022_0 decomp: 14009634 len: 14009638 to MEMORY
2013-08-28 00:29:10,319 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0010_m_000002_0 decomp: 13964290 len: 13964294 to MEMORY
2013-08-28 00:29:10,601 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14009634 bytes from map-output for attempt_1377648003102_0010_m_000022_0
2013-08-28 00:29:10,607 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14009634, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41917310
2013-08-28 00:29:10,609 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#1 in 508s
2013-08-28 00:29:10,609 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 4 to fetcher#1
2013-08-28 00:29:10,609 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-6:8080 to fetcher#1
2013-08-28 00:29:10,618 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000017_0,attempt_1377648003102_0010_m_000019_0,attempt_1377648003102_0010_m_000021_0,attempt_1377648003102_0010_m_000028_0 sent hash and received reply
2013-08-28 00:29:10,624 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000017_0 decomp: 13960546 len: 13960550 to MEMORY
2013-08-28 00:29:10,787 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13964290 bytes from map-output for attempt_1377648003102_0010_m_000002_0
2013-08-28 00:29:10,788 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13964290, inMemoryMapOutputs.size() -> 2, commitMemory -> 14009634, usedMemory ->55877856
2013-08-28 00:29:10,805 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0010_m_000010_0 decomp: 13975002 len: 13975006 to MEMORY
2013-08-28 00:29:10,981 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960546 bytes from map-output for attempt_1377648003102_0010_m_000017_0
2013-08-28 00:29:10,982 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960546, inMemoryMapOutputs.size() -> 3, commitMemory -> 27973924, usedMemory ->69852858
2013-08-28 00:29:11,162 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000019_0 decomp: 13993722 len: 13993726 to MEMORY
2013-08-28 00:29:11,332 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13975002 bytes from map-output for attempt_1377648003102_0010_m_000010_0
2013-08-28 00:29:11,333 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13975002, inMemoryMapOutputs.size() -> 4, commitMemory -> 41934470, usedMemory ->83846580
2013-08-28 00:29:11,342 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0010_m_000013_0 decomp: 13925498 len: 13925502 to MEMORY
2013-08-28 00:29:11,494 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13993722 bytes from map-output for attempt_1377648003102_0010_m_000019_0
2013-08-28 00:29:11,494 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13993722, inMemoryMapOutputs.size() -> 5, commitMemory -> 55909472, usedMemory ->97772078
2013-08-28 00:29:11,501 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000021_0 decomp: 14021594 len: 14021598 to MEMORY
2013-08-28 00:29:11,713 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925498 bytes from map-output for attempt_1377648003102_0010_m_000013_0
2013-08-28 00:29:11,714 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925498, inMemoryMapOutputs.size() -> 6, commitMemory -> 69903194, usedMemory ->111793672
2013-08-28 00:29:11,776 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#3 in 1676s
2013-08-28 00:29:11,776 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 2 to fetcher#3
2013-08-28 00:29:11,777 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-3:8080 to fetcher#3
2013-08-28 00:29:11,783 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000024_0,attempt_1377648003102_0010_m_000031_0 sent hash and received reply
2013-08-28 00:29:11,789 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0010_m_000024_0 decomp: 13984778 len: 13984782 to MEMORY
2013-08-28 00:29:11,833 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14021594 bytes from map-output for attempt_1377648003102_0010_m_000021_0
2013-08-28 00:29:11,834 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14021594, inMemoryMapOutputs.size() -> 7, commitMemory -> 83828692, usedMemory ->125778450
2013-08-28 00:29:11,834 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97850286 > mergeThreshold=86139864. Current usedMemory=125778450
2013-08-28 00:29:11,834 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:29:11,977 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000028_0 decomp: 13930698 len: 13930702 to MEMORY
2013-08-28 00:29:12,232 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930698 bytes from map-output for attempt_1377648003102_0010_m_000028_0
2013-08-28 00:29:12,232 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930698, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139709148
2013-08-28 00:29:12,234 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#1 in 1625s
2013-08-28 00:29:12,355 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:29:12,363 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:29:12,365 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97850195 bytes
2013-08-28 00:29:12,383 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13984778 bytes from map-output for attempt_1377648003102_0010_m_000024_0
2013-08-28 00:29:12,384 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13984778, inMemoryMapOutputs.size() -> 2, commitMemory -> 13930698, usedMemory ->139709148
2013-08-28 00:29:12,385 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-28 00:29:12,385 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#3 in 609s
2013-08-28 00:29:12,460 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000001_0,attempt_1377648003102_0010_m_000003_0,attempt_1377648003102_0010_m_000009_0,attempt_1377648003102_0010_m_000014_0 sent hash and received reply
2013-08-28 00:29:12,461 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-28 00:29:12,461 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#2 in 2360s
2013-08-28 00:29:12,530 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13943386 bytes from map-output for attempt_1377648003102_0010_m_000000_0
2013-08-28 00:29:12,531 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13943386, inMemoryMapOutputs.size() -> 3, commitMemory -> 27915476, usedMemory ->139709148
2013-08-28 00:29:12,531 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#4 in 2446s
2013-08-28 00:29:14,550 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010/output/attempt_1377648003102_0010_r_000006_1/map_13.out.merged of size 97850278
2013-08-28 00:29:14,551 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 3 to fetcher#4
2013-08-28 00:29:14,551 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-5:8080 to fetcher#4
2013-08-28 00:29:14,551 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 9 to fetcher#1
2013-08-28 00:29:14,551 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-9-7:8080 to fetcher#1
2013-08-28 00:29:14,552 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 7 to fetcher#2
2013-08-28 00:29:14,552 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-2:8080 to fetcher#2
2013-08-28 00:29:14,552 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 1 to fetcher#3
2013-08-28 00:29:14,552 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-3:8080 to fetcher#3
2013-08-28 00:29:14,556 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000031_0 sent hash and received reply
2013-08-28 00:29:14,558 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000007_0,attempt_1377648003102_0010_m_000008_0,attempt_1377648003102_0010_m_000016_0,attempt_1377648003102_0010_m_000026_0,attempt_1377648003102_0010_m_000029_0,attempt_1377648003102_0010_m_000034_0,attempt_1377648003102_0010_m_000036_0 sent hash and received reply
2013-08-28 00:29:14,563 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000007_0 decomp: 13963458 len: 13963462 to MEMORY
2013-08-28 00:29:14,643 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000023_0,attempt_1377648003102_0010_m_000018_0,attempt_1377648003102_0010_m_000027_0,attempt_1377648003102_0010_m_000032_0,attempt_1377648003102_0010_m_000037_0,attempt_1377648003102_0010_m_000001_0,attempt_1377648003102_0010_m_000014_0,attempt_1377648003102_0010_m_000009_0,attempt_1377648003102_0010_m_000003_0 sent hash and received reply
2013-08-28 00:29:14,646 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0010_m_000031_0 decomp: 13930698 len: 13930702 to MEMORY
2013-08-28 00:29:14,649 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000023_0 decomp: 13983218 len: 13983222 to MEMORY
2013-08-28 00:29:14,657 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000012_0,attempt_1377648003102_0010_m_000033_0,attempt_1377648003102_0010_m_000038_0 sent hash and received reply
2013-08-28 00:29:14,665 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000012_0 decomp: 14001730 len: 14001734 to MEMORY
2013-08-28 00:29:15,079 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930698 bytes from map-output for attempt_1377648003102_0010_m_000031_0
2013-08-28 00:29:15,079 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930698, inMemoryMapOutputs.size() -> 4, commitMemory -> 41858862, usedMemory ->97737966
2013-08-28 00:29:15,080 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#3 in 528s
2013-08-28 00:29:15,320 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13983218 bytes from map-output for attempt_1377648003102_0010_m_000023_0
2013-08-28 00:29:15,320 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13983218, inMemoryMapOutputs.size() -> 5, commitMemory -> 55789560, usedMemory ->97737966
2013-08-28 00:29:15,325 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000018_0 decomp: 14009322 len: 14009326 to MEMORY
2013-08-28 00:29:15,655 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14009322 bytes from map-output for attempt_1377648003102_0010_m_000018_0
2013-08-28 00:29:15,655 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14009322, inMemoryMapOutputs.size() -> 6, commitMemory -> 69772778, usedMemory ->111747288
2013-08-28 00:29:15,748 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000027_0 decomp: 13952330 len: 13952334 to MEMORY
2013-08-28 00:29:16,124 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13952330 bytes from map-output for attempt_1377648003102_0010_m_000027_0
2013-08-28 00:29:16,124 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13952330, inMemoryMapOutputs.size() -> 7, commitMemory -> 83782100, usedMemory ->125699618
2013-08-28 00:29:16,124 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97734430 > mergeThreshold=86139864. Current usedMemory=125699618
2013-08-28 00:29:16,125 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:29:16,130 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000032_0 decomp: 13994658 len: 13994662 to MEMORY
2013-08-28 00:29:16,196 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14001730 bytes from map-output for attempt_1377648003102_0010_m_000012_0
2013-08-28 00:29:16,196 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14001730, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139694276
2013-08-28 00:29:16,197 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-28 00:29:16,197 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#4 in 1646s
2013-08-28 00:29:16,198 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 2 to fetcher#3
2013-08-28 00:29:16,198 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-5:8080 to fetcher#3
2013-08-28 00:29:16,221 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000038_0,attempt_1377648003102_0010_m_000033_0 sent hash and received reply
2013-08-28 00:29:16,222 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-28 00:29:16,223 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#3 in 24s
2013-08-28 00:29:16,379 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:29:16,379 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:29:16,380 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97734339 bytes
2013-08-28 00:29:17,159 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13994658 bytes from map-output for attempt_1377648003102_0010_m_000032_0
2013-08-28 00:29:17,159 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13994658, inMemoryMapOutputs.size() -> 2, commitMemory -> 14001730, usedMemory ->139694276
2013-08-28 00:29:17,160 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-28 00:29:17,160 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#1 in 2609s
2013-08-28 00:29:17,174 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13963458 bytes from map-output for attempt_1377648003102_0010_m_000007_0
2013-08-28 00:29:17,174 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13963458, inMemoryMapOutputs.size() -> 3, commitMemory -> 27996388, usedMemory ->139694276
2013-08-28 00:29:17,174 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-28 00:29:17,174 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#2 in 2622s
2013-08-28 00:29:17,977 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010/output/attempt_1377648003102_0010_r_000006_1/map_28.out.merged of size 97734422
2013-08-28 00:29:17,978 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 5 to fetcher#2
2013-08-28 00:29:17,978 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-9-7:8080 to fetcher#2
2013-08-28 00:29:17,978 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 6 to fetcher#4
2013-08-28 00:29:17,979 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-2:8080 to fetcher#4
2013-08-28 00:29:17,980 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 2 to fetcher#1
2013-08-28 00:29:17,980 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-5:8080 to fetcher#1
2013-08-28 00:29:17,983 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000001_0,attempt_1377648003102_0010_m_000014_0,attempt_1377648003102_0010_m_000003_0,attempt_1377648003102_0010_m_000009_0,attempt_1377648003102_0010_m_000037_0 sent hash and received reply
2013-08-28 00:29:18,062 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000038_0,attempt_1377648003102_0010_m_000033_0 sent hash and received reply
2013-08-28 00:29:18,062 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000008_0,attempt_1377648003102_0010_m_000029_0,attempt_1377648003102_0010_m_000036_0,attempt_1377648003102_0010_m_000026_0,attempt_1377648003102_0010_m_000016_0,attempt_1377648003102_0010_m_000034_0 sent hash and received reply
2013-08-28 00:29:18,065 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000001_0 decomp: 13928202 len: 13928206 to MEMORY
2013-08-28 00:29:18,069 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000038_0 decomp: 13989146 len: 13989150 to MEMORY
2013-08-28 00:29:18,074 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000008_0 decomp: 13967098 len: 13967102 to MEMORY
2013-08-28 00:29:18,286 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13989146 bytes from map-output for attempt_1377648003102_0010_m_000038_0
2013-08-28 00:29:18,286 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13989146, inMemoryMapOutputs.size() -> 4, commitMemory -> 41959846, usedMemory ->83844292
2013-08-28 00:29:18,374 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0010_m_000033_0 decomp: 13970946 len: 13970950 to MEMORY
2013-08-28 00:29:18,590 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13967098 bytes from map-output for attempt_1377648003102_0010_m_000008_0
2013-08-28 00:29:18,590 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13967098, inMemoryMapOutputs.size() -> 5, commitMemory -> 55948992, usedMemory ->97815238
2013-08-28 00:29:18,594 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000029_0 decomp: 14013066 len: 14013070 to MEMORY
2013-08-28 00:29:18,748 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970946 bytes from map-output for attempt_1377648003102_0010_m_000033_0
2013-08-28 00:29:18,749 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970946, inMemoryMapOutputs.size() -> 6, commitMemory -> 69916090, usedMemory ->111828304
2013-08-28 00:29:18,750 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#1 in 770s
2013-08-28 00:29:20,138 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14013066 bytes from map-output for attempt_1377648003102_0010_m_000029_0
2013-08-28 00:29:20,138 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14013066, inMemoryMapOutputs.size() -> 7, commitMemory -> 83887036, usedMemory ->111828304
2013-08-28 00:29:20,138 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97900102 > mergeThreshold=86139864. Current usedMemory=111828304
2013-08-28 00:29:20,138 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:29:20,143 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000036_0 decomp: 14032514 len: 14032518 to MEMORY
2013-08-28 00:29:20,425 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:29:20,425 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:29:20,426 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97900011 bytes
2013-08-28 00:29:22,045 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010/output/attempt_1377648003102_0010_r_000006_1/map_7.out.merged of size 97900094
2013-08-28 00:29:23,515 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14032514 bytes from map-output for attempt_1377648003102_0010_m_000036_0
2013-08-28 00:29:23,515 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14032514, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27960716
2013-08-28 00:29:23,519 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000026_0 decomp: 13919258 len: 13919262 to MEMORY
2013-08-28 00:29:24,829 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13919258 bytes from map-output for attempt_1377648003102_0010_m_000026_0
2013-08-28 00:29:24,829 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13919258, inMemoryMapOutputs.size() -> 2, commitMemory -> 14032514, usedMemory ->41879974
2013-08-28 00:29:24,834 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000016_0 decomp: 14025754 len: 14025758 to MEMORY
2013-08-28 00:29:25,867 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14025754 bytes from map-output for attempt_1377648003102_0010_m_000016_0
2013-08-28 00:29:25,867 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14025754, inMemoryMapOutputs.size() -> 3, commitMemory -> 27951772, usedMemory ->55905728
2013-08-28 00:29:25,948 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0010_m_000034_0 decomp: 13972090 len: 13972094 to MEMORY
2013-08-28 00:29:28,635 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13928202 bytes from map-output for attempt_1377648003102_0010_m_000001_0
2013-08-28 00:29:28,635 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13928202, inMemoryMapOutputs.size() -> 4, commitMemory -> 41977526, usedMemory ->69877818
2013-08-28 00:29:28,640 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000014_0 decomp: 13992682 len: 13992686 to MEMORY
2013-08-28 00:29:28,781 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13992682 bytes from map-output for attempt_1377648003102_0010_m_000014_0
2013-08-28 00:29:28,782 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13992682, inMemoryMapOutputs.size() -> 5, commitMemory -> 55905728, usedMemory ->83870500
2013-08-28 00:29:28,788 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000003_0 decomp: 13902826 len: 13902830 to MEMORY
2013-08-28 00:29:28,874 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13972090 bytes from map-output for attempt_1377648003102_0010_m_000034_0
2013-08-28 00:29:28,874 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13972090, inMemoryMapOutputs.size() -> 6, commitMemory -> 69898410, usedMemory ->97773326
2013-08-28 00:29:28,875 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#4 in 10897s
2013-08-28 00:29:34,733 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13902826 bytes from map-output for attempt_1377648003102_0010_m_000003_0
2013-08-28 00:29:34,733 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13902826, inMemoryMapOutputs.size() -> 7, commitMemory -> 83870500, usedMemory ->97773326
2013-08-28 00:29:34,733 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97773326 > mergeThreshold=86139864. Current usedMemory=97773326
2013-08-28 00:29:34,733 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:29:34,828 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000009_0 decomp: 13976874 len: 13976878 to MEMORY
2013-08-28 00:29:35,967 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:29:35,968 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:29:35,968 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97773235 bytes
2013-08-28 00:29:38,021 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010/output/attempt_1377648003102_0010_r_000006_1/map_3.out.merged of size 97773318
2013-08-28 00:29:39,499 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976874 bytes from map-output for attempt_1377648003102_0010_m_000009_0
2013-08-28 00:29:39,499 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976874, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13976874
2013-08-28 00:29:39,503 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0010_m_000037_0 decomp: 14029186 len: 14029190 to MEMORY
2013-08-28 00:29:39,672 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14029186 bytes from map-output for attempt_1377648003102_0010_m_000037_0
2013-08-28 00:29:39,672 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14029186, inMemoryMapOutputs.size() -> 2, commitMemory -> 13976874, usedMemory ->28006060
2013-08-28 00:29:39,673 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#2 in 21695s
2013-08-28 00:29:41,640 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000006_0,attempt_1377648003102_0010_m_000005_0,attempt_1377648003102_0010_m_000004_0,attempt_1377648003102_0010_m_000011_0,attempt_1377648003102_0010_m_000015_0,attempt_1377648003102_0010_m_000020_0 sent hash and received reply
2013-08-28 00:29:41,645 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000006_0 decomp: 14026066 len: 14026070 to MEMORY
2013-08-28 00:31:26,453 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14026066 bytes from map-output for attempt_1377648003102_0010_m_000006_0
2013-08-28 00:31:26,453 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14026066, inMemoryMapOutputs.size() -> 3, commitMemory -> 28006060, usedMemory ->42032126
2013-08-28 00:31:26,525 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000005_0 decomp: 13978642 len: 13978646 to MEMORY
2013-08-28 00:31:51,870 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13978642 bytes from map-output for attempt_1377648003102_0010_m_000005_0
2013-08-28 00:31:51,871 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13978642, inMemoryMapOutputs.size() -> 4, commitMemory -> 42032126, usedMemory ->56010768
2013-08-28 00:31:51,875 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000004_0 decomp: 13911874 len: 13911878 to MEMORY
2013-08-28 00:32:13,238 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13911874 bytes from map-output for attempt_1377648003102_0010_m_000004_0
2013-08-28 00:32:13,239 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13911874, inMemoryMapOutputs.size() -> 5, commitMemory -> 56010768, usedMemory ->69922642
2013-08-28 00:32:13,243 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000011_0 decomp: 13979994 len: 13979998 to MEMORY
2013-08-28 00:32:26,921 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13979994 bytes from map-output for attempt_1377648003102_0010_m_000011_0
2013-08-28 00:32:26,922 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13979994, inMemoryMapOutputs.size() -> 6, commitMemory -> 69922642, usedMemory ->83902636
2013-08-28 00:32:26,926 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000015_0 decomp: 13941098 len: 13941102 to MEMORY
2013-08-28 00:32:33,214 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13941098 bytes from map-output for attempt_1377648003102_0010_m_000015_0
2013-08-28 00:32:33,215 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13941098, inMemoryMapOutputs.size() -> 7, commitMemory -> 83902636, usedMemory ->97843734
2013-08-28 00:32:33,215 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97843734 > mergeThreshold=86139864. Current usedMemory=97843734
2013-08-28 00:32:33,215 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:32:33,219 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000020_0 decomp: 13992058 len: 13992062 to MEMORY
2013-08-28 00:32:33,432 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:32:33,433 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:32:33,433 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97843643 bytes
2013-08-28 00:32:35,111 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0010_r_000006_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0010/output/attempt_1377648003102_0010_r_000006_1/map_4.out.merged of size 97843726
2013-08-28 00:32:35,450 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13992058 bytes from map-output for attempt_1377648003102_0010_m_000020_0
2013-08-28 00:32:35,450 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13992058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13992058
2013-08-28 00:32:35,451 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#5 in 205351s
2013-08-28 00:32:35,451 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 4 to fetcher#5
2013-08-28 00:32:35,451 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-4:8080 to fetcher#5
2013-08-28 00:32:35,456 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0010&reduce=6&map=attempt_1377648003102_0010_m_000025_0,attempt_1377648003102_0010_m_000030_0,attempt_1377648003102_0010_m_000035_0,attempt_1377648003102_0010_m_000039_0 sent hash and received reply
2013-08-28 00:32:35,551 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000025_0 decomp: 13982074 len: 13982078 to MEMORY
2013-08-28 00:32:38,204 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13982074 bytes from map-output for attempt_1377648003102_0010_m_000025_0
2013-08-28 00:32:38,204 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13982074, inMemoryMapOutputs.size() -> 2, commitMemory -> 13992058, usedMemory ->27974132
2013-08-28 00:32:38,208 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000030_0 decomp: 13904178 len: 13904182 to MEMORY
2013-08-28 00:32:40,101 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13904178 bytes from map-output for attempt_1377648003102_0010_m_000030_0
2013-08-28 00:32:40,102 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13904178, inMemoryMapOutputs.size() -> 3, commitMemory -> 27974132, usedMemory ->41878310
2013-08-28 00:32:40,106 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000035_0 decomp: 13986026 len: 13986030 to MEMORY
2013-08-28 00:32:43,437 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13986026 bytes from map-output for attempt_1377648003102_0010_m_000035_0
2013-08-28 00:32:43,437 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13986026, inMemoryMapOutputs.size() -> 4, commitMemory -> 41878310, usedMemory ->55864336
2013-08-28 00:32:43,535 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0010_m_000039_0 decomp: 14035322 len: 14035326 to MEMORY
2013-08-28 00:32:44,510 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14035322 bytes from map-output for attempt_1377648003102_0010_m_000039_0
2013-08-28 00:32:44,510 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14035322, inMemoryMapOutputs.size() -> 5, commitMemory -> 55864336, usedMemory ->69899658
2013-08-28 00:32:44,510 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#5 in 9059s
2013-08-28 00:32:44,511 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-28 00:32:44,525 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-28 00:32:44,711 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-28 00:32:44,711 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69899593 bytes
2013-08-28 00:32:45,496 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69899658 bytes to disk to satisfy reduce memory limit
2013-08-28 00:32:45,498 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 559001492 bytes from disk
2013-08-28 00:32:45,499 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-28 00:32:45,499 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-28 00:32:45,567 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 559001390 bytes
2013-08-28 00:32:45,746 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-28 00:33:07,158 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377648003102_0010_r_000006_1/part-r-00006
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377648003102_0010_r_000006_1/part-r-00006: File does not exist. Holder DFSClient_attempt_1377648003102_0010_r_000006_1_-1693966612_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-28 00:33:07,158 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-28 00:33:07,161 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

