2013-08-28 00:30:25,807 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-28 00:30:25,878 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-28 00:30:26,086 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-28 00:30:26,236 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-28 00:30:26,237 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-28 00:30:26,260 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-28 00:30:26,261 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377648003102_0006, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-28 00:30:26,388 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-28 00:30:27,158 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006
2013-08-28 00:30:27,454 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-28 00:30:27,455 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-28 00:30:27,456 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-28 00:30:27,457 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-28 00:30:27,459 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-28 00:30:27,459 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-28 00:30:27,460 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-28 00:30:27,461 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-28 00:30:27,461 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-28 00:30:27,732 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-28 00:30:28,322 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-28 00:30:28,455 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f9da97e
2013-08-28 00:30:28,500 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-28 00:30:28,507 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377648003102_0006_r_000009_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-28 00:30:28,531 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 3 to fetcher#5
2013-08-28 00:30:28,532 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-5:8080 to fetcher#5
2013-08-28 00:30:28,532 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 3 to fetcher#4
2013-08-28 00:30:28,533 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-6:8080 to fetcher#4
2013-08-28 00:30:28,533 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 2 to fetcher#3
2013-08-28 00:30:28,534 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-2:8080 to fetcher#3
2013-08-28 00:30:28,534 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 4 to fetcher#2
2013-08-28 00:30:28,534 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-7:8080 to fetcher#2
2013-08-28 00:30:28,543 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377648003102_0006_r_000009_1: Got 40 new map-outputs
2013-08-28 00:30:28,543 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 4 to fetcher#1
2013-08-28 00:30:28,543 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-3:8080 to fetcher#1
2013-08-28 00:30:28,798 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000000_0,attempt_1377648003102_0006_m_000003_0,attempt_1377648003102_0006_m_000008_0 sent hash and received reply
2013-08-28 00:30:28,800 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000019_0,attempt_1377648003102_0006_m_000030_0,attempt_1377648003102_0006_m_000033_0,attempt_1377648003102_0006_m_000039_0 sent hash and received reply
2013-08-28 00:30:28,803 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000006_0,attempt_1377648003102_0006_m_000005_0,attempt_1377648003102_0006_m_000007_0,attempt_1377648003102_0006_m_000009_0 sent hash and received reply
2013-08-28 00:30:28,803 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000002_0,attempt_1377648003102_0006_m_000004_0,attempt_1377648003102_0006_m_000014_0 sent hash and received reply
2013-08-28 00:30:28,799 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000010_0,attempt_1377648003102_0006_m_000011_0 sent hash and received reply
2013-08-28 00:30:28,852 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000019_0 decomp: 13868194 len: 13868198 to MEMORY
2013-08-28 00:30:28,856 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0006_m_000010_0 decomp: 13871730 len: 13871734 to MEMORY
2013-08-28 00:30:28,870 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000000_0 decomp: 13911770 len: 13911774 to MEMORY
2013-08-28 00:30:28,870 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000006_0 decomp: 13808498 len: 13808502 to MEMORY
2013-08-28 00:30:28,887 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000002_0 decomp: 13841986 len: 13841990 to MEMORY
2013-08-28 00:30:29,928 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13841986 bytes from map-output for attempt_1377648003102_0006_m_000002_0
2013-08-28 00:30:29,931 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13841986, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->69302178
2013-08-28 00:30:30,122 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000004_0 decomp: 13863514 len: 13863518 to MEMORY
2013-08-28 00:30:30,343 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13911770 bytes from map-output for attempt_1377648003102_0006_m_000000_0
2013-08-28 00:30:30,344 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13911770, inMemoryMapOutputs.size() -> 2, commitMemory -> 13841986, usedMemory ->83165692
2013-08-28 00:30:30,350 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000003_0 decomp: 13900954 len: 13900958 to MEMORY
2013-08-28 00:30:31,255 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13871730 bytes from map-output for attempt_1377648003102_0006_m_000010_0
2013-08-28 00:30:31,255 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13871730, inMemoryMapOutputs.size() -> 3, commitMemory -> 27753756, usedMemory ->97066646
2013-08-28 00:30:31,260 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0006_m_000011_0 decomp: 13814426 len: 13814430 to MEMORY
2013-08-28 00:30:31,484 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13868194 bytes from map-output for attempt_1377648003102_0006_m_000019_0
2013-08-28 00:30:31,484 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13868194, inMemoryMapOutputs.size() -> 4, commitMemory -> 41625486, usedMemory ->110881072
2013-08-28 00:30:31,489 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000030_0 decomp: 13861746 len: 13861750 to MEMORY
2013-08-28 00:30:32,021 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13814426 bytes from map-output for attempt_1377648003102_0006_m_000011_0
2013-08-28 00:30:32,021 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13814426, inMemoryMapOutputs.size() -> 5, commitMemory -> 55493680, usedMemory ->124742818
2013-08-28 00:30:32,022 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#3 in 3488s
2013-08-28 00:30:32,023 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 7 to fetcher#3
2013-08-28 00:30:32,023 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-2:8080 to fetcher#3
2013-08-28 00:30:32,030 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000018_0,attempt_1377648003102_0006_m_000023_0,attempt_1377648003102_0006_m_000028_0,attempt_1377648003102_0006_m_000032_0,attempt_1377648003102_0006_m_000031_0,attempt_1377648003102_0006_m_000036_0,attempt_1377648003102_0006_m_000038_0 sent hash and received reply
2013-08-28 00:30:32,146 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0006_m_000018_0 decomp: 13828882 len: 13828886 to MEMORY
2013-08-28 00:30:32,153 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13863514 bytes from map-output for attempt_1377648003102_0006_m_000004_0
2013-08-28 00:30:32,154 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13863514, inMemoryMapOutputs.size() -> 6, commitMemory -> 69308106, usedMemory ->138571700
2013-08-28 00:30:32,155 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-28 00:30:32,155 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#5 in 3623s
2013-08-28 00:30:32,155 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 5 to fetcher#5
2013-08-28 00:30:32,156 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-9-4:8080 to fetcher#5
2013-08-28 00:30:32,195 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13900954 bytes from map-output for attempt_1377648003102_0006_m_000003_0
2013-08-28 00:30:32,195 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13900954, inMemoryMapOutputs.size() -> 7, commitMemory -> 83171620, usedMemory ->138571700
2013-08-28 00:30:32,195 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97072574 > mergeThreshold=86139864. Current usedMemory=138571700
2013-08-28 00:30:32,195 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:30:32,196 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-28 00:30:32,196 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#4 in 3663s
2013-08-28 00:30:32,513 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:30:32,521 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:30:32,522 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97072483 bytes
2013-08-28 00:30:32,727 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13808498 bytes from map-output for attempt_1377648003102_0006_m_000006_0
2013-08-28 00:30:32,727 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13808498, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138571700
2013-08-28 00:30:32,728 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-28 00:30:32,728 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#2 in 4194s
2013-08-28 00:30:33,119 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13828882 bytes from map-output for attempt_1377648003102_0006_m_000018_0
2013-08-28 00:30:33,119 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13828882, inMemoryMapOutputs.size() -> 2, commitMemory -> 13808498, usedMemory ->138571700
2013-08-28 00:30:33,120 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-28 00:30:33,120 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#3 in 1097s
2013-08-28 00:30:34,519 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0006_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006/output/attempt_1377648003102_0006_r_000009_1/map_11.out.merged of size 97072566
2013-08-28 00:30:34,520 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 10 to fetcher#3
2013-08-28 00:30:34,520 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 10 of 10 to hadoop-9-7:8080 to fetcher#3
2013-08-28 00:30:34,520 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 6 to fetcher#4
2013-08-28 00:30:34,521 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-2:8080 to fetcher#4
2013-08-28 00:30:34,522 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 2 to fetcher#2
2013-08-28 00:30:34,522 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-6:8080 to fetcher#2
2013-08-28 00:30:34,525 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000023_0,attempt_1377648003102_0006_m_000036_0,attempt_1377648003102_0006_m_000038_0,attempt_1377648003102_0006_m_000031_0,attempt_1377648003102_0006_m_000028_0,attempt_1377648003102_0006_m_000032_0 sent hash and received reply
2013-08-28 00:30:34,528 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000013_0,attempt_1377648003102_0006_m_000008_0 sent hash and received reply
2013-08-28 00:30:34,530 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000023_0 decomp: 13853322 len: 13853326 to MEMORY
2013-08-28 00:30:34,611 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000013_0 decomp: 13861746 len: 13861750 to MEMORY
2013-08-28 00:30:35,565 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13861746 bytes from map-output for attempt_1377648003102_0006_m_000013_0
2013-08-28 00:30:35,566 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13861746, inMemoryMapOutputs.size() -> 3, commitMemory -> 27637380, usedMemory ->69214194
2013-08-28 00:30:35,572 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000008_0 decomp: 13894714 len: 13894718 to MEMORY
2013-08-28 00:30:36,153 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13853322 bytes from map-output for attempt_1377648003102_0006_m_000023_0
2013-08-28 00:30:36,154 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13853322, inMemoryMapOutputs.size() -> 4, commitMemory -> 41499126, usedMemory ->83108908
2013-08-28 00:30:36,158 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000036_0 decomp: 13860914 len: 13860918 to MEMORY
2013-08-28 00:30:37,122 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13860914 bytes from map-output for attempt_1377648003102_0006_m_000036_0
2013-08-28 00:30:37,122 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13860914, inMemoryMapOutputs.size() -> 5, commitMemory -> 55352448, usedMemory ->96969822
2013-08-28 00:30:37,127 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000038_0 decomp: 13812138 len: 13812142 to MEMORY
2013-08-28 00:30:37,127 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000020_0,attempt_1377648003102_0006_m_000012_0,attempt_1377648003102_0006_m_000021_0,attempt_1377648003102_0006_m_000024_0,attempt_1377648003102_0006_m_000026_0,attempt_1377648003102_0006_m_000029_0,attempt_1377648003102_0006_m_000035_0,attempt_1377648003102_0006_m_000005_0,attempt_1377648003102_0006_m_000009_0,attempt_1377648003102_0006_m_000007_0 sent hash and received reply
2013-08-28 00:30:37,223 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0006_m_000020_0 decomp: 13809330 len: 13809334 to MEMORY
2013-08-28 00:30:37,228 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13894714 bytes from map-output for attempt_1377648003102_0006_m_000008_0
2013-08-28 00:30:37,229 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13894714, inMemoryMapOutputs.size() -> 6, commitMemory -> 69213362, usedMemory ->124591290
2013-08-28 00:30:37,229 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#2 in 2707s
2013-08-28 00:30:37,229 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 5 to fetcher#2
2013-08-28 00:30:37,229 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-9-5:8080 to fetcher#2
2013-08-28 00:30:37,235 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000017_0,attempt_1377648003102_0006_m_000015_0,attempt_1377648003102_0006_m_000022_0,attempt_1377648003102_0006_m_000037_0,attempt_1377648003102_0006_m_000014_0 sent hash and received reply
2013-08-28 00:30:37,240 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000017_0 decomp: 13870170 len: 13870174 to MEMORY
2013-08-28 00:30:37,817 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13870170 bytes from map-output for attempt_1377648003102_0006_m_000017_0
2013-08-28 00:30:37,817 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13870170, inMemoryMapOutputs.size() -> 7, commitMemory -> 83108076, usedMemory ->138461460
2013-08-28 00:30:37,818 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=96978246 > mergeThreshold=86139864. Current usedMemory=138461460
2013-08-28 00:30:37,818 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:30:37,820 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-28 00:30:37,820 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#2 in 591s
2013-08-28 00:30:37,944 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13812138 bytes from map-output for attempt_1377648003102_0006_m_000038_0
2013-08-28 00:30:37,944 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13812138, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138461460
2013-08-28 00:30:37,945 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-28 00:30:37,945 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#4 in 3425s
2013-08-28 00:30:38,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:30:38,046 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:30:38,047 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 96978155 bytes
2013-08-28 00:30:39,578 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0006_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006/output/attempt_1377648003102_0006_r_000009_1/map_6.out.merged of size 96978238
2013-08-28 00:30:39,578 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 4 to fetcher#4
2013-08-28 00:30:39,578 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-5:8080 to fetcher#4
2013-08-28 00:30:39,578 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 3 to fetcher#2
2013-08-28 00:30:39,579 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-2:8080 to fetcher#2
2013-08-28 00:30:39,583 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000031_0,attempt_1377648003102_0006_m_000028_0,attempt_1377648003102_0006_m_000032_0 sent hash and received reply
2013-08-28 00:30:39,583 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000022_0,attempt_1377648003102_0006_m_000015_0,attempt_1377648003102_0006_m_000014_0,attempt_1377648003102_0006_m_000037_0 sent hash and received reply
2013-08-28 00:30:39,663 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000022_0 decomp: 13811202 len: 13811206 to MEMORY
2013-08-28 00:30:39,667 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000031_0 decomp: 13860602 len: 13860606 to MEMORY
2013-08-28 00:30:39,883 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13861746 bytes from map-output for attempt_1377648003102_0006_m_000030_0
2013-08-28 00:30:39,883 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13861746, inMemoryMapOutputs.size() -> 2, commitMemory -> 13812138, usedMemory ->69155018
2013-08-28 00:30:39,887 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000033_0 decomp: 13881922 len: 13881926 to MEMORY
2013-08-28 00:30:40,070 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13811202 bytes from map-output for attempt_1377648003102_0006_m_000022_0
2013-08-28 00:30:40,070 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13811202, inMemoryMapOutputs.size() -> 3, commitMemory -> 27673884, usedMemory ->83036940
2013-08-28 00:30:40,076 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000015_0 decomp: 13905010 len: 13905014 to MEMORY
2013-08-28 00:30:40,942 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13905010 bytes from map-output for attempt_1377648003102_0006_m_000015_0
2013-08-28 00:30:40,942 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13905010, inMemoryMapOutputs.size() -> 4, commitMemory -> 41485086, usedMemory ->96941950
2013-08-28 00:30:41,087 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000014_0 decomp: 13832210 len: 13832214 to MEMORY
2013-08-28 00:30:41,460 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13832210 bytes from map-output for attempt_1377648003102_0006_m_000014_0
2013-08-28 00:30:41,461 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13832210, inMemoryMapOutputs.size() -> 5, commitMemory -> 55390096, usedMemory ->110774160
2013-08-28 00:30:41,473 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377648003102_0006_m_000037_0 decomp: 13812242 len: 13812246 to MEMORY
2013-08-28 00:30:41,602 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13860602 bytes from map-output for attempt_1377648003102_0006_m_000031_0
2013-08-28 00:30:41,602 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13860602, inMemoryMapOutputs.size() -> 6, commitMemory -> 69222306, usedMemory ->124586402
2013-08-28 00:30:41,607 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000028_0 decomp: 13881090 len: 13881094 to MEMORY
2013-08-28 00:30:41,764 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13812242 bytes from map-output for attempt_1377648003102_0006_m_000037_0
2013-08-28 00:30:41,765 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13812242, inMemoryMapOutputs.size() -> 7, commitMemory -> 83082908, usedMemory ->138467492
2013-08-28 00:30:41,765 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=96895150 > mergeThreshold=86139864. Current usedMemory=138467492
2013-08-28 00:30:41,765 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:30:41,765 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#4 in 2187s
2013-08-28 00:30:41,877 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13881922 bytes from map-output for attempt_1377648003102_0006_m_000033_0
2013-08-28 00:30:41,877 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13881922, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138467492
2013-08-28 00:30:41,878 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-28 00:30:41,878 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#1 in 13335s
2013-08-28 00:30:42,121 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:30:42,122 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:30:42,122 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 96895059 bytes
2013-08-28 00:30:42,464 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13809330 bytes from map-output for attempt_1377648003102_0006_m_000020_0
2013-08-28 00:30:42,464 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13809330, inMemoryMapOutputs.size() -> 2, commitMemory -> 13881922, usedMemory ->138467492
2013-08-28 00:30:42,465 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-28 00:30:42,466 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#3 in 7945s
2013-08-28 00:30:43,170 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0006_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006/output/attempt_1377648003102_0006_r_000009_1/map_22.out.merged of size 96895142
2013-08-28 00:30:43,170 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 1 to fetcher#3
2013-08-28 00:30:43,170 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-3:8080 to fetcher#3
2013-08-28 00:30:43,171 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 9 to fetcher#1
2013-08-28 00:30:43,171 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 9 of 9 to hadoop-9-7:8080 to fetcher#1
2013-08-28 00:30:43,174 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000039_0 sent hash and received reply
2013-08-28 00:30:43,177 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000026_0,attempt_1377648003102_0006_m_000005_0,attempt_1377648003102_0006_m_000029_0,attempt_1377648003102_0006_m_000024_0,attempt_1377648003102_0006_m_000009_0,attempt_1377648003102_0006_m_000021_0,attempt_1377648003102_0006_m_000012_0,attempt_1377648003102_0006_m_000007_0,attempt_1377648003102_0006_m_000035_0 sent hash and received reply
2013-08-28 00:30:43,179 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377648003102_0006_m_000039_0 decomp: 13901266 len: 13901270 to MEMORY
2013-08-28 00:30:43,182 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000026_0 decomp: 13847602 len: 13847606 to MEMORY
2013-08-28 00:30:46,006 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13881090 bytes from map-output for attempt_1377648003102_0006_m_000028_0
2013-08-28 00:30:46,006 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13881090, inMemoryMapOutputs.size() -> 3, commitMemory -> 27691252, usedMemory ->69321210
2013-08-28 00:30:46,090 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377648003102_0006_m_000032_0 decomp: 13863202 len: 13863206 to MEMORY
2013-08-28 00:30:47,610 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13847602 bytes from map-output for attempt_1377648003102_0006_m_000026_0
2013-08-28 00:30:47,610 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13847602, inMemoryMapOutputs.size() -> 4, commitMemory -> 41572342, usedMemory ->83184412
2013-08-28 00:30:47,615 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000005_0 decomp: 13827322 len: 13827326 to MEMORY
2013-08-28 00:30:47,996 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13863202 bytes from map-output for attempt_1377648003102_0006_m_000032_0
2013-08-28 00:30:47,997 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13863202, inMemoryMapOutputs.size() -> 5, commitMemory -> 55419944, usedMemory ->97011734
2013-08-28 00:30:47,997 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#2 in 8419s
2013-08-28 00:30:51,360 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901266 bytes from map-output for attempt_1377648003102_0006_m_000039_0
2013-08-28 00:30:51,360 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901266, inMemoryMapOutputs.size() -> 6, commitMemory -> 69283146, usedMemory ->97011734
2013-08-28 00:30:51,361 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#3 in 8191s
2013-08-28 00:30:51,449 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13827322 bytes from map-output for attempt_1377648003102_0006_m_000005_0
2013-08-28 00:30:51,449 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13827322, inMemoryMapOutputs.size() -> 7, commitMemory -> 83184412, usedMemory ->97011734
2013-08-28 00:30:51,449 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97011734 > mergeThreshold=86139864. Current usedMemory=97011734
2013-08-28 00:30:51,449 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:30:51,458 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000029_0 decomp: 13821810 len: 13821814 to MEMORY
2013-08-28 00:30:51,831 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:30:51,832 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:30:51,832 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97011643 bytes
2013-08-28 00:30:53,528 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0006_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006/output/attempt_1377648003102_0006_r_000009_1/map_20.out.merged of size 97011726
2013-08-28 00:30:57,207 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13821810 bytes from map-output for attempt_1377648003102_0006_m_000029_0
2013-08-28 00:30:57,207 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13821810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13821810
2013-08-28 00:30:57,212 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000024_0 decomp: 13859042 len: 13859046 to MEMORY
2013-08-28 00:30:59,661 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13859042 bytes from map-output for attempt_1377648003102_0006_m_000024_0
2013-08-28 00:30:59,662 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13859042, inMemoryMapOutputs.size() -> 2, commitMemory -> 13821810, usedMemory ->27680852
2013-08-28 00:30:59,669 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000009_0 decomp: 13828154 len: 13828158 to MEMORY
2013-08-28 00:31:01,028 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377648003102_0006&reduce=9&map=attempt_1377648003102_0006_m_000001_0,attempt_1377648003102_0006_m_000016_0,attempt_1377648003102_0006_m_000025_0,attempt_1377648003102_0006_m_000027_0,attempt_1377648003102_0006_m_000034_0 sent hash and received reply
2013-08-28 00:31:01,122 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000001_0 decomp: 13790922 len: 13790926 to MEMORY
2013-08-28 00:31:01,854 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13828154 bytes from map-output for attempt_1377648003102_0006_m_000009_0
2013-08-28 00:31:01,854 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13828154, inMemoryMapOutputs.size() -> 3, commitMemory -> 27680852, usedMemory ->55299928
2013-08-28 00:31:01,859 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000021_0 decomp: 13815778 len: 13815782 to MEMORY
2013-08-28 00:31:06,855 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13815778 bytes from map-output for attempt_1377648003102_0006_m_000021_0
2013-08-28 00:31:06,856 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13815778, inMemoryMapOutputs.size() -> 4, commitMemory -> 41509006, usedMemory ->69115706
2013-08-28 00:31:06,860 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000012_0 decomp: 13736842 len: 13736846 to MEMORY
2013-08-28 00:31:09,144 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13736842 bytes from map-output for attempt_1377648003102_0006_m_000012_0
2013-08-28 00:31:09,144 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13736842, inMemoryMapOutputs.size() -> 5, commitMemory -> 55324784, usedMemory ->82852548
2013-08-28 00:31:09,241 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000007_0 decomp: 13856234 len: 13856238 to MEMORY
2013-08-28 00:31:12,180 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13856234 bytes from map-output for attempt_1377648003102_0006_m_000007_0
2013-08-28 00:31:12,181 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13856234, inMemoryMapOutputs.size() -> 6, commitMemory -> 69061626, usedMemory ->96708782
2013-08-28 00:31:12,185 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377648003102_0006_m_000035_0 decomp: 13812658 len: 13812662 to MEMORY
2013-08-28 00:31:14,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13812658 bytes from map-output for attempt_1377648003102_0006_m_000035_0
2013-08-28 00:31:14,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13812658, inMemoryMapOutputs.size() -> 7, commitMemory -> 82917860, usedMemory ->110521440
2013-08-28 00:31:14,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=96730518 > mergeThreshold=86139864. Current usedMemory=110521440
2013-08-28 00:31:14,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 00:31:14,819 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#1 in 31648s
2013-08-28 00:31:15,034 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 00:31:15,034 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 00:31:15,035 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 96730427 bytes
2013-08-28 00:31:15,450 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13790922 bytes from map-output for attempt_1377648003102_0006_m_000001_0
2013-08-28 00:31:15,450 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13790922, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->110521440
2013-08-28 00:31:15,554 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000016_0 decomp: 13843546 len: 13843550 to MEMORY
2013-08-28 00:31:16,619 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377648003102_0006_r_000009_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377648003102_0006/output/attempt_1377648003102_0006_r_000009_1/map_12.out.merged of size 96730510
2013-08-28 00:31:38,101 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13843546 bytes from map-output for attempt_1377648003102_0006_m_000016_0
2013-08-28 00:31:38,101 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13843546, inMemoryMapOutputs.size() -> 2, commitMemory -> 13790922, usedMemory ->27634468
2013-08-28 00:31:38,106 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000025_0 decomp: 13805170 len: 13805174 to MEMORY
2013-08-28 00:31:55,513 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13805170 bytes from map-output for attempt_1377648003102_0006_m_000025_0
2013-08-28 00:31:55,513 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13805170, inMemoryMapOutputs.size() -> 3, commitMemory -> 27634468, usedMemory ->41439638
2013-08-28 00:31:55,518 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000027_0 decomp: 13852802 len: 13852806 to MEMORY
2013-08-28 00:32:10,462 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13852802 bytes from map-output for attempt_1377648003102_0006_m_000027_0
2013-08-28 00:32:10,462 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13852802, inMemoryMapOutputs.size() -> 4, commitMemory -> 41439638, usedMemory ->55292440
2013-08-28 00:32:10,467 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377648003102_0006_m_000034_0 decomp: 13815466 len: 13815470 to MEMORY
2013-08-28 00:32:34,399 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13815466 bytes from map-output for attempt_1377648003102_0006_m_000034_0
2013-08-28 00:32:34,399 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13815466, inMemoryMapOutputs.size() -> 5, commitMemory -> 55292440, usedMemory ->69107906
2013-08-28 00:32:34,400 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#5 in 122245s
2013-08-28 00:32:34,400 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-28 00:32:34,410 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-28 00:32:34,636 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-28 00:32:34,636 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69107841 bytes
2013-08-28 00:32:35,649 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69107906 bytes to disk to satisfy reduce memory limit
2013-08-28 00:32:35,651 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 553796084 bytes from disk
2013-08-28 00:32:35,653 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-28 00:32:35,653 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-28 00:32:35,882 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 553795982 bytes
2013-08-28 00:32:35,982 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-28 00:32:50,725 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-28 00:32:50,726 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-28 00:32:50,730 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-5/_temporary/1/_temporary/attempt_1377648003102_0006_r_000009_1/part-r-00009
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-5/_temporary/1/_temporary/attempt_1377648003102_0006_r_000009_1/part-r-00009: File does not exist. Holder DFSClient_attempt_1377648003102_0006_r_000009_1_316639500_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
