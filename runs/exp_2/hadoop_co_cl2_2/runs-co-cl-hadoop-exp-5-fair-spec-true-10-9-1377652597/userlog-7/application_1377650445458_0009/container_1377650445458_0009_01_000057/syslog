2013-08-28 01:07:33,704 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-28 01:07:33,755 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-28 01:07:33,957 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-28 01:07:34,116 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-28 01:07:34,116 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-28 01:07:34,139 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-28 01:07:34,139 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377650445458_0009, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-28 01:07:34,296 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-28 01:07:35,069 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009
2013-08-28 01:07:35,439 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-28 01:07:35,440 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-28 01:07:35,441 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-28 01:07:35,442 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-28 01:07:35,443 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-28 01:07:35,444 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-28 01:07:35,445 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-28 01:07:35,446 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-28 01:07:35,446 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-28 01:07:35,715 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-28 01:07:36,311 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-28 01:07:36,462 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30176605
2013-08-28 01:07:36,506 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-28 01:07:36,513 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377650445458_0009_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
2013-08-28 01:07:36,537 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 4 to fetcher#5
2013-08-28 01:07:36,537 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-7:8080 to fetcher#5
2013-08-28 01:07:36,537 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 1 to fetcher#4
2013-08-28 01:07:36,541 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-3:8080 to fetcher#4
2013-08-28 01:07:36,541 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 1 to fetcher#3
2013-08-28 01:07:36,542 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-4:8080 to fetcher#3
2013-08-28 01:07:36,542 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 1 to fetcher#2
2013-08-28 01:07:36,542 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-2:8080 to fetcher#2
2013-08-28 01:07:36,542 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 1 to fetcher#1
2013-08-28 01:07:36,543 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-6:8080 to fetcher#1
2013-08-28 01:07:36,553 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377650445458_0009_r_000004_0: Got 40 new map-outputs
2013-08-28 01:07:36,800 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000005_0 sent hash and received reply
2013-08-28 01:07:36,803 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000002_0 sent hash and received reply
2013-08-28 01:07:36,805 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000003_0 sent hash and received reply
2013-08-28 01:07:36,858 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000002_0 decomp: 14034386 len: 14034390 to MEMORY
2013-08-28 01:07:36,862 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377650445458_0009_m_000005_0 decomp: 13875266 len: 13875270 to MEMORY
2013-08-28 01:07:36,866 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377650445458_0009_m_000003_0 decomp: 13973962 len: 13973966 to MEMORY
2013-08-28 01:07:37,616 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13875266 bytes from map-output for attempt_1377650445458_0009_m_000005_0
2013-08-28 01:07:37,623 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13875266, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41883614
2013-08-28 01:07:37,627 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#1 in 1083s
2013-08-28 01:07:37,628 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 4 to fetcher#1
2013-08-28 01:07:37,628 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-5:8080 to fetcher#1
2013-08-28 01:07:37,636 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000015_0,attempt_1377650445458_0009_m_000010_0,attempt_1377650445458_0009_m_000022_0,attempt_1377650445458_0009_m_000039_0 sent hash and received reply
2013-08-28 01:07:37,646 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377650445458_0009_m_000015_0 decomp: 13972714 len: 13972718 to MEMORY
2013-08-28 01:07:37,685 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14034386 bytes from map-output for attempt_1377650445458_0009_m_000002_0
2013-08-28 01:07:37,686 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14034386, inMemoryMapOutputs.size() -> 2, commitMemory -> 13875266, usedMemory ->55856328
2013-08-28 01:07:37,687 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#4 in 1146s
2013-08-28 01:07:37,687 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 3 to fetcher#4
2013-08-28 01:07:37,687 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-3:8080 to fetcher#4
2013-08-28 01:07:37,693 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000014_0,attempt_1377650445458_0009_m_000020_0,attempt_1377650445458_0009_m_000027_0 sent hash and received reply
2013-08-28 01:07:37,709 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000014_0 decomp: 13896586 len: 13896590 to MEMORY
2013-08-28 01:07:39,001 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896586 bytes from map-output for attempt_1377650445458_0009_m_000014_0
2013-08-28 01:07:39,001 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896586, inMemoryMapOutputs.size() -> 3, commitMemory -> 27909652, usedMemory ->69752914
2013-08-28 01:07:39,257 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000020_0 decomp: 13981554 len: 13981558 to MEMORY
2013-08-28 01:07:39,684 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13981554 bytes from map-output for attempt_1377650445458_0009_m_000020_0
2013-08-28 01:07:39,684 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13981554, inMemoryMapOutputs.size() -> 4, commitMemory -> 41806238, usedMemory ->83734468
2013-08-28 01:07:39,693 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000027_0 decomp: 13888786 len: 13888790 to MEMORY
2013-08-28 01:07:40,435 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13888786 bytes from map-output for attempt_1377650445458_0009_m_000027_0
2013-08-28 01:07:40,435 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13888786, inMemoryMapOutputs.size() -> 5, commitMemory -> 55787792, usedMemory ->97623254
2013-08-28 01:07:40,437 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#4 in 2749s
2013-08-28 01:07:42,585 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13972714 bytes from map-output for attempt_1377650445458_0009_m_000015_0
2013-08-28 01:07:42,585 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13972714, inMemoryMapOutputs.size() -> 6, commitMemory -> 69676578, usedMemory ->97623254
2013-08-28 01:07:42,589 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377650445458_0009_m_000010_0 decomp: 13970218 len: 13970222 to MEMORY
2013-08-28 01:07:43,295 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13973962 bytes from map-output for attempt_1377650445458_0009_m_000003_0
2013-08-28 01:07:43,296 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13973962, inMemoryMapOutputs.size() -> 7, commitMemory -> 83649292, usedMemory ->111593472
2013-08-28 01:07:43,296 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97623254 > mergeThreshold=86139864. Current usedMemory=111593472
2013-08-28 01:07:43,296 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 01:07:43,297 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#3 in 6756s
2013-08-28 01:07:43,297 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 6 to fetcher#4
2013-08-28 01:07:43,297 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-4:8080 to fetcher#4
2013-08-28 01:07:43,303 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000013_0,attempt_1377650445458_0009_m_000023_0,attempt_1377650445458_0009_m_000016_0,attempt_1377650445458_0009_m_000028_0,attempt_1377650445458_0009_m_000032_0,attempt_1377650445458_0009_m_000034_0 sent hash and received reply
2013-08-28 01:07:43,548 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000013_0 decomp: 13914370 len: 13914374 to MEMORY
2013-08-28 01:07:43,959 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 01:07:43,967 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 01:07:43,968 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97623163 bytes
2013-08-28 01:07:47,373 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377650445458_0009_r_000004_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009/output/attempt_1377650445458_0009_r_000004_0/map_5.out.merged of size 97623246
2013-08-28 01:07:47,949 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970218 bytes from map-output for attempt_1377650445458_0009_m_000010_0
2013-08-28 01:07:47,949 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970218, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27884588
2013-08-28 01:07:47,953 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377650445458_0009_m_000022_0 decomp: 13912706 len: 13912710 to MEMORY
2013-08-28 01:07:50,539 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13914370 bytes from map-output for attempt_1377650445458_0009_m_000013_0
2013-08-28 01:07:50,540 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13914370, inMemoryMapOutputs.size() -> 2, commitMemory -> 13970218, usedMemory ->41797294
2013-08-28 01:07:50,660 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000023_0 decomp: 13908026 len: 13908030 to MEMORY
2013-08-28 01:07:52,500 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13912706 bytes from map-output for attempt_1377650445458_0009_m_000022_0
2013-08-28 01:07:52,500 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13912706, inMemoryMapOutputs.size() -> 3, commitMemory -> 27884588, usedMemory ->55705320
2013-08-28 01:07:52,505 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377650445458_0009_m_000039_0 decomp: 13927266 len: 13927270 to MEMORY
2013-08-28 01:07:53,187 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13927266 bytes from map-output for attempt_1377650445458_0009_m_000039_0
2013-08-28 01:07:53,188 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13927266, inMemoryMapOutputs.size() -> 4, commitMemory -> 41797294, usedMemory ->69632586
2013-08-28 01:07:53,188 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#1 in 15560s
2013-08-28 01:07:55,749 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13908026 bytes from map-output for attempt_1377650445458_0009_m_000023_0
2013-08-28 01:07:55,749 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13908026, inMemoryMapOutputs.size() -> 5, commitMemory -> 55724560, usedMemory ->69632586
2013-08-28 01:07:55,753 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000016_0 decomp: 13948274 len: 13948278 to MEMORY
2013-08-28 01:07:57,202 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000004_0,attempt_1377650445458_0009_m_000006_0,attempt_1377650445458_0009_m_000007_0,attempt_1377650445458_0009_m_000000_0 sent hash and received reply
2013-08-28 01:07:57,311 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000004_0 decomp: 13922586 len: 13922590 to MEMORY
2013-08-28 01:08:01,593 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13948274 bytes from map-output for attempt_1377650445458_0009_m_000016_0
2013-08-28 01:08:01,593 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13948274, inMemoryMapOutputs.size() -> 6, commitMemory -> 69632586, usedMemory ->97503446
2013-08-28 01:08:01,598 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000028_0 decomp: 13930178 len: 13930182 to MEMORY
2013-08-28 01:08:10,076 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930178 bytes from map-output for attempt_1377650445458_0009_m_000028_0
2013-08-28 01:08:10,076 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930178, inMemoryMapOutputs.size() -> 7, commitMemory -> 83580860, usedMemory ->111433624
2013-08-28 01:08:10,077 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97511038 > mergeThreshold=86139864. Current usedMemory=111433624
2013-08-28 01:08:10,077 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 01:08:10,226 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000032_0 decomp: 13907610 len: 13907614 to MEMORY
2013-08-28 01:08:10,669 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922586 bytes from map-output for attempt_1377650445458_0009_m_000004_0
2013-08-28 01:08:10,670 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922586, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->125341234
2013-08-28 01:08:10,674 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000006_0 decomp: 13962938 len: 13962942 to MEMORY
2013-08-28 01:08:10,758 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 01:08:10,759 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 01:08:10,759 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97510947 bytes
2013-08-28 01:08:13,569 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377650445458_0009_r_000004_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009/output/attempt_1377650445458_0009_r_000004_0/map_23.out.merged of size 97511030
2013-08-28 01:08:14,724 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13907610 bytes from map-output for attempt_1377650445458_0009_m_000032_0
2013-08-28 01:08:14,725 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13907610, inMemoryMapOutputs.size() -> 2, commitMemory -> 13922586, usedMemory ->41793134
2013-08-28 01:08:14,837 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377650445458_0009_m_000034_0 decomp: 13955034 len: 13955038 to MEMORY
2013-08-28 01:08:21,181 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13955034 bytes from map-output for attempt_1377650445458_0009_m_000034_0
2013-08-28 01:08:21,182 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13955034, inMemoryMapOutputs.size() -> 3, commitMemory -> 27830196, usedMemory ->55748168
2013-08-28 01:08:21,182 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#4 in 37885s
2013-08-28 01:08:26,909 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13962938 bytes from map-output for attempt_1377650445458_0009_m_000006_0
2013-08-28 01:08:26,909 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13962938, inMemoryMapOutputs.size() -> 4, commitMemory -> 41785230, usedMemory ->55748168
2013-08-28 01:08:26,914 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000007_0 decomp: 13917490 len: 13917494 to MEMORY
2013-08-28 01:08:41,080 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13917490 bytes from map-output for attempt_1377650445458_0009_m_000007_0
2013-08-28 01:08:41,080 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13917490, inMemoryMapOutputs.size() -> 5, commitMemory -> 55748168, usedMemory ->69665658
2013-08-28 01:08:41,231 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000000_0 decomp: 13896482 len: 13896486 to MEMORY
2013-08-28 01:08:51,710 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896482 bytes from map-output for attempt_1377650445458_0009_m_000000_0
2013-08-28 01:08:51,710 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896482, inMemoryMapOutputs.size() -> 6, commitMemory -> 69665658, usedMemory ->83562140
2013-08-28 01:08:51,711 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#5 in 75174s
2013-08-28 01:08:51,711 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 7 to fetcher#5
2013-08-28 01:08:51,711 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-7:8080 to fetcher#5
2013-08-28 01:09:01,208 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000009_0,attempt_1377650445458_0009_m_000008_0,attempt_1377650445458_0009_m_000012_0,attempt_1377650445458_0009_m_000021_0,attempt_1377650445458_0009_m_000030_0,attempt_1377650445458_0009_m_000035_0,attempt_1377650445458_0009_m_000038_0 sent hash and received reply
2013-08-28 01:09:01,213 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000009_0 decomp: 13976354 len: 13976358 to MEMORY
2013-08-28 01:09:15,907 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976354 bytes from map-output for attempt_1377650445458_0009_m_000009_0
2013-08-28 01:09:15,907 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976354, inMemoryMapOutputs.size() -> 7, commitMemory -> 83562140, usedMemory ->97538494
2013-08-28 01:09:15,907 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97538494 > mergeThreshold=86139864. Current usedMemory=97538494
2013-08-28 01:09:15,908 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 01:09:15,913 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000008_0 decomp: 13927162 len: 13927166 to MEMORY
2013-08-28 01:09:16,164 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 01:09:16,164 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 01:09:16,164 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97538403 bytes
2013-08-28 01:09:17,853 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377650445458_0009_r_000004_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009/output/attempt_1377650445458_0009_r_000004_0/map_0.out.merged of size 97538486
2013-08-28 01:09:24,560 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13927162 bytes from map-output for attempt_1377650445458_0009_m_000008_0
2013-08-28 01:09:24,561 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13927162, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13927162
2013-08-28 01:09:24,664 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000012_0 decomp: 13972090 len: 13972094 to MEMORY
2013-08-28 01:09:32,022 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13972090 bytes from map-output for attempt_1377650445458_0009_m_000012_0
2013-08-28 01:09:32,023 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13972090, inMemoryMapOutputs.size() -> 2, commitMemory -> 13927162, usedMemory ->27899252
2013-08-28 01:09:32,030 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000021_0 decomp: 13935170 len: 13935174 to MEMORY
2013-08-28 01:09:42,765 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13935170 bytes from map-output for attempt_1377650445458_0009_m_000021_0
2013-08-28 01:09:42,765 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13935170, inMemoryMapOutputs.size() -> 3, commitMemory -> 27899252, usedMemory ->41834422
2013-08-28 01:09:42,864 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000030_0 decomp: 13981554 len: 13981558 to MEMORY
2013-08-28 01:09:52,189 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13981554 bytes from map-output for attempt_1377650445458_0009_m_000030_0
2013-08-28 01:09:52,190 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13981554, inMemoryMapOutputs.size() -> 4, commitMemory -> 41834422, usedMemory ->55815976
2013-08-28 01:09:52,194 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000035_0 decomp: 13960546 len: 13960550 to MEMORY
2013-08-28 01:10:01,176 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13960546 bytes from map-output for attempt_1377650445458_0009_m_000035_0
2013-08-28 01:10:01,176 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13960546, inMemoryMapOutputs.size() -> 5, commitMemory -> 55815976, usedMemory ->69776522
2013-08-28 01:10:01,261 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377650445458_0009_m_000038_0 decomp: 13920194 len: 13920198 to MEMORY
2013-08-28 01:10:08,719 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13920194 bytes from map-output for attempt_1377650445458_0009_m_000038_0
2013-08-28 01:10:08,719 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13920194, inMemoryMapOutputs.size() -> 6, commitMemory -> 69776522, usedMemory ->83696716
2013-08-28 01:10:08,720 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#5 in 77009s
2013-08-28 01:10:37,028 WARN [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to hadoop-9-2:8080 with 1 map outputs
java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.read(SocketInputStream.java:150)
	at java.net.SocketInputStream.read(SocketInputStream.java:121)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:275)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:633)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:579)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1322)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:240)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:154)
2013-08-28 01:10:37,033 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#2 in 180491s
2013-08-28 01:10:50,032 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 13 to fetcher#2
2013-08-28 01:10:50,033 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 13 of 13 to hadoop-9-2:8080 to fetcher#2
2013-08-28 01:11:05,369 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377650445458_0009&reduce=4&map=attempt_1377650445458_0009_m_000011_0,attempt_1377650445458_0009_m_000018_0,attempt_1377650445458_0009_m_000019_0,attempt_1377650445458_0009_m_000017_0,attempt_1377650445458_0009_m_000024_0,attempt_1377650445458_0009_m_000026_0,attempt_1377650445458_0009_m_000025_0,attempt_1377650445458_0009_m_000029_0,attempt_1377650445458_0009_m_000031_0,attempt_1377650445458_0009_m_000033_0,attempt_1377650445458_0009_m_000036_0,attempt_1377650445458_0009_m_000037_0,attempt_1377650445458_0009_m_000001_0 sent hash and received reply
2013-08-28 01:11:05,375 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000011_0 decomp: 13934858 len: 13934862 to MEMORY
2013-08-28 01:11:46,204 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13934858 bytes from map-output for attempt_1377650445458_0009_m_000011_0
2013-08-28 01:11:46,204 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13934858, inMemoryMapOutputs.size() -> 7, commitMemory -> 83696716, usedMemory ->97631574
2013-08-28 01:11:46,204 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97631574 > mergeThreshold=86139864. Current usedMemory=97631574
2013-08-28 01:11:46,204 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 01:11:46,209 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000018_0 decomp: 13921338 len: 13921342 to MEMORY
2013-08-28 01:11:46,404 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 01:11:46,405 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 01:11:46,406 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97631483 bytes
2013-08-28 01:11:48,070 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377650445458_0009_r_000004_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009/output/attempt_1377650445458_0009_r_000004_0/map_38.out.merged of size 97631566
2013-08-28 01:11:58,161 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13921338 bytes from map-output for attempt_1377650445458_0009_m_000018_0
2013-08-28 01:11:58,161 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13921338, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13921338
2013-08-28 01:11:58,166 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000019_0 decomp: 13913642 len: 13913646 to MEMORY
2013-08-28 01:12:11,943 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13913642 bytes from map-output for attempt_1377650445458_0009_m_000019_0
2013-08-28 01:12:11,944 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13913642, inMemoryMapOutputs.size() -> 2, commitMemory -> 13921338, usedMemory ->27834980
2013-08-28 01:12:11,952 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000017_0 decomp: 13901994 len: 13901998 to MEMORY
2013-08-28 01:12:29,577 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901994 bytes from map-output for attempt_1377650445458_0009_m_000017_0
2013-08-28 01:12:29,577 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901994, inMemoryMapOutputs.size() -> 3, commitMemory -> 27834980, usedMemory ->41736974
2013-08-28 01:12:29,582 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000024_0 decomp: 13948170 len: 13948174 to MEMORY
2013-08-28 01:12:38,908 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13948170 bytes from map-output for attempt_1377650445458_0009_m_000024_0
2013-08-28 01:12:38,909 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13948170, inMemoryMapOutputs.size() -> 4, commitMemory -> 41736974, usedMemory ->55685144
2013-08-28 01:12:38,913 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000026_0 decomp: 13923938 len: 13923942 to MEMORY
2013-08-28 01:12:45,056 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13923938 bytes from map-output for attempt_1377650445458_0009_m_000026_0
2013-08-28 01:12:45,056 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13923938, inMemoryMapOutputs.size() -> 5, commitMemory -> 55685144, usedMemory ->69609082
2013-08-28 01:12:45,195 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000025_0 decomp: 13924874 len: 13924878 to MEMORY
2013-08-28 01:13:40,720 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13924874 bytes from map-output for attempt_1377650445458_0009_m_000025_0
2013-08-28 01:13:40,720 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13924874, inMemoryMapOutputs.size() -> 6, commitMemory -> 69609082, usedMemory ->83533956
2013-08-28 01:13:40,724 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000029_0 decomp: 13953474 len: 13953478 to MEMORY
2013-08-28 01:13:45,227 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13953474 bytes from map-output for attempt_1377650445458_0009_m_000029_0
2013-08-28 01:13:45,227 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13953474, inMemoryMapOutputs.size() -> 7, commitMemory -> 83533956, usedMemory ->97487430
2013-08-28 01:13:45,316 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97487430 > mergeThreshold=86139864. Current usedMemory=97487430
2013-08-28 01:13:45,316 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-28 01:13:45,326 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000031_0 decomp: 13987378 len: 13987382 to MEMORY
2013-08-28 01:13:45,623 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-28 01:13:45,623 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-28 01:13:45,624 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97487339 bytes
2013-08-28 01:13:47,393 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377650445458_0009_r_000004_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377650445458_0009/output/attempt_1377650445458_0009_r_000004_0/map_17.out.merged of size 97487422
2013-08-28 01:13:48,794 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13987378 bytes from map-output for attempt_1377650445458_0009_m_000031_0
2013-08-28 01:13:48,795 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13987378, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13987378
2013-08-28 01:13:48,799 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000033_0 decomp: 13888578 len: 13888582 to MEMORY
2013-08-28 01:13:50,012 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13888578 bytes from map-output for attempt_1377650445458_0009_m_000033_0
2013-08-28 01:13:50,012 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13888578, inMemoryMapOutputs.size() -> 2, commitMemory -> 13987378, usedMemory ->27875956
2013-08-28 01:13:50,017 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000036_0 decomp: 13901474 len: 13901478 to MEMORY
2013-08-28 01:13:50,235 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901474 bytes from map-output for attempt_1377650445458_0009_m_000036_0
2013-08-28 01:13:50,235 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901474, inMemoryMapOutputs.size() -> 3, commitMemory -> 27875956, usedMemory ->41777430
2013-08-28 01:13:50,435 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000037_0 decomp: 13977082 len: 13977086 to MEMORY
2013-08-28 01:13:50,610 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13977082 bytes from map-output for attempt_1377650445458_0009_m_000037_0
2013-08-28 01:13:50,610 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13977082, inMemoryMapOutputs.size() -> 4, commitMemory -> 41777430, usedMemory ->55754512
2013-08-28 01:13:50,615 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377650445458_0009_m_000001_0 decomp: 13939018 len: 13939022 to MEMORY
2013-08-28 01:13:53,667 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13939018 bytes from map-output for attempt_1377650445458_0009_m_000001_0
2013-08-28 01:13:53,667 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13939018, inMemoryMapOutputs.size() -> 5, commitMemory -> 55754512, usedMemory ->69693530
2013-08-28 01:13:53,668 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-28 01:13:53,668 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#2 in 183635s
2013-08-28 01:13:53,677 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-28 01:13:53,829 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-28 01:13:53,830 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69693465 bytes
2013-08-28 01:13:54,740 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69693530 bytes to disk to satisfy reduce memory limit
2013-08-28 01:13:54,741 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 557485276 bytes from disk
2013-08-28 01:13:54,743 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-28 01:13:54,743 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-28 01:13:55,385 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 557485174 bytes
2013-08-28 01:13:55,721 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-28 01:14:40,794 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377650445458_0009_r_000004_0/part-r-00004
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-3/_temporary/1/_temporary/attempt_1377650445458_0009_r_000004_0/part-r-00004: File does not exist. Holder DFSClient_attempt_1377650445458_0009_r_000004_0_-919252067_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-28 01:14:40,794 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-28 01:14:40,796 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-28 01:14:40,802 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
