2013-08-27 23:49:38,578 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-27 23:49:38,603 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-27 23:49:38,700 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-27 23:49:38,831 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-27 23:49:38,831 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-27 23:49:38,863 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-27 23:49:38,864 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1377645635971_0010, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@2e71f06c)
2013-08-27 23:49:39,019 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-27 23:49:39,933 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010
2013-08-27 23:49:40,308 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-27 23:49:40,308 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-27 23:49:40,310 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-27 23:49:40,311 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-27 23:49:40,314 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-27 23:49:40,315 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-27 23:49:40,315 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-27 23:49:40,316 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-27 23:49:40,316 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-27 23:49:40,713 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-27 23:49:41,433 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-27 23:49:41,556 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@392305e8
2013-08-27 23:49:41,598 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-27 23:49:41,606 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377645635971_0010_r_000004_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-27 23:49:41,634 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 4 to fetcher#5
2013-08-27 23:49:41,634 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-3:8080 to fetcher#5
2013-08-27 23:49:41,640 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 1 to fetcher#4
2013-08-27 23:49:41,640 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-6:8080 to fetcher#4
2013-08-27 23:49:41,641 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 2 to fetcher#3
2013-08-27 23:49:41,641 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-4:8080 to fetcher#3
2013-08-27 23:49:41,641 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 2 to fetcher#2
2013-08-27 23:49:41,641 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-9-5:8080 to fetcher#2
2013-08-27 23:49:41,642 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 7 to fetcher#1
2013-08-27 23:49:41,642 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-2:8080 to fetcher#1
2013-08-27 23:49:41,647 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1377645635971_0010_r_000004_1: Got 40 new map-outputs
2013-08-27 23:49:41,910 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000013_0 sent hash and received reply
2013-08-27 23:49:41,910 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000001_0,attempt_1377645635971_0010_m_000005_0,attempt_1377645635971_0010_m_000006_0,attempt_1377645635971_0010_m_000007_0,attempt_1377645635971_0010_m_000008_0,attempt_1377645635971_0010_m_000011_0,attempt_1377645635971_0010_m_000016_0 sent hash and received reply
2013-08-27 23:49:41,912 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000012_0,attempt_1377645635971_0010_m_000020_0 sent hash and received reply
2013-08-27 23:49:41,913 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000000_0,attempt_1377645635971_0010_m_000009_0,attempt_1377645635971_0010_m_000004_0,attempt_1377645635971_0010_m_000019_0 sent hash and received reply
2013-08-27 23:49:41,927 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000012_0 decomp: 13900538 len: 13900542 to MEMORY
2013-08-27 23:49:42,003 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000000_0 decomp: 13897834 len: 13897838 to MEMORY
2013-08-27 23:49:42,010 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377645635971_0010_m_000013_0 decomp: 13885458 len: 13885462 to MEMORY
2013-08-27 23:49:42,010 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000001_0 decomp: 13943178 len: 13943182 to MEMORY
2013-08-27 23:49:42,334 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13885458 bytes from map-output for attempt_1377645635971_0010_m_000013_0
2013-08-27 23:49:42,337 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13885458, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55627008
2013-08-27 23:49:42,339 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#4 in 699s
2013-08-27 23:49:42,339 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 7 to fetcher#4
2013-08-27 23:49:42,340 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-6:8080 to fetcher#4
2013-08-27 23:49:42,350 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000017_0,attempt_1377645635971_0010_m_000021_0,attempt_1377645635971_0010_m_000026_0,attempt_1377645635971_0010_m_000027_0,attempt_1377645635971_0010_m_000030_0,attempt_1377645635971_0010_m_000034_0,attempt_1377645635971_0010_m_000035_0 sent hash and received reply
2013-08-27 23:49:42,365 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377645635971_0010_m_000017_0 decomp: 13913850 len: 13913854 to MEMORY
2013-08-27 23:49:42,485 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13913850 bytes from map-output for attempt_1377645635971_0010_m_000017_0
2013-08-27 23:49:42,485 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13913850, inMemoryMapOutputs.size() -> 2, commitMemory -> 13885458, usedMemory ->69540858
2013-08-27 23:49:42,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000003_0,attempt_1377645635971_0010_m_000002_0 sent hash and received reply
2013-08-27 23:49:42,713 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377645635971_0010_m_000021_0 decomp: 13980410 len: 13980414 to MEMORY
2013-08-27 23:49:42,725 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377645635971_0010_m_000003_0 decomp: 13969698 len: 13969702 to MEMORY
2013-08-27 23:49:43,797 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13897834 bytes from map-output for attempt_1377645635971_0010_m_000000_0
2013-08-27 23:49:43,922 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13897834, inMemoryMapOutputs.size() -> 3, commitMemory -> 27799308, usedMemory ->97490966
2013-08-27 23:49:43,927 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000009_0 decomp: 13981970 len: 13981974 to MEMORY
2013-08-27 23:49:45,027 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13943178 bytes from map-output for attempt_1377645635971_0010_m_000001_0
2013-08-27 23:49:45,027 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13943178, inMemoryMapOutputs.size() -> 4, commitMemory -> 41697142, usedMemory ->111472936
2013-08-27 23:49:45,032 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000005_0 decomp: 13884522 len: 13884526 to MEMORY
2013-08-27 23:49:45,636 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13980410 bytes from map-output for attempt_1377645635971_0010_m_000021_0
2013-08-27 23:49:45,636 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13980410, inMemoryMapOutputs.size() -> 5, commitMemory -> 55640320, usedMemory ->125357458
2013-08-27 23:49:45,809 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377645635971_0010_m_000026_0 decomp: 13927682 len: 13927686 to MEMORY
2013-08-27 23:49:45,959 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13927682 bytes from map-output for attempt_1377645635971_0010_m_000026_0
2013-08-27 23:49:45,959 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13927682, inMemoryMapOutputs.size() -> 6, commitMemory -> 69620730, usedMemory ->139285140
2013-08-27 23:49:45,960 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-27 23:49:45,961 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#4 in 3621s
2013-08-27 23:49:45,961 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 1 to fetcher#4
2013-08-27 23:49:45,961 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-7:8080 to fetcher#4
2013-08-27 23:49:46,003 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000010_0 sent hash and received reply
2013-08-27 23:49:46,005 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-27 23:49:46,010 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#4 in 48s
2013-08-27 23:49:46,010 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 4 to fetcher#4
2013-08-27 23:49:46,011 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-6:8080 to fetcher#4
2013-08-27 23:49:46,020 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000035_0,attempt_1377645635971_0010_m_000034_0,attempt_1377645635971_0010_m_000027_0,attempt_1377645635971_0010_m_000030_0 sent hash and received reply
2013-08-27 23:49:46,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-27 23:49:46,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#4 in 11s
2013-08-27 23:49:46,021 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-7:8080 with 1 to fetcher#4
2013-08-27 23:49:46,022 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-7:8080 to fetcher#4
2013-08-27 23:49:47,394 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13981970 bytes from map-output for attempt_1377645635971_0010_m_000009_0
2013-08-27 23:49:47,394 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13981970, inMemoryMapOutputs.size() -> 7, commitMemory -> 83548412, usedMemory ->139285140
2013-08-27 23:49:47,394 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97530382 > mergeThreshold=86139864. Current usedMemory=139285140
2013-08-27 23:49:47,395 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-27 23:49:47,396 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-27 23:49:47,396 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#5 in 5762s
2013-08-27 23:49:47,777 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-27 23:49:47,787 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-27 23:49:47,788 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97530291 bytes
2013-08-27 23:49:49,981 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377645635971_0010_r_000004_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010/output/attempt_1377645635971_0010_r_000004_1/map_13.out.merged of size 97530374
2013-08-27 23:49:49,982 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-6:8080 with 4 to fetcher#5
2013-08-27 23:49:49,982 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-6:8080 to fetcher#5
2013-08-27 23:49:49,984 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000035_0,attempt_1377645635971_0010_m_000034_0,attempt_1377645635971_0010_m_000027_0,attempt_1377645635971_0010_m_000030_0 sent hash and received reply
2013-08-27 23:49:49,987 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000035_0 decomp: 13970530 len: 13970534 to MEMORY
2013-08-27 23:49:50,140 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970530 bytes from map-output for attempt_1377645635971_0010_m_000035_0
2013-08-27 23:49:50,141 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970530, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55725288
2013-08-27 23:49:50,239 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000034_0 decomp: 13890034 len: 13890038 to MEMORY
2013-08-27 23:49:50,358 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13890034 bytes from map-output for attempt_1377645635971_0010_m_000034_0
2013-08-27 23:49:50,358 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13890034, inMemoryMapOutputs.size() -> 2, commitMemory -> 13970530, usedMemory ->69615322
2013-08-27 23:49:50,361 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000027_0 decomp: 13901578 len: 13901582 to MEMORY
2013-08-27 23:49:50,524 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901578 bytes from map-output for attempt_1377645635971_0010_m_000027_0
2013-08-27 23:49:50,525 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901578, inMemoryMapOutputs.size() -> 3, commitMemory -> 27860564, usedMemory ->83516900
2013-08-27 23:49:50,529 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000030_0 decomp: 13910314 len: 13910318 to MEMORY
2013-08-27 23:49:50,579 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13910314 bytes from map-output for attempt_1377645635971_0010_m_000030_0
2013-08-27 23:49:50,579 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13910314, inMemoryMapOutputs.size() -> 4, commitMemory -> 41762142, usedMemory ->97427214
2013-08-27 23:49:50,580 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-6:8080 freed by fetcher#5 in 598s
2013-08-27 23:49:50,580 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 7 to fetcher#5
2013-08-27 23:49:50,580 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 7 of 7 to hadoop-9-3:8080 to fetcher#5
2013-08-27 23:49:50,584 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000014_0,attempt_1377645635971_0010_m_000022_0,attempt_1377645635971_0010_m_000029_0,attempt_1377645635971_0010_m_000032_0,attempt_1377645635971_0010_m_000038_0,attempt_1377645635971_0010_m_000019_0,attempt_1377645635971_0010_m_000004_0 sent hash and received reply
2013-08-27 23:49:50,588 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000014_0 decomp: 13965226 len: 13965230 to MEMORY
2013-08-27 23:49:50,846 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13965226 bytes from map-output for attempt_1377645635971_0010_m_000014_0
2013-08-27 23:49:50,846 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13965226, inMemoryMapOutputs.size() -> 5, commitMemory -> 55672456, usedMemory ->111392440
2013-08-27 23:49:50,940 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000022_0 decomp: 13962938 len: 13962942 to MEMORY
2013-08-27 23:49:51,188 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13962938 bytes from map-output for attempt_1377645635971_0010_m_000022_0
2013-08-27 23:49:51,188 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13962938, inMemoryMapOutputs.size() -> 6, commitMemory -> 69637682, usedMemory ->125355378
2013-08-27 23:49:51,192 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000029_0 decomp: 13980098 len: 13980102 to MEMORY
2013-08-27 23:49:52,120 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13900538 bytes from map-output for attempt_1377645635971_0010_m_000012_0
2013-08-27 23:49:52,121 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13900538, inMemoryMapOutputs.size() -> 7, commitMemory -> 83600620, usedMemory ->139335476
2013-08-27 23:49:52,121 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97501158 > mergeThreshold=86139864. Current usedMemory=139335476
2013-08-27 23:49:52,121 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-27 23:49:52,122 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-27 23:49:52,122 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#3 in 10481s
2013-08-27 23:49:52,349 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-27 23:49:52,350 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-27 23:49:52,350 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97501067 bytes
2013-08-27 23:49:52,524 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13980098 bytes from map-output for attempt_1377645635971_0010_m_000029_0
2013-08-27 23:49:52,525 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13980098, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139335476
2013-08-27 23:49:52,529 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-27 23:49:52,531 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#5 in 1951s
2013-08-27 23:49:52,645 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13884522 bytes from map-output for attempt_1377645635971_0010_m_000005_0
2013-08-27 23:49:52,645 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13884522, inMemoryMapOutputs.size() -> 2, commitMemory -> 13980098, usedMemory ->139335476
2013-08-27 23:49:52,646 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-27 23:49:52,646 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#1 in 11004s
2013-08-27 23:49:54,659 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377645635971_0010_r_000004_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010/output/attempt_1377645635971_0010_r_000004_1/map_34.out.merged of size 97501150
2013-08-27 23:49:54,659 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 4 to fetcher#1
2013-08-27 23:49:54,659 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-9-3:8080 to fetcher#1
2013-08-27 23:49:54,661 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 6 to fetcher#5
2013-08-27 23:49:54,661 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-4:8080 to fetcher#5
2013-08-27 23:49:54,662 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 10 to fetcher#3
2013-08-27 23:49:54,662 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 10 of 10 to hadoop-9-2:8080 to fetcher#3
2013-08-27 23:49:54,664 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000038_0,attempt_1377645635971_0010_m_000019_0,attempt_1377645635971_0010_m_000004_0,attempt_1377645635971_0010_m_000032_0 sent hash and received reply
2013-08-27 23:49:54,752 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000038_0 decomp: 13933818 len: 13933822 to MEMORY
2013-08-27 23:49:55,710 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000023_0,attempt_1377645635971_0010_m_000025_0,attempt_1377645635971_0010_m_000028_0,attempt_1377645635971_0010_m_000036_0,attempt_1377645635971_0010_m_000039_0,attempt_1377645635971_0010_m_000006_0,attempt_1377645635971_0010_m_000007_0,attempt_1377645635971_0010_m_000016_0,attempt_1377645635971_0010_m_000011_0,attempt_1377645635971_0010_m_000008_0 sent hash and received reply
2013-08-27 23:49:55,715 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000023_0 decomp: 13949002 len: 13949006 to MEMORY
2013-08-27 23:49:56,673 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000010_0 sent hash and received reply
2013-08-27 23:49:56,679 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1377645635971_0010_m_000010_0 decomp: 13965330 len: 13965334 to MEMORY
2013-08-27 23:49:56,958 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13949002 bytes from map-output for attempt_1377645635971_0010_m_000023_0
2013-08-27 23:49:56,958 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13949002, inMemoryMapOutputs.size() -> 3, commitMemory -> 27864620, usedMemory ->83682468
2013-08-27 23:49:56,964 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000025_0 decomp: 13909898 len: 13909902 to MEMORY
2013-08-27 23:49:57,988 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909898 bytes from map-output for attempt_1377645635971_0010_m_000025_0
2013-08-27 23:49:57,988 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909898, inMemoryMapOutputs.size() -> 4, commitMemory -> 41813622, usedMemory ->97592366
2013-08-27 23:49:58,081 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000028_0 decomp: 13928410 len: 13928414 to MEMORY
2013-08-27 23:49:59,235 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13928410 bytes from map-output for attempt_1377645635971_0010_m_000028_0
2013-08-27 23:49:59,235 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13928410, inMemoryMapOutputs.size() -> 5, commitMemory -> 55723520, usedMemory ->111520776
2013-08-27 23:49:59,239 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000036_0 decomp: 13926018 len: 13926022 to MEMORY
2013-08-27 23:49:59,569 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13926018 bytes from map-output for attempt_1377645635971_0010_m_000036_0
2013-08-27 23:49:59,570 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13926018, inMemoryMapOutputs.size() -> 6, commitMemory -> 69651930, usedMemory ->125446794
2013-08-27 23:49:59,578 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000039_0 decomp: 13939330 len: 13939334 to MEMORY
2013-08-27 23:49:59,913 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13939330 bytes from map-output for attempt_1377645635971_0010_m_000039_0
2013-08-27 23:49:59,914 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13939330, inMemoryMapOutputs.size() -> 7, commitMemory -> 83577948, usedMemory ->139386124
2013-08-27 23:49:59,914 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97517278 > mergeThreshold=86139864. Current usedMemory=139386124
2013-08-27 23:49:59,915 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-27 23:49:59,916 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-27 23:49:59,916 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#3 in 5254s
2013-08-27 23:50:00,323 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-27 23:50:00,324 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-27 23:50:00,324 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97517187 bytes
2013-08-27 23:50:00,383 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13933818 bytes from map-output for attempt_1377645635971_0010_m_000038_0
2013-08-27 23:50:00,383 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13933818, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139386124
2013-08-27 23:50:00,384 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-27 23:50:00,384 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#1 in 5725s
2013-08-27 23:50:00,814 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000015_0,attempt_1377645635971_0010_m_000024_0,attempt_1377645635971_0010_m_000031_0,attempt_1377645635971_0010_m_000033_0,attempt_1377645635971_0010_m_000037_0,attempt_1377645635971_0010_m_000020_0 sent hash and received reply
2013-08-27 23:50:00,815 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-27 23:50:00,815 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#5 in 6154s
2013-08-27 23:50:02,007 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377645635971_0010_r_000004_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010/output/attempt_1377645635971_0010_r_000004_1/map_5.out.merged of size 97517270
2013-08-27 23:50:02,007 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-2:8080 with 5 to fetcher#5
2013-08-27 23:50:02,007 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-9-2:8080 to fetcher#5
2013-08-27 23:50:02,009 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-3:8080 with 3 to fetcher#1
2013-08-27 23:50:02,009 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-9-3:8080 to fetcher#1
2013-08-27 23:50:02,010 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-4:8080 with 6 to fetcher#3
2013-08-27 23:50:02,010 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 6 of 6 to hadoop-9-4:8080 to fetcher#3
2013-08-27 23:50:02,014 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000020_0,attempt_1377645635971_0010_m_000037_0,attempt_1377645635971_0010_m_000031_0,attempt_1377645635971_0010_m_000015_0,attempt_1377645635971_0010_m_000033_0,attempt_1377645635971_0010_m_000024_0 sent hash and received reply
2013-08-27 23:50:02,015 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000019_0,attempt_1377645635971_0010_m_000004_0,attempt_1377645635971_0010_m_000032_0 sent hash and received reply
2013-08-27 23:50:02,020 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000020_0 decomp: 13909586 len: 13909590 to MEMORY
2013-08-27 23:50:02,125 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000019_0 decomp: 13940058 len: 13940062 to MEMORY
2013-08-27 23:50:02,529 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13969698 bytes from map-output for attempt_1377645635971_0010_m_000003_0
2013-08-27 23:50:02,530 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13969698, inMemoryMapOutputs.size() -> 2, commitMemory -> 13933818, usedMemory ->69718490
2013-08-27 23:50:02,535 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1377645635971_0010_m_000002_0 decomp: 14027314 len: 14027318 to MEMORY
2013-08-27 23:50:02,967 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13940058 bytes from map-output for attempt_1377645635971_0010_m_000019_0
2013-08-27 23:50:02,967 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13940058, inMemoryMapOutputs.size() -> 3, commitMemory -> 27903516, usedMemory ->83745804
2013-08-27 23:50:02,974 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000004_0 decomp: 13925810 len: 13925814 to MEMORY
2013-08-27 23:50:03,395 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925810 bytes from map-output for attempt_1377645635971_0010_m_000004_0
2013-08-27 23:50:03,396 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925810, inMemoryMapOutputs.size() -> 4, commitMemory -> 41843574, usedMemory ->97671614
2013-08-27 23:50:03,508 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000032_0 decomp: 13957946 len: 13957950 to MEMORY
2013-08-27 23:50:03,971 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000006_0,attempt_1377645635971_0010_m_000007_0,attempt_1377645635971_0010_m_000016_0,attempt_1377645635971_0010_m_000008_0,attempt_1377645635971_0010_m_000011_0 sent hash and received reply
2013-08-27 23:50:03,990 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000006_0 decomp: 13967514 len: 13967518 to MEMORY
2013-08-27 23:50:04,279 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13965330 bytes from map-output for attempt_1377645635971_0010_m_000010_0
2013-08-27 23:50:04,279 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13965330, inMemoryMapOutputs.size() -> 5, commitMemory -> 55769384, usedMemory ->125597074
2013-08-27 23:50:04,280 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-7:8080 freed by fetcher#4 in 18259s
2013-08-27 23:50:04,527 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13957946 bytes from map-output for attempt_1377645635971_0010_m_000032_0
2013-08-27 23:50:04,528 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13957946, inMemoryMapOutputs.size() -> 6, commitMemory -> 69734714, usedMemory ->125597074
2013-08-27 23:50:04,530 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-3:8080 freed by fetcher#1 in 2521s
2013-08-27 23:50:08,292 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14027314 bytes from map-output for attempt_1377645635971_0010_m_000002_0
2013-08-27 23:50:08,292 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14027314, inMemoryMapOutputs.size() -> 7, commitMemory -> 83692660, usedMemory ->125597074
2013-08-27 23:50:08,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97719974 > mergeThreshold=86139864. Current usedMemory=125597074
2013-08-27 23:50:08,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-27 23:50:08,293 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#2 in 26652s
2013-08-27 23:50:08,293 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-9-5:8080 with 1 to fetcher#1
2013-08-27 23:50:08,294 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-9-5:8080 to fetcher#1
2013-08-27 23:50:08,506 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-27 23:50:08,506 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-27 23:50:08,506 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97719883 bytes
2013-08-27 23:50:09,954 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909586 bytes from map-output for attempt_1377645635971_0010_m_000020_0
2013-08-27 23:50:09,954 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909586, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->125597074
2013-08-27 23:50:09,957 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000037_0 decomp: 13899498 len: 13899502 to MEMORY
2013-08-27 23:50:10,132 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377645635971_0010_r_000004_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010/output/attempt_1377645635971_0010_r_000004_1/map_4.out.merged of size 97719966
2013-08-27 23:50:11,745 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13899498 bytes from map-output for attempt_1377645635971_0010_m_000037_0
2013-08-27 23:50:11,745 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13899498, inMemoryMapOutputs.size() -> 2, commitMemory -> 13909586, usedMemory ->41776598
2013-08-27 23:50:11,750 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000031_0 decomp: 13887954 len: 13887958 to MEMORY
2013-08-27 23:50:14,066 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13967514 bytes from map-output for attempt_1377645635971_0010_m_000006_0
2013-08-27 23:50:14,073 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13967514, inMemoryMapOutputs.size() -> 3, commitMemory -> 27809084, usedMemory ->55664552
2013-08-27 23:50:14,077 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000007_0 decomp: 13924562 len: 13924566 to MEMORY
2013-08-27 23:50:20,490 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13887954 bytes from map-output for attempt_1377645635971_0010_m_000031_0
2013-08-27 23:50:20,490 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13887954, inMemoryMapOutputs.size() -> 4, commitMemory -> 41776598, usedMemory ->69589114
2013-08-27 23:50:20,591 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000015_0 decomp: 13943074 len: 13943078 to MEMORY
2013-08-27 23:50:23,139 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13924562 bytes from map-output for attempt_1377645635971_0010_m_000007_0
2013-08-27 23:50:23,139 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13924562, inMemoryMapOutputs.size() -> 5, commitMemory -> 55664552, usedMemory ->83532188
2013-08-27 23:50:23,144 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000016_0 decomp: 13905114 len: 13905118 to MEMORY
2013-08-27 23:50:24,121 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13905114 bytes from map-output for attempt_1377645635971_0010_m_000016_0
2013-08-27 23:50:24,122 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13905114, inMemoryMapOutputs.size() -> 6, commitMemory -> 69589114, usedMemory ->97437302
2013-08-27 23:50:24,126 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000008_0 decomp: 13917594 len: 13917598 to MEMORY
2013-08-27 23:50:24,452 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13917594 bytes from map-output for attempt_1377645635971_0010_m_000008_0
2013-08-27 23:50:24,452 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13917594, inMemoryMapOutputs.size() -> 7, commitMemory -> 83494228, usedMemory ->111354896
2013-08-27 23:50:24,452 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97411822 > mergeThreshold=86139864. Current usedMemory=111354896
2013-08-27 23:50:24,452 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-27 23:50:24,602 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1377645635971_0010_m_000011_0 decomp: 13970634 len: 13970638 to MEMORY
2013-08-27 23:50:24,878 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-27 23:50:24,881 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-27 23:50:24,882 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97411731 bytes
2013-08-27 23:50:25,231 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13970634 bytes from map-output for attempt_1377645635971_0010_m_000011_0
2013-08-27 23:50:25,231 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13970634, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->125325530
2013-08-27 23:50:25,232 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-2:8080 freed by fetcher#5 in 23225s
2013-08-27 23:50:25,360 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13943074 bytes from map-output for attempt_1377645635971_0010_m_000015_0
2013-08-27 23:50:25,360 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13943074, inMemoryMapOutputs.size() -> 2, commitMemory -> 13970634, usedMemory ->125325530
2013-08-27 23:50:25,364 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000033_0 decomp: 13958882 len: 13958886 to MEMORY
2013-08-27 23:50:26,760 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1377645635971_0010_r_000004_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1377645635971_0010/output/attempt_1377645635971_0010_r_000004_1/map_31.out.merged of size 97411814
2013-08-27 23:50:29,936 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13958882 bytes from map-output for attempt_1377645635971_0010_m_000033_0
2013-08-27 23:50:29,937 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13958882, inMemoryMapOutputs.size() -> 3, commitMemory -> 27913708, usedMemory ->41872590
2013-08-27 23:50:30,020 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1377645635971_0010_m_000024_0 decomp: 13932986 len: 13932990 to MEMORY
2013-08-27 23:50:35,659 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13932986 bytes from map-output for attempt_1377645635971_0010_m_000024_0
2013-08-27 23:50:35,659 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13932986, inMemoryMapOutputs.size() -> 4, commitMemory -> 41872590, usedMemory ->55805576
2013-08-27 23:50:35,660 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-4:8080 freed by fetcher#3 in 33650s
2013-08-27 23:50:49,802 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1377645635971_0010&reduce=4&map=attempt_1377645635971_0010_m_000018_0 sent hash and received reply
2013-08-27 23:50:49,808 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1377645635971_0010_m_000018_0 decomp: 13976354 len: 13976358 to MEMORY
2013-08-27 23:51:24,918 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976354 bytes from map-output for attempt_1377645635971_0010_m_000018_0
2013-08-27 23:51:24,918 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976354, inMemoryMapOutputs.size() -> 5, commitMemory -> 55805576, usedMemory ->69781930
2013-08-27 23:51:24,919 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-27 23:51:24,919 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-9-5:8080 freed by fetcher#1 in 76626s
2013-08-27 23:51:25,122 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-27 23:51:25,256 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-27 23:51:25,257 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69781865 bytes
2013-08-27 23:51:26,372 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69781930 bytes to disk to satisfy reduce memory limit
2013-08-27 23:51:26,374 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 557462500 bytes from disk
2013-08-27 23:51:26,377 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-27 23:51:26,377 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-27 23:51:26,382 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 557462398 bytes
2013-08-27 23:51:26,581 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-27 23:51:41,914 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377645635971_0010_r_000004_1/part-r-00004
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377645635971_0010_r_000004_1/part-r-00004: File does not exist. Holder DFSClient_attempt_1377645635971_0010_r_000004_1_-316043716_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-27 23:51:41,914 WARN [main] org.apache.hadoop.hdfs.DFSClient: Unable to persist blocks in hflush for /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377645635971_0010_r_000004_1/part-r-00004
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1377645635971_0010_r_000004_1/part-r-00004: File does not exist. Holder DFSClient_attempt_1377645635971_0010_r_000004_1_-316043716_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.fsync(FSNamesystem.java:3110)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.fsync(NameNodeRpcServer.java:830)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.fsync(ClientNamenodeProtocolServerSideTranslatorPB.java:718)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:41033)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.fsync(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.fsync(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.fsync(ClientNamenodeProtocolTranslatorPB.java:694)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1644)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1545)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1528)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:124)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.close(TeraOutputFormat.java:75)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:572)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-27 23:51:41,917 WARN [main] org.apache.hadoop.hdfs.DFSClient: Error while syncing
java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:1650)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1545)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:1528)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:124)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.close(TeraOutputFormat.java:75)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:572)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:649)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
2013-08-27 23:51:41,918 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
