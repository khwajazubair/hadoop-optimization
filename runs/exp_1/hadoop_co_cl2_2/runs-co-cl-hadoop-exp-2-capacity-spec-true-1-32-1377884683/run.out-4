13/08/30 17:07:31 INFO terasort.TeraSort: starting
13/08/30 17:07:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13/08/30 17:07:34 INFO input.FileInputFormat: Total input paths to process : 2
Spent 270ms computing base-splits.
Spent 4ms computing TeraScheduler splits.
Computing input splits took 275ms
Sampling 10 splits of 40
Making 1 from 100000 sampled records
Computing parititions took 1429ms
Spent 1710ms computing partitions.
13/08/30 17:07:35 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is inited.
13/08/30 17:07:36 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is started.
13/08/30 17:07:37 INFO mapreduce.JobSubmitter: number of splits:40
13/08/30 17:07:37 WARN conf.Configuration: mapred.jar is deprecated. Instead, use mapreduce.job.jar
13/08/30 17:07:37 WARN conf.Configuration: mapred.cache.files is deprecated. Instead, use mapreduce.job.cache.files
13/08/30 17:07:37 WARN conf.Configuration: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
13/08/30 17:07:37 WARN conf.Configuration: mapreduce.partitioner.class is deprecated. Instead, use mapreduce.job.partitioner.class
13/08/30 17:07:37 WARN conf.Configuration: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
13/08/30 17:07:37 WARN conf.Configuration: mapred.job.name is deprecated. Instead, use mapreduce.job.name
13/08/30 17:07:37 WARN conf.Configuration: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
13/08/30 17:07:37 WARN conf.Configuration: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
13/08/30 17:07:37 WARN conf.Configuration: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
13/08/30 17:07:37 WARN conf.Configuration: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
13/08/30 17:07:37 WARN conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
13/08/30 17:07:37 WARN conf.Configuration: mapred.cache.files.timestamps is deprecated. Instead, use mapreduce.job.cache.files.timestamps
13/08/30 17:07:37 WARN conf.Configuration: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
13/08/30 17:07:37 WARN conf.Configuration: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
13/08/30 17:07:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1377881440942_0006
13/08/30 17:07:38 INFO client.YarnClientImpl: Submitted application application_1377881440942_0006 to ResourceManager at hadoop-32-1/192.168.100.25:54111
13/08/30 17:07:38 INFO mapreduce.Job: The url to track the job: http://hadoop-32-1.novalocal:8088/proxy/application_1377881440942_0006/
13/08/30 17:07:38 INFO mapreduce.Job: Running job: job_1377881440942_0006
13/08/30 17:07:47 INFO mapreduce.Job: Job job_1377881440942_0006 running in uber mode : false
13/08/30 17:07:47 INFO mapreduce.Job:  map 0% reduce 0%
13/08/30 17:08:01 INFO mapreduce.Job:  map 7% reduce 0%
13/08/30 17:08:02 INFO mapreduce.Job:  map 8% reduce 0%
13/08/30 17:08:04 INFO mapreduce.Job:  map 13% reduce 0%
13/08/30 17:08:06 INFO mapreduce.Job:  map 20% reduce 0%
13/08/30 17:08:08 INFO mapreduce.Job:  map 24% reduce 0%
13/08/30 17:08:10 INFO mapreduce.Job:  map 29% reduce 0%
13/08/30 17:08:11 INFO mapreduce.Job:  map 31% reduce 0%
13/08/30 17:08:13 INFO mapreduce.Job:  map 33% reduce 0%
13/08/30 17:08:14 INFO mapreduce.Job:  map 34% reduce 0%
13/08/30 17:08:15 INFO mapreduce.Job:  map 36% reduce 0%
13/08/30 17:08:16 INFO mapreduce.Job:  map 38% reduce 0%
13/08/30 17:08:18 INFO mapreduce.Job:  map 39% reduce 0%
13/08/30 17:08:19 INFO mapreduce.Job:  map 42% reduce 0%
13/08/30 17:08:21 INFO mapreduce.Job:  map 44% reduce 0%
13/08/30 17:08:22 INFO mapreduce.Job:  map 46% reduce 0%
13/08/30 17:08:24 INFO mapreduce.Job:  map 47% reduce 0%
13/08/30 17:08:26 INFO mapreduce.Job:  map 49% reduce 1%
13/08/30 17:08:28 INFO mapreduce.Job:  map 51% reduce 1%
13/08/30 17:08:30 INFO mapreduce.Job:  map 53% reduce 1%
13/08/30 17:08:32 INFO mapreduce.Job:  map 55% reduce 1%
13/08/30 17:08:33 INFO mapreduce.Job:  map 57% reduce 2%
13/08/30 17:08:34 INFO mapreduce.Job:  map 58% reduce 2%
13/08/30 17:08:35 INFO mapreduce.Job:  map 60% reduce 2%
13/08/30 17:08:36 INFO mapreduce.Job:  map 60% reduce 3%
13/08/30 17:08:38 INFO mapreduce.Job:  map 61% reduce 3%
13/08/30 17:08:39 INFO mapreduce.Job:  map 63% reduce 3%
13/08/30 17:08:41 INFO mapreduce.Job:  map 64% reduce 3%
13/08/30 17:08:42 INFO mapreduce.Job:  map 66% reduce 3%
13/08/30 17:08:43 INFO mapreduce.Job:  map 68% reduce 3%
13/08/30 17:08:45 INFO mapreduce.Job:  map 71% reduce 4%
13/08/30 17:08:47 INFO mapreduce.Job:  map 72% reduce 4%
13/08/30 17:08:51 INFO mapreduce.Job:  map 74% reduce 6%
13/08/30 17:08:53 INFO mapreduce.Job:  map 75% reduce 6%
13/08/30 17:08:54 INFO mapreduce.Job:  map 76% reduce 6%
13/08/30 17:08:55 INFO mapreduce.Job:  map 76% reduce 8%
13/08/30 17:08:56 INFO mapreduce.Job:  map 78% reduce 8%
13/08/30 17:08:57 INFO mapreduce.Job:  map 79% reduce 8%
13/08/30 17:08:59 INFO mapreduce.Job:  map 80% reduce 8%
13/08/30 17:09:02 INFO mapreduce.Job:  map 81% reduce 8%
13/08/30 17:09:05 INFO mapreduce.Job:  map 82% reduce 8%
13/08/30 17:09:06 INFO mapreduce.Job:  map 83% reduce 8%
13/08/30 17:09:07 INFO mapreduce.Job:  map 83% reduce 9%
13/08/30 17:09:08 INFO mapreduce.Job:  map 84% reduce 9%
13/08/30 17:09:12 INFO mapreduce.Job:  map 86% reduce 10%
13/08/30 17:09:13 INFO mapreduce.Job:  map 87% reduce 10%
13/08/30 17:09:14 INFO mapreduce.Job:  map 87% reduce 11%
13/08/30 17:09:17 INFO mapreduce.Job:  map 88% reduce 11%
13/08/30 17:09:20 INFO mapreduce.Job:  map 88% reduce 12%
13/08/30 17:09:21 INFO mapreduce.Job:  map 90% reduce 12%
13/08/30 17:09:24 INFO mapreduce.Job:  map 91% reduce 12%
13/08/30 17:09:26 INFO mapreduce.Job:  map 92% reduce 12%
13/08/30 17:09:29 INFO mapreduce.Job:  map 93% reduce 13%
13/08/30 17:09:31 INFO mapreduce.Job:  map 94% reduce 13%
13/08/30 17:09:38 INFO mapreduce.Job:  map 95% reduce 13%
13/08/30 17:09:40 INFO mapreduce.Job:  map 97% reduce 13%
13/08/30 17:09:43 INFO mapreduce.Job:  map 98% reduce 13%
13/08/30 17:09:49 INFO mapreduce.Job:  map 99% reduce 13%
13/08/30 17:09:55 INFO mapreduce.Job:  map 99% reduce 14%
13/08/30 17:10:01 INFO mapreduce.Job:  map 100% reduce 14%
13/08/30 17:10:16 INFO mapreduce.Job:  map 100% reduce 15%
13/08/30 17:10:29 INFO mapreduce.Job:  map 100% reduce 16%
13/08/30 17:10:41 INFO mapreduce.Job:  map 100% reduce 17%
13/08/30 17:10:50 INFO mapreduce.Job:  map 100% reduce 18%
13/08/30 17:11:05 INFO mapreduce.Job:  map 100% reduce 19%
13/08/30 17:11:09 INFO mapreduce.Job:  map 100% reduce 21%
13/08/30 17:11:12 INFO mapreduce.Job:  map 100% reduce 22%
13/08/30 17:11:40 INFO mapreduce.Job:  map 100% reduce 23%
13/08/30 17:11:49 INFO mapreduce.Job:  map 100% reduce 24%
13/08/30 17:12:26 INFO mapreduce.Job:  map 100% reduce 25%
13/08/30 17:12:55 INFO mapreduce.Job:  map 100% reduce 26%
13/08/30 17:14:07 INFO mapreduce.Job:  map 100% reduce 27%
13/08/30 17:14:38 INFO mapreduce.Job:  map 100% reduce 28%
13/08/30 17:15:49 INFO mapreduce.Job:  map 100% reduce 29%
13/08/30 17:15:59 INFO mapreduce.Job:  map 100% reduce 30%
13/08/30 17:16:42 INFO mapreduce.Job:  map 100% reduce 31%
13/08/30 17:22:55 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_r_000000_0, Status : FAILED
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:121)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:379)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:263)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:193)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:268)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:154)

13/08/30 17:22:56 INFO mapreduce.Job:  map 100% reduce 0%
13/08/30 17:23:08 INFO mapreduce.Job:  map 100% reduce 4%
13/08/30 17:23:11 INFO mapreduce.Job:  map 100% reduce 6%
13/08/30 17:23:14 INFO mapreduce.Job:  map 100% reduce 7%
13/08/30 17:23:17 INFO mapreduce.Job:  map 100% reduce 9%
13/08/30 17:23:20 INFO mapreduce.Job:  map 100% reduce 11%
13/08/30 17:23:23 INFO mapreduce.Job:  map 100% reduce 12%
13/08/30 17:23:26 INFO mapreduce.Job:  map 100% reduce 13%
13/08/30 17:23:29 INFO mapreduce.Job:  map 100% reduce 15%
13/08/30 17:23:32 INFO mapreduce.Job:  map 100% reduce 17%
13/08/30 17:23:35 INFO mapreduce.Job:  map 100% reduce 18%
13/08/30 17:23:41 INFO mapreduce.Job:  map 100% reduce 20%
13/08/30 17:23:44 INFO mapreduce.Job:  map 100% reduce 21%
13/08/30 17:23:50 INFO mapreduce.Job:  map 100% reduce 22%
13/08/30 17:23:53 INFO mapreduce.Job:  map 100% reduce 23%
13/08/30 17:24:02 INFO mapreduce.Job:  map 100% reduce 24%
13/08/30 17:24:08 INFO mapreduce.Job:  map 100% reduce 25%
13/08/30 17:24:15 INFO mapreduce.Job:  map 100% reduce 26%
13/08/30 17:24:18 INFO mapreduce.Job:  map 100% reduce 27%
13/08/30 17:24:26 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000020_0, Status : FAILED
Container killed by the ApplicationMaster.


Too Many fetch failures.Failing the attempt
13/08/30 17:24:27 INFO mapreduce.Job:  map 98% reduce 27%
13/08/30 17:24:39 INFO mapreduce.Job:  map 99% reduce 27%
13/08/30 17:24:47 INFO mapreduce.Job:  map 100% reduce 27%
13/08/30 17:24:51 INFO mapreduce.Job:  map 100% reduce 28%
13/08/30 17:25:38 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000017_0, Status : FAILED
Container killed by the ApplicationMaster.


Too Many fetch failures.Failing the attempt
13/08/30 17:25:38 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000018_0, Status : FAILED
Container killed by the ApplicationMaster.


Too Many fetch failures.Failing the attempt
13/08/30 17:25:39 INFO mapreduce.Job:  map 95% reduce 28%
13/08/30 17:25:41 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_r_000000_1, Status : FAILED
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#5
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:121)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:379)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:263)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:193)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:268)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:154)

13/08/30 17:25:42 INFO mapreduce.Job:  map 95% reduce 0%
13/08/30 17:25:51 INFO mapreduce.Job:  map 97% reduce 0%
13/08/30 17:25:54 INFO mapreduce.Job:  map 98% reduce 0%
13/08/30 17:25:55 INFO mapreduce.Job:  map 98% reduce 3%
13/08/30 17:25:57 INFO mapreduce.Job:  map 99% reduce 3%
13/08/30 17:25:58 INFO mapreduce.Job:  map 99% reduce 6%
13/08/30 17:26:00 INFO mapreduce.Job:  map 100% reduce 6%
13/08/30 17:26:02 INFO mapreduce.Job:  map 100% reduce 8%
13/08/30 17:26:05 INFO mapreduce.Job:  map 100% reduce 10%
13/08/30 17:26:08 INFO mapreduce.Job:  map 100% reduce 12%
13/08/30 17:26:11 INFO mapreduce.Job:  map 100% reduce 13%
13/08/30 17:26:14 INFO mapreduce.Job:  map 100% reduce 15%
13/08/30 17:26:17 INFO mapreduce.Job:  map 100% reduce 16%
13/08/30 17:26:20 INFO mapreduce.Job:  map 100% reduce 17%
13/08/30 17:26:23 INFO mapreduce.Job:  map 100% reduce 19%
13/08/30 17:26:26 INFO mapreduce.Job:  map 100% reduce 20%
13/08/30 17:26:29 INFO mapreduce.Job:  map 100% reduce 21%
13/08/30 17:26:32 INFO mapreduce.Job:  map 100% reduce 22%
13/08/30 17:26:35 INFO mapreduce.Job:  map 100% reduce 23%
13/08/30 17:26:38 INFO mapreduce.Job:  map 100% reduce 24%
13/08/30 17:26:41 INFO mapreduce.Job:  map 100% reduce 25%
13/08/30 17:26:47 INFO mapreduce.Job:  map 100% reduce 26%
13/08/30 17:26:53 INFO mapreduce.Job:  map 100% reduce 27%
13/08/30 17:27:02 INFO mapreduce.Job:  map 100% reduce 28%
13/08/30 17:27:14 INFO mapreduce.Job:  map 100% reduce 29%
13/08/30 17:27:19 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000023_0, Status : FAILED
Too Many fetch failures.Failing the attempt
13/08/30 17:27:20 INFO mapreduce.Job:  map 98% reduce 29%
13/08/30 17:27:22 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000016_0, Status : FAILED
Container killed by the ApplicationMaster.


Too Many fetch failures.Failing the attempt
13/08/30 17:27:22 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000019_0, Status : FAILED
Too Many fetch failures.Failing the attempt
13/08/30 17:27:22 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000022_0, Status : FAILED
Too Many fetch failures.Failing the attempt
13/08/30 17:27:22 INFO mapreduce.Job: Task Id : attempt_1377881440942_0006_m_000021_0, Status : FAILED
Too Many fetch failures.Failing the attempt
13/08/30 17:27:23 INFO mapreduce.Job:  map 88% reduce 29%
13/08/30 17:27:32 INFO mapreduce.Job:  map 89% reduce 29%
13/08/30 17:27:35 INFO mapreduce.Job:  map 91% reduce 29%
13/08/30 17:27:37 INFO mapreduce.Job:  map 93% reduce 29%
13/08/30 17:27:38 INFO mapreduce.Job:  map 94% reduce 29%
13/08/30 17:27:39 INFO mapreduce.Job:  map 96% reduce 29%
13/08/30 17:27:40 INFO mapreduce.Job:  map 97% reduce 29%
13/08/30 17:27:41 INFO mapreduce.Job:  map 98% reduce 29%
13/08/30 17:27:43 INFO mapreduce.Job:  map 99% reduce 29%
13/08/30 17:27:45 INFO mapreduce.Job:  map 100% reduce 29%
13/08/30 17:27:48 INFO mapreduce.Job:  map 100% reduce 33%
13/08/30 17:30:11 INFO mapreduce.Job:  map 100% reduce 36%
13/08/30 17:30:14 INFO mapreduce.Job:  map 100% reduce 40%
13/08/30 17:30:17 INFO mapreduce.Job:  map 100% reduce 42%
13/08/30 17:30:20 INFO mapreduce.Job:  map 100% reduce 46%
13/08/30 17:30:23 INFO mapreduce.Job:  map 100% reduce 49%
13/08/30 17:30:26 INFO mapreduce.Job:  map 100% reduce 52%
13/08/30 17:30:29 INFO mapreduce.Job:  map 100% reduce 54%
13/08/30 17:30:32 INFO mapreduce.Job:  map 100% reduce 56%
13/08/30 17:30:35 INFO mapreduce.Job:  map 100% reduce 58%
13/08/30 17:30:38 INFO mapreduce.Job:  map 100% reduce 59%
13/08/30 17:30:41 INFO mapreduce.Job:  map 100% reduce 61%
13/08/30 17:30:44 INFO mapreduce.Job:  map 100% reduce 63%
13/08/30 17:30:47 INFO mapreduce.Job:  map 100% reduce 64%
13/08/30 17:30:50 INFO mapreduce.Job:  map 100% reduce 67%
13/08/30 17:31:09 INFO mapreduce.Job:  map 100% reduce 68%
13/08/30 17:31:29 INFO mapreduce.Job:  map 100% reduce 69%
13/08/30 17:31:44 INFO mapreduce.Job:  map 100% reduce 70%
13/08/30 17:32:15 INFO mapreduce.Job:  map 100% reduce 71%
13/08/30 17:32:27 INFO mapreduce.Job:  map 100% reduce 72%
13/08/30 17:32:45 INFO mapreduce.Job:  map 100% reduce 73%
13/08/30 17:32:57 INFO mapreduce.Job:  map 100% reduce 74%
13/08/30 17:33:10 INFO mapreduce.Job:  map 100% reduce 75%
13/08/30 17:33:25 INFO mapreduce.Job:  map 100% reduce 76%
13/08/30 17:33:40 INFO mapreduce.Job:  map 100% reduce 77%
13/08/30 17:33:49 INFO mapreduce.Job:  map 100% reduce 78%
13/08/30 17:34:01 INFO mapreduce.Job:  map 100% reduce 79%
13/08/30 17:34:13 INFO mapreduce.Job:  map 100% reduce 80%
13/08/30 17:34:23 INFO mapreduce.Job:  map 100% reduce 81%
13/08/30 17:34:32 INFO mapreduce.Job:  map 100% reduce 82%
13/08/30 17:34:38 INFO mapreduce.Job:  map 100% reduce 83%
13/08/30 17:34:44 INFO mapreduce.Job:  map 100% reduce 84%
13/08/30 17:34:50 INFO mapreduce.Job:  map 100% reduce 85%
13/08/30 17:34:59 INFO mapreduce.Job:  map 100% reduce 86%
13/08/30 17:35:05 INFO mapreduce.Job:  map 100% reduce 87%
13/08/30 17:35:11 INFO mapreduce.Job:  map 100% reduce 88%
13/08/30 17:35:17 INFO mapreduce.Job:  map 100% reduce 89%
13/08/30 17:35:26 INFO mapreduce.Job:  map 100% reduce 90%
13/08/30 17:35:32 INFO mapreduce.Job:  map 100% reduce 91%
13/08/30 17:35:38 INFO mapreduce.Job:  map 100% reduce 92%
13/08/30 17:35:44 INFO mapreduce.Job:  map 100% reduce 93%
13/08/30 17:35:50 INFO mapreduce.Job:  map 100% reduce 94%
13/08/30 17:35:59 INFO mapreduce.Job:  map 100% reduce 95%
13/08/30 17:36:05 INFO mapreduce.Job:  map 100% reduce 96%
13/08/30 17:36:12 INFO mapreduce.Job:  map 100% reduce 97%
13/08/30 17:36:21 INFO mapreduce.Job:  map 100% reduce 98%
13/08/30 17:36:27 INFO mapreduce.Job:  map 100% reduce 99%
13/08/30 17:36:36 INFO mapreduce.Job:  map 100% reduce 100%
13/08/30 17:36:38 INFO mapreduce.Job: Job job_1377881440942_0006 completed successfully
13/08/30 17:36:38 INFO mapreduce.Job: Counters: 47
	File System Counters
		FILE: Number of bytes read=15912854064
		FILE: Number of bytes written=21542722839
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5368715060
		HDFS: Number of bytes written=5368709100
		HDFS: Number of read operations=123
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Failed map tasks=8
		Failed reduce tasks=2
		Killed map tasks=6
		Launched map tasks=54
		Launched reduce tasks=3
		Other local map tasks=8
		Rack-local map tasks=46
		Total time spent by all maps in occupied slots (ms)=2857429
		Total time spent by all reduces in occupied slots (ms)=1702308
	Map-Reduce Framework
		Map input records=53687091
		Map output records=53687091
		Map output bytes=5476083282
		Map output materialized bytes=5583457704
		Input split bytes=5960
		Combine input records=0
		Combine output records=0
		Reduce input groups=53687091
		Reduce shuffle bytes=5583457704
		Reduce input records=53687091
		Reduce output records=53687091
		Spilled Records=206695296
		Shuffled Maps =40
		Failed Shuffles=50
		Merged Map outputs=40
		GC time elapsed (ms)=12250
		CPU time spent (ms)=1054640
		Physical memory (bytes) snapshot=10199035904
		Virtual memory (bytes) snapshot=41673441280
		Total committed heap usage (bytes)=7819886592
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=11
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5368709100
	File Output Format Counters 
		Bytes Written=5368709100
13/08/30 17:36:38 INFO terasort.TeraSort: done
