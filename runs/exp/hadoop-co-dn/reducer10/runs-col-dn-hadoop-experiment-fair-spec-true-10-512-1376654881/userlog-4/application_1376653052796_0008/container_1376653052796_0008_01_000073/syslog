2013-08-16 11:59:37,642 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-16 11:59:37,674 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-16 11:59:37,837 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-16 11:59:37,912 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-16 11:59:37,912 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-16 11:59:37,938 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-16 11:59:37,938 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1376653052796_0008, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-16 11:59:38,070 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-16 11:59:38,824 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008
2013-08-16 11:59:39,174 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-16 11:59:39,175 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-16 11:59:39,176 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-16 11:59:39,177 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-16 11:59:39,179 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-16 11:59:39,179 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-16 11:59:39,180 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-16 11:59:39,181 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-16 11:59:39,181 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-16 11:59:39,487 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-16 11:59:40,080 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-16 11:59:40,175 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1387e2f2
2013-08-16 11:59:40,231 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-16 11:59:40,238 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376653052796_0008_r_000000_1 Thread started: EventFetcher for fetching Map Completion Events
2013-08-16 11:59:40,266 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 4 to fetcher#5
2013-08-16 11:59:40,267 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-3:8080 to fetcher#5
2013-08-16 11:59:40,274 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 1 to fetcher#4
2013-08-16 11:59:40,275 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-4:8080 to fetcher#4
2013-08-16 11:59:40,275 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 3 to fetcher#3
2013-08-16 11:59:40,276 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-5:8080 to fetcher#3
2013-08-16 11:59:40,276 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 2 to fetcher#2
2013-08-16 11:59:40,276 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-6:8080 to fetcher#2
2013-08-16 11:59:40,276 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#1
2013-08-16 11:59:40,277 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#1
2013-08-16 11:59:40,282 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376653052796_0008_r_000000_1: Got 40 new map-outputs
2013-08-16 11:59:40,511 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000003_0,attempt_1376653052796_0008_m_000011_0,attempt_1376653052796_0008_m_000015_0 sent hash and received reply
2013-08-16 11:59:40,514 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000008_0,attempt_1376653052796_0008_m_000017_0 sent hash and received reply
2013-08-16 11:59:40,515 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000005_0,attempt_1376653052796_0008_m_000009_0,attempt_1376653052796_0008_m_000000_0,attempt_1376653052796_0008_m_000013_0 sent hash and received reply
2013-08-16 11:59:40,512 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000002_0,attempt_1376653052796_0008_m_000010_0 sent hash and received reply
2013-08-16 11:59:40,538 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000003_0 decomp: 13902410 len: 13902414 to MEMORY
2013-08-16 11:59:40,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000002_0 decomp: 13874018 len: 13874022 to MEMORY
2013-08-16 11:59:40,602 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000005_0 decomp: 13916970 len: 13916974 to MEMORY
2013-08-16 11:59:40,603 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000008_0 decomp: 13851450 len: 13851454 to MEMORY
2013-08-16 11:59:41,306 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13851450 bytes from map-output for attempt_1376653052796_0008_m_000008_0
2013-08-16 11:59:41,308 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13851450, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->55544848
2013-08-16 11:59:41,314 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000017_0 decomp: 13926746 len: 13926750 to MEMORY
2013-08-16 11:59:42,715 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13874018 bytes from map-output for attempt_1376653052796_0008_m_000002_0
2013-08-16 11:59:42,716 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13874018, inMemoryMapOutputs.size() -> 2, commitMemory -> 13851450, usedMemory ->69471594
2013-08-16 11:59:42,933 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000010_0 decomp: 13909794 len: 13909798 to MEMORY
2013-08-16 11:59:43,723 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909794 bytes from map-output for attempt_1376653052796_0008_m_000010_0
2013-08-16 11:59:43,724 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909794, inMemoryMapOutputs.size() -> 3, commitMemory -> 27725468, usedMemory ->83381388
2013-08-16 11:59:43,725 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#1 in 3449s
2013-08-16 11:59:43,725 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#1
2013-08-16 11:59:43,726 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#1
2013-08-16 11:59:43,735 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000016_0,attempt_1376653052796_0008_m_000027_0 sent hash and received reply
2013-08-16 11:59:43,749 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000016_0 decomp: 13900954 len: 13900958 to MEMORY
2013-08-16 11:59:43,782 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13926746 bytes from map-output for attempt_1376653052796_0008_m_000017_0
2013-08-16 11:59:43,783 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13926746, inMemoryMapOutputs.size() -> 4, commitMemory -> 41635262, usedMemory ->97282342
2013-08-16 11:59:43,785 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#2 in 3509s
2013-08-16 11:59:43,786 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 3 to fetcher#2
2013-08-16 11:59:43,787 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-6:8080 to fetcher#2
2013-08-16 11:59:43,795 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000018_0,attempt_1376653052796_0008_m_000026_0,attempt_1376653052796_0008_m_000033_0 sent hash and received reply
2013-08-16 11:59:43,799 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000018_0 decomp: 13840738 len: 13840742 to MEMORY
2013-08-16 11:59:44,458 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13900954 bytes from map-output for attempt_1376653052796_0008_m_000016_0
2013-08-16 11:59:44,459 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13900954, inMemoryMapOutputs.size() -> 5, commitMemory -> 55562008, usedMemory ->111123080
2013-08-16 11:59:44,466 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000027_0 decomp: 13887330 len: 13887334 to MEMORY
2013-08-16 11:59:45,419 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13840738 bytes from map-output for attempt_1376653052796_0008_m_000018_0
2013-08-16 11:59:45,420 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13840738, inMemoryMapOutputs.size() -> 6, commitMemory -> 69462962, usedMemory ->125010410
2013-08-16 11:59:45,535 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000026_0 decomp: 13901890 len: 13901894 to MEMORY
2013-08-16 11:59:46,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13901890 bytes from map-output for attempt_1376653052796_0008_m_000026_0
2013-08-16 11:59:46,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13901890, inMemoryMapOutputs.size() -> 7, commitMemory -> 83303700, usedMemory ->138912300
2013-08-16 11:59:46,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97205590 > mergeThreshold=86139864. Current usedMemory=138912300
2013-08-16 11:59:46,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:59:46,710 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 11:59:46,710 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#2 in 2924s
2013-08-16 11:59:46,817 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13887330 bytes from map-output for attempt_1376653052796_0008_m_000027_0
2013-08-16 11:59:46,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13887330, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->138912300
2013-08-16 11:59:46,818 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#1 in 3093s
2013-08-16 11:59:47,035 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:59:47,043 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:59:47,043 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97205499 bytes
2013-08-16 11:59:47,217 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000001_0 sent hash and received reply
2013-08-16 11:59:47,217 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-16 11:59:47,217 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#4 in 6942s
2013-08-16 11:59:48,040 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13902410 bytes from map-output for attempt_1376653052796_0008_m_000003_0
2013-08-16 11:59:48,040 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13902410, inMemoryMapOutputs.size() -> 2, commitMemory -> 13887330, usedMemory ->138912300
2013-08-16 11:59:48,041 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 11:59:48,042 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#3 in 7767s
2013-08-16 11:59:49,160 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376653052796_0008_r_000000_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008/output/attempt_1376653052796_0008_r_000000_1/map_18.out.merged of size 97205582
2013-08-16 11:59:49,161 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 8 to fetcher#3
2013-08-16 11:59:49,161 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-512-2:8080 to fetcher#3
2013-08-16 11:59:49,161 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 4 to fetcher#2
2013-08-16 11:59:49,162 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-5:8080 to fetcher#2
2013-08-16 11:59:49,162 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 10 to fetcher#1
2013-08-16 11:59:49,162 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 10 of 10 to hadoop-512-4:8080 to fetcher#1
2013-08-16 11:59:49,162 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#4
2013-08-16 11:59:49,162 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-6:8080 to fetcher#4
2013-08-16 11:59:49,167 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000033_0 sent hash and received reply
2013-08-16 11:59:49,167 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000006_0,attempt_1376653052796_0008_m_000007_0,attempt_1376653052796_0008_m_000004_0,attempt_1376653052796_0008_m_000020_0,attempt_1376653052796_0008_m_000024_0,attempt_1376653052796_0008_m_000029_0,attempt_1376653052796_0008_m_000038_0,attempt_1376653052796_0008_m_000037_0 sent hash and received reply
2013-08-16 11:59:49,167 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000019_0,attempt_1376653052796_0008_m_000030_0,attempt_1376653052796_0008_m_000015_0,attempt_1376653052796_0008_m_000011_0 sent hash and received reply
2013-08-16 11:59:49,172 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376653052796_0008_m_000033_0 decomp: 13890762 len: 13890766 to MEMORY
2013-08-16 11:59:49,260 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000006_0 decomp: 13936314 len: 13936318 to MEMORY
2013-08-16 11:59:49,269 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000019_0 decomp: 13879530 len: 13879534 to MEMORY
2013-08-16 11:59:49,502 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13916970 bytes from map-output for attempt_1376653052796_0008_m_000005_0
2013-08-16 11:59:49,502 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13916970, inMemoryMapOutputs.size() -> 3, commitMemory -> 27789740, usedMemory ->83413316
2013-08-16 11:59:49,506 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000009_0 decomp: 13866530 len: 13866534 to MEMORY
2013-08-16 11:59:49,658 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13890762 bytes from map-output for attempt_1376653052796_0008_m_000033_0
2013-08-16 11:59:49,658 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13890762, inMemoryMapOutputs.size() -> 4, commitMemory -> 41706710, usedMemory ->97279846
2013-08-16 11:59:49,659 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#4 in 497s
2013-08-16 11:59:53,690 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13866530 bytes from map-output for attempt_1376653052796_0008_m_000009_0
2013-08-16 11:59:53,690 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13866530, inMemoryMapOutputs.size() -> 5, commitMemory -> 55597472, usedMemory ->97279846
2013-08-16 11:59:53,800 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000000_0 decomp: 13880154 len: 13880158 to MEMORY
2013-08-16 11:59:55,133 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13879530 bytes from map-output for attempt_1376653052796_0008_m_000019_0
2013-08-16 11:59:55,134 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13879530, inMemoryMapOutputs.size() -> 6, commitMemory -> 69464002, usedMemory ->111160000
2013-08-16 11:59:55,138 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000030_0 decomp: 13896690 len: 13896694 to MEMORY
2013-08-16 11:59:57,750 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13880154 bytes from map-output for attempt_1376653052796_0008_m_000000_0
2013-08-16 11:59:57,949 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13880154, inMemoryMapOutputs.size() -> 7, commitMemory -> 83343532, usedMemory ->125056690
2013-08-16 11:59:57,949 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97223686 > mergeThreshold=86139864. Current usedMemory=125056690
2013-08-16 11:59:57,949 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:59:57,957 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000013_0 decomp: 13944426 len: 13944430 to MEMORY
2013-08-16 11:59:58,289 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:59:58,290 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:59:58,290 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97223595 bytes
2013-08-16 11:59:59,758 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376653052796_0008_r_000000_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008/output/attempt_1376653052796_0008_r_000000_1/map_9.out.merged of size 97223678
2013-08-16 12:00:02,336 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944426 bytes from map-output for attempt_1376653052796_0008_m_000013_0
2013-08-16 12:00:02,336 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944426, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41777430
2013-08-16 12:00:02,337 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#5 in 22071s
2013-08-16 12:00:02,337 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 4 to fetcher#5
2013-08-16 12:00:02,337 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-3:8080 to fetcher#5
2013-08-16 12:00:02,342 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000021_0,attempt_1376653052796_0008_m_000022_0,attempt_1376653052796_0008_m_000028_0,attempt_1376653052796_0008_m_000034_0 sent hash and received reply
2013-08-16 12:00:02,354 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000021_0 decomp: 13894610 len: 13894614 to MEMORY
2013-08-16 12:00:02,625 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896690 bytes from map-output for attempt_1376653052796_0008_m_000030_0
2013-08-16 12:00:02,625 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896690, inMemoryMapOutputs.size() -> 2, commitMemory -> 13944426, usedMemory ->55672040
2013-08-16 12:00:02,638 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000015_0 decomp: 13855090 len: 13855094 to MEMORY
2013-08-16 12:00:03,880 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13936314 bytes from map-output for attempt_1376653052796_0008_m_000006_0
2013-08-16 12:00:03,881 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13936314, inMemoryMapOutputs.size() -> 3, commitMemory -> 27841116, usedMemory ->69527130
2013-08-16 12:00:03,972 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000007_0 decomp: 13864866 len: 13864870 to MEMORY
2013-08-16 12:00:06,349 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13855090 bytes from map-output for attempt_1376653052796_0008_m_000015_0
2013-08-16 12:00:06,350 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13855090, inMemoryMapOutputs.size() -> 4, commitMemory -> 41777430, usedMemory ->83391996
2013-08-16 12:00:06,356 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376653052796_0008_m_000011_0 decomp: 13930074 len: 13930078 to MEMORY
2013-08-16 12:00:06,636 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13894610 bytes from map-output for attempt_1376653052796_0008_m_000021_0
2013-08-16 12:00:06,636 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13894610, inMemoryMapOutputs.size() -> 5, commitMemory -> 55632520, usedMemory ->97322070
2013-08-16 12:00:06,647 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000022_0 decomp: 13884002 len: 13884006 to MEMORY
2013-08-16 12:00:09,203 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13930074 bytes from map-output for attempt_1376653052796_0008_m_000011_0
2013-08-16 12:00:09,203 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13930074, inMemoryMapOutputs.size() -> 6, commitMemory -> 69527130, usedMemory ->111206072
2013-08-16 12:00:09,206 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#2 in 20045s
2013-08-16 12:00:11,008 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13884002 bytes from map-output for attempt_1376653052796_0008_m_000022_0
2013-08-16 12:00:11,008 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13884002, inMemoryMapOutputs.size() -> 7, commitMemory -> 83457204, usedMemory ->111206072
2013-08-16 12:00:11,008 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97341206 > mergeThreshold=86139864. Current usedMemory=111206072
2013-08-16 12:00:11,008 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 12:00:11,110 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000028_0 decomp: 13909898 len: 13909902 to MEMORY
2013-08-16 12:00:11,913 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 12:00:11,913 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 12:00:11,914 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97341115 bytes
2013-08-16 12:00:13,578 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376653052796_0008_r_000000_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008/output/attempt_1376653052796_0008_r_000000_1/map_15.out.merged of size 97341198
2013-08-16 12:00:14,095 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13909898 bytes from map-output for attempt_1376653052796_0008_m_000028_0
2013-08-16 12:00:14,096 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13909898, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27774764
2013-08-16 12:00:14,105 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376653052796_0008_m_000034_0 decomp: 13884106 len: 13884110 to MEMORY
2013-08-16 12:00:15,957 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13864866 bytes from map-output for attempt_1376653052796_0008_m_000007_0
2013-08-16 12:00:15,957 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13864866, inMemoryMapOutputs.size() -> 2, commitMemory -> 13909898, usedMemory ->41658870
2013-08-16 12:00:16,042 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000004_0 decomp: 13976874 len: 13976878 to MEMORY
2013-08-16 12:00:18,395 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13884106 bytes from map-output for attempt_1376653052796_0008_m_000034_0
2013-08-16 12:00:18,396 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13884106, inMemoryMapOutputs.size() -> 3, commitMemory -> 27774764, usedMemory ->55635744
2013-08-16 12:00:18,427 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#5 in 16090s
2013-08-16 12:00:20,402 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376653052796_0008&reduce=0&map=attempt_1376653052796_0008_m_000014_0,attempt_1376653052796_0008_m_000012_0,attempt_1376653052796_0008_m_000023_0,attempt_1376653052796_0008_m_000025_0,attempt_1376653052796_0008_m_000032_0,attempt_1376653052796_0008_m_000031_0,attempt_1376653052796_0008_m_000036_0,attempt_1376653052796_0008_m_000039_0,attempt_1376653052796_0008_m_000035_0,attempt_1376653052796_0008_m_000001_0 sent hash and received reply
2013-08-16 12:00:20,408 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000014_0 decomp: 13878802 len: 13878806 to MEMORY
2013-08-16 12:00:27,023 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976874 bytes from map-output for attempt_1376653052796_0008_m_000004_0
2013-08-16 12:00:27,024 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976874, inMemoryMapOutputs.size() -> 4, commitMemory -> 41658870, usedMemory ->69514546
2013-08-16 12:00:27,029 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000020_0 decomp: 13835850 len: 13835854 to MEMORY
2013-08-16 12:00:29,704 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13878802 bytes from map-output for attempt_1376653052796_0008_m_000014_0
2013-08-16 12:00:29,704 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13878802, inMemoryMapOutputs.size() -> 5, commitMemory -> 55635744, usedMemory ->83350396
2013-08-16 12:00:29,802 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000012_0 decomp: 13912914 len: 13912918 to MEMORY
2013-08-16 12:00:40,015 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13835850 bytes from map-output for attempt_1376653052796_0008_m_000020_0
2013-08-16 12:00:40,015 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13835850, inMemoryMapOutputs.size() -> 6, commitMemory -> 69514546, usedMemory ->97263310
2013-08-16 12:00:40,020 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000024_0 decomp: 13917802 len: 13917806 to MEMORY
2013-08-16 12:00:49,037 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13912914 bytes from map-output for attempt_1376653052796_0008_m_000012_0
2013-08-16 12:00:49,037 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13912914, inMemoryMapOutputs.size() -> 7, commitMemory -> 83350396, usedMemory ->111181112
2013-08-16 12:00:49,037 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97263310 > mergeThreshold=86139864. Current usedMemory=111181112
2013-08-16 12:00:49,037 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 12:00:49,046 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000023_0 decomp: 13874642 len: 13874646 to MEMORY
2013-08-16 12:00:49,721 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13917802 bytes from map-output for attempt_1376653052796_0008_m_000024_0
2013-08-16 12:00:49,721 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13917802, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->125055754
2013-08-16 12:00:49,803 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000029_0 decomp: 13877970 len: 13877974 to MEMORY
2013-08-16 12:00:50,288 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 12:00:50,288 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 12:00:50,289 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97263219 bytes
2013-08-16 12:00:52,258 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376653052796_0008_r_000000_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008/output/attempt_1376653052796_0008_r_000000_1/map_20.out.merged of size 97263302
2013-08-16 12:00:59,926 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13877970 bytes from map-output for attempt_1376653052796_0008_m_000029_0
2013-08-16 12:00:59,926 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13877970, inMemoryMapOutputs.size() -> 2, commitMemory -> 13917802, usedMemory ->41670414
2013-08-16 12:00:59,931 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000038_0 decomp: 13926018 len: 13926022 to MEMORY
2013-08-16 12:01:01,685 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13874642 bytes from map-output for attempt_1376653052796_0008_m_000023_0
2013-08-16 12:01:01,685 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13874642, inMemoryMapOutputs.size() -> 3, commitMemory -> 27795772, usedMemory ->55596432
2013-08-16 12:01:01,689 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000025_0 decomp: 13907090 len: 13907094 to MEMORY
2013-08-16 12:01:08,681 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13926018 bytes from map-output for attempt_1376653052796_0008_m_000038_0
2013-08-16 12:01:08,681 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13926018, inMemoryMapOutputs.size() -> 4, commitMemory -> 41670414, usedMemory ->69503522
2013-08-16 12:01:08,685 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376653052796_0008_m_000037_0 decomp: 13821706 len: 13821710 to MEMORY
2013-08-16 12:01:16,688 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13821706 bytes from map-output for attempt_1376653052796_0008_m_000037_0
2013-08-16 12:01:16,688 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13821706, inMemoryMapOutputs.size() -> 5, commitMemory -> 55596432, usedMemory ->83325228
2013-08-16 12:01:16,688 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#3 in 87527s
2013-08-16 12:01:18,378 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13907090 bytes from map-output for attempt_1376653052796_0008_m_000025_0
2013-08-16 12:01:18,379 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13907090, inMemoryMapOutputs.size() -> 6, commitMemory -> 69418138, usedMemory ->83325228
2013-08-16 12:01:18,383 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000032_0 decomp: 13879634 len: 13879638 to MEMORY
2013-08-16 12:01:34,443 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13879634 bytes from map-output for attempt_1376653052796_0008_m_000032_0
2013-08-16 12:01:34,444 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13879634, inMemoryMapOutputs.size() -> 7, commitMemory -> 83325228, usedMemory ->97204862
2013-08-16 12:01:34,445 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97204862 > mergeThreshold=86139864. Current usedMemory=97204862
2013-08-16 12:01:34,448 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 12:01:34,455 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000031_0 decomp: 13863930 len: 13863934 to MEMORY
2013-08-16 12:01:34,785 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 12:01:34,786 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 12:01:34,786 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97204771 bytes
2013-08-16 12:01:36,711 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376653052796_0008_r_000000_1 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376653052796_0008/output/attempt_1376653052796_0008_r_000000_1/map_37.out.merged of size 97204854
2013-08-16 12:01:51,789 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13863930 bytes from map-output for attempt_1376653052796_0008_m_000031_0
2013-08-16 12:01:51,790 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13863930, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13863930
2013-08-16 12:01:51,794 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000036_0 decomp: 13895234 len: 13895238 to MEMORY
2013-08-16 12:02:04,430 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13895234 bytes from map-output for attempt_1376653052796_0008_m_000036_0
2013-08-16 12:02:04,431 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13895234, inMemoryMapOutputs.size() -> 2, commitMemory -> 13863930, usedMemory ->27759164
2013-08-16 12:02:04,438 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000039_0 decomp: 13865074 len: 13865078 to MEMORY
2013-08-16 12:02:17,012 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13865074 bytes from map-output for attempt_1376653052796_0008_m_000039_0
2013-08-16 12:02:17,012 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13865074, inMemoryMapOutputs.size() -> 3, commitMemory -> 27759164, usedMemory ->41624238
2013-08-16 12:02:17,017 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000035_0 decomp: 13865386 len: 13865390 to MEMORY
2013-08-16 12:02:27,764 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13865386 bytes from map-output for attempt_1376653052796_0008_m_000035_0
2013-08-16 12:02:27,764 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13865386, inMemoryMapOutputs.size() -> 4, commitMemory -> 41624238, usedMemory ->55489624
2013-08-16 12:02:27,769 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376653052796_0008_m_000001_0 decomp: 13898250 len: 13898254 to MEMORY
2013-08-16 12:02:45,066 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13898250 bytes from map-output for attempt_1376653052796_0008_m_000001_0
2013-08-16 12:02:45,066 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13898250, inMemoryMapOutputs.size() -> 5, commitMemory -> 55489624, usedMemory ->69387874
2013-08-16 12:02:45,067 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#1 in 175905s
2013-08-16 12:02:45,068 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-16 12:02:45,075 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-16 12:02:45,218 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-16 12:02:45,218 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69387809 bytes
2013-08-16 12:02:46,515 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69387874 bytes to disk to satisfy reduce memory limit
2013-08-16 12:02:46,517 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 555626484 bytes from disk
2013-08-16 12:02:46,519 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-16 12:02:46,520 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-16 12:02:46,987 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 555626382 bytes
2013-08-16 12:02:47,309 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-16 12:03:33,507 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376653052796_0008_r_000000_1/part-r-00000
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-1/_temporary/1/_temporary/attempt_1376653052796_0008_r_000000_1/part-r-00000: File does not exist. Holder DFSClient_attempt_1376653052796_0008_r_000000_1_-473630622_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-16 12:03:33,532 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: Filesystem closed
2013-08-16 12:03:33,533 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:540)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1435)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-16 12:03:33,540 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
