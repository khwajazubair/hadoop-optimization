2013-08-16 11:22:08,080 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2013-08-16 11:22:08,127 ERROR [main] org.apache.hadoop.util.Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:163)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:186)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:77)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:91)
2013-08-16 11:22:08,313 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2013-08-16 11:22:08,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2013-08-16 11:22:08,469 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
2013-08-16 11:22:08,493 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens:
2013-08-16 11:22:08,493 INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: job_1376651007637_0006, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@3a5f5a46)
2013-08-16 11:22:08,625 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2013-08-16 11:22:09,404 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006
2013-08-16 11:22:09,582 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2013-08-16 11:22:09,582 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2013-08-16 11:22:09,733 WARN [main] org.apache.hadoop.conf.Configuration: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2013-08-16 11:22:09,734 WARN [main] org.apache.hadoop.conf.Configuration: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2013-08-16 11:22:09,734 WARN [main] org.apache.hadoop.conf.Configuration: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir
2013-08-16 11:22:09,735 WARN [main] org.apache.hadoop.conf.Configuration: job.local.dir is deprecated. Instead, use mapreduce.job.local.dir
2013-08-16 11:22:09,735 WARN [main] org.apache.hadoop.conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2013-08-16 11:22:09,736 WARN [main] org.apache.hadoop.conf.Configuration: mapred.cache.localFiles is deprecated. Instead, use mapreduce.job.cache.local.files
2013-08-16 11:22:09,736 WARN [main] org.apache.hadoop.conf.Configuration: mapred.job.id is deprecated. Instead, use mapreduce.job.id
2013-08-16 11:22:09,917 WARN [main] org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2013-08-16 11:22:10,486 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2013-08-16 11:22:10,589 INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e0b62b2
2013-08-16 11:22:10,630 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=130514944, maxSingleShuffleLimit=32628736, mergeThreshold=86139864, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-08-16 11:22:10,637 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376651007637_0006_r_000008_0 Thread started: EventFetcher for fetching Map Completion Events
2013-08-16 11:22:10,661 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 1 to fetcher#3
2013-08-16 11:22:10,662 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 1 to fetcher#1
2013-08-16 11:22:10,664 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-5:8080 to fetcher#1
2013-08-16 11:22:10,679 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1376651007637_0006_r_000008_0: Got 40 new map-outputs
2013-08-16 11:22:10,679 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 10 of 10 to hadoop-512-6:8080 to fetcher#3
2013-08-16 11:22:10,679 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-4:8080 with 5 to fetcher#5
2013-08-16 11:22:10,680 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-4:8080 to fetcher#5
2013-08-16 11:22:10,680 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 12 to fetcher#4
2013-08-16 11:22:10,681 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-3:8080 with 4 to fetcher#2
2013-08-16 11:22:10,681 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to hadoop-512-3:8080 to fetcher#2
2013-08-16 11:22:10,682 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 12 of 12 to hadoop-512-7:8080 to fetcher#4
2013-08-16 11:22:10,913 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000010_0,attempt_1376651007637_0006_m_000017_0,attempt_1376651007637_0006_m_000025_0,attempt_1376651007637_0006_m_000031_0 sent hash and received reply
2013-08-16 11:22:10,914 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000006_0,attempt_1376651007637_0006_m_000000_0,attempt_1376651007637_0006_m_000002_0,attempt_1376651007637_0006_m_000004_0,attempt_1376651007637_0006_m_000005_0,attempt_1376651007637_0006_m_000011_0,attempt_1376651007637_0006_m_000012_0,attempt_1376651007637_0006_m_000021_0,attempt_1376651007637_0006_m_000033_0,attempt_1376651007637_0006_m_000038_0 sent hash and received reply
2013-08-16 11:22:10,926 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000010_0 decomp: 13952642 len: 13952646 to MEMORY
2013-08-16 11:22:10,987 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000006_0 decomp: 13896066 len: 13896070 to MEMORY
2013-08-16 11:22:11,306 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13952642 bytes from map-output for attempt_1376651007637_0006_m_000010_0
2013-08-16 11:22:11,314 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13952642, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->27848708
2013-08-16 11:22:11,319 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000017_0 decomp: 14026170 len: 14026174 to MEMORY
2013-08-16 11:22:11,475 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14026170 bytes from map-output for attempt_1376651007637_0006_m_000017_0
2013-08-16 11:22:11,475 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14026170, inMemoryMapOutputs.size() -> 2, commitMemory -> 13952642, usedMemory ->41874878
2013-08-16 11:22:11,480 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000025_0 decomp: 13968138 len: 13968142 to MEMORY
2013-08-16 11:22:14,209 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000003_0 sent hash and received reply
2013-08-16 11:22:14,235 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0006_m_000003_0 decomp: 13975106 len: 13975110 to MEMORY
2013-08-16 11:22:14,360 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13968138 bytes from map-output for attempt_1376651007637_0006_m_000025_0
2013-08-16 11:22:14,361 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13968138, inMemoryMapOutputs.size() -> 3, commitMemory -> 27978812, usedMemory ->69818122
2013-08-16 11:22:14,619 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000031_0 decomp: 14056330 len: 14056334 to MEMORY
2013-08-16 11:22:16,874 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14056330 bytes from map-output for attempt_1376651007637_0006_m_000031_0
2013-08-16 11:22:16,875 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14056330, inMemoryMapOutputs.size() -> 4, commitMemory -> 41946950, usedMemory ->83874452
2013-08-16 11:22:16,876 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-3:8080 freed by fetcher#2 in 6194s
2013-08-16 11:22:16,876 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 3 to fetcher#2
2013-08-16 11:22:16,876 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 3 of 3 to hadoop-512-2:8080 to fetcher#2
2013-08-16 11:22:16,883 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000008_0,attempt_1376651007637_0006_m_000020_0,attempt_1376651007637_0006_m_000029_0 sent hash and received reply
2013-08-16 11:22:16,893 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000008_0 decomp: 13979994 len: 13979998 to MEMORY
2013-08-16 11:22:17,735 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000009_0,attempt_1376651007637_0006_m_000016_0,attempt_1376651007637_0006_m_000024_0,attempt_1376651007637_0006_m_000035_0,attempt_1376651007637_0006_m_000037_0 sent hash and received reply
2013-08-16 11:22:17,740 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0006_m_000009_0 decomp: 13958154 len: 13958158 to MEMORY
2013-08-16 11:22:18,685 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13979994 bytes from map-output for attempt_1376651007637_0006_m_000008_0
2013-08-16 11:22:18,685 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13979994, inMemoryMapOutputs.size() -> 5, commitMemory -> 56003280, usedMemory ->111812600
2013-08-16 11:22:18,871 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000020_0 decomp: 14012546 len: 14012550 to MEMORY
2013-08-16 11:22:19,385 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13896066 bytes from map-output for attempt_1376651007637_0006_m_000006_0
2013-08-16 11:22:19,386 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13896066, inMemoryMapOutputs.size() -> 6, commitMemory -> 69983274, usedMemory ->125825146
2013-08-16 11:22:19,391 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000000_0 decomp: 14001834 len: 14001838 to MEMORY
2013-08-16 11:22:20,218 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14012546 bytes from map-output for attempt_1376651007637_0006_m_000020_0
2013-08-16 11:22:20,219 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14012546, inMemoryMapOutputs.size() -> 7, commitMemory -> 83879340, usedMemory ->139826980
2013-08-16 11:22:20,219 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97891886 > mergeThreshold=86139864. Current usedMemory=139826980
2013-08-16 11:22:20,219 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:22:20,220 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 11:22:20,220 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#2 in 3344s
2013-08-16 11:22:21,383 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:22:21,392 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:22:21,393 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97891795 bytes
2013-08-16 11:22:22,987 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14001834 bytes from map-output for attempt_1376651007637_0006_m_000000_0
2013-08-16 11:22:22,987 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14001834, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139826980
2013-08-16 11:22:22,988 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 11:22:22,989 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#3 in 12327s
2013-08-16 11:22:24,709 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0006_r_000008_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006/output/attempt_1376651007637_0006_r_000008_0/map_6.out.merged of size 97891878
2013-08-16 11:22:24,709 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-6:8080 with 8 to fetcher#3
2013-08-16 11:22:24,709 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 8 of 8 to hadoop-512-6:8080 to fetcher#3
2013-08-16 11:22:24,709 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-2:8080 with 1 to fetcher#2
2013-08-16 11:22:24,710 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to hadoop-512-2:8080 to fetcher#2
2013-08-16 11:22:25,884 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000029_0 sent hash and received reply
2013-08-16 11:22:25,970 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000029_0 decomp: 13987482 len: 13987486 to MEMORY
2013-08-16 11:22:26,085 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13975106 bytes from map-output for attempt_1376651007637_0006_m_000003_0
2013-08-16 11:22:26,086 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13975106, inMemoryMapOutputs.size() -> 2, commitMemory -> 14001834, usedMemory ->55922576
2013-08-16 11:22:26,086 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#1 in 15423s
2013-08-16 11:22:26,086 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 5 to fetcher#1
2013-08-16 11:22:26,087 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 5 of 5 to hadoop-512-5:8080 to fetcher#1
2013-08-16 11:22:26,097 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000019_0,attempt_1376651007637_0006_m_000028_0,attempt_1376651007637_0006_m_000032_0,attempt_1376651007637_0006_m_000036_0,attempt_1376651007637_0006_m_000039_0 sent hash and received reply
2013-08-16 11:22:26,102 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0006_m_000019_0 decomp: 13940578 len: 13940582 to MEMORY
2013-08-16 11:22:30,294 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13987482 bytes from map-output for attempt_1376651007637_0006_m_000029_0
2013-08-16 11:22:30,294 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13987482, inMemoryMapOutputs.size() -> 3, commitMemory -> 27976940, usedMemory ->69863154
2013-08-16 11:22:30,295 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-2:8080 freed by fetcher#2 in 5585s
2013-08-16 11:22:30,736 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13940578 bytes from map-output for attempt_1376651007637_0006_m_000019_0
2013-08-16 11:22:30,737 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13940578, inMemoryMapOutputs.size() -> 4, commitMemory -> 41964422, usedMemory ->69863154
2013-08-16 11:22:30,741 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0006_m_000028_0 decomp: 13954514 len: 13954518 to MEMORY
2013-08-16 11:22:33,184 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000038_0,attempt_1376651007637_0006_m_000012_0,attempt_1376651007637_0006_m_000005_0,attempt_1376651007637_0006_m_000002_0,attempt_1376651007637_0006_m_000011_0,attempt_1376651007637_0006_m_000021_0,attempt_1376651007637_0006_m_000004_0,attempt_1376651007637_0006_m_000033_0 sent hash and received reply
2013-08-16 11:22:33,274 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000038_0 decomp: 14004018 len: 14004022 to MEMORY
2013-08-16 11:22:33,320 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14004018 bytes from map-output for attempt_1376651007637_0006_m_000038_0
2013-08-16 11:22:33,320 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14004018, inMemoryMapOutputs.size() -> 5, commitMemory -> 55905000, usedMemory ->97821686
2013-08-16 11:22:33,324 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000012_0 decomp: 14010362 len: 14010366 to MEMORY
2013-08-16 11:22:42,961 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13954514 bytes from map-output for attempt_1376651007637_0006_m_000028_0
2013-08-16 11:22:42,961 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13954514, inMemoryMapOutputs.size() -> 6, commitMemory -> 69909018, usedMemory ->111832048
2013-08-16 11:22:42,964 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1376651007637_0006_m_000032_0 decomp: 13934858 len: 13934862 to MEMORY
2013-08-16 11:22:43,863 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14010362 bytes from map-output for attempt_1376651007637_0006_m_000012_0
2013-08-16 11:22:43,864 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14010362, inMemoryMapOutputs.size() -> 7, commitMemory -> 83863532, usedMemory ->125766906
2013-08-16 11:22:43,864 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97873894 > mergeThreshold=86139864. Current usedMemory=125766906
2013-08-16 11:22:43,864 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:22:43,948 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000005_0 decomp: 13957426 len: 13957430 to MEMORY
2013-08-16 11:22:45,951 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:22:45,952 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:22:45,952 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97873803 bytes
2013-08-16 11:22:48,752 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13934858 bytes from map-output for attempt_1376651007637_0006_m_000032_0
2013-08-16 11:22:48,752 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13934858, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->139724332
2013-08-16 11:22:48,753 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-16 11:22:48,753 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#1 in 22666s
2013-08-16 11:22:48,753 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 2 to fetcher#2
2013-08-16 11:22:48,754 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-5:8080 to fetcher#2
2013-08-16 11:22:49,175 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000036_0,attempt_1376651007637_0006_m_000039_0 sent hash and received reply
2013-08-16 11:22:49,177 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2013-08-16 11:22:49,177 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#2 in 423s
2013-08-16 11:22:49,442 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0006_r_000008_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006/output/attempt_1376651007637_0006_r_000008_0/map_19.out.merged of size 97873886
2013-08-16 11:22:49,443 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-5:8080 with 2 to fetcher#2
2013-08-16 11:22:49,443 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-5:8080 to fetcher#2
2013-08-16 11:22:49,463 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000036_0,attempt_1376651007637_0006_m_000039_0 sent hash and received reply
2013-08-16 11:22:49,469 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000036_0 decomp: 14006930 len: 14006934 to MEMORY
2013-08-16 11:22:54,783 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13957426 bytes from map-output for attempt_1376651007637_0006_m_000005_0
2013-08-16 11:22:54,783 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13957426, inMemoryMapOutputs.size() -> 2, commitMemory -> 13934858, usedMemory ->55857368
2013-08-16 11:22:54,788 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000002_0 decomp: 13923626 len: 13923630 to MEMORY
2013-08-16 11:22:57,837 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14006930 bytes from map-output for attempt_1376651007637_0006_m_000036_0
2013-08-16 11:22:57,837 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14006930, inMemoryMapOutputs.size() -> 3, commitMemory -> 27892284, usedMemory ->69780994
2013-08-16 11:22:57,842 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000039_0 decomp: 13925914 len: 13925918 to MEMORY
2013-08-16 11:22:58,095 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13923626 bytes from map-output for attempt_1376651007637_0006_m_000002_0
2013-08-16 11:22:58,095 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13923626, inMemoryMapOutputs.size() -> 4, commitMemory -> 41899214, usedMemory ->83706908
2013-08-16 11:22:58,099 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000011_0 decomp: 13988314 len: 13988318 to MEMORY
2013-08-16 11:22:58,293 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13958154 bytes from map-output for attempt_1376651007637_0006_m_000009_0
2013-08-16 11:22:58,293 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13958154, inMemoryMapOutputs.size() -> 5, commitMemory -> 55822840, usedMemory ->97695222
2013-08-16 11:22:58,404 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0006_m_000016_0 decomp: 13958154 len: 13958158 to MEMORY
2013-08-16 11:23:02,724 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13988314 bytes from map-output for attempt_1376651007637_0006_m_000011_0
2013-08-16 11:23:02,724 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13988314, inMemoryMapOutputs.size() -> 6, commitMemory -> 69780994, usedMemory ->111653376
2013-08-16 11:23:02,728 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000021_0 decomp: 13943698 len: 13943702 to MEMORY
2013-08-16 11:23:03,106 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13925914 bytes from map-output for attempt_1376651007637_0006_m_000039_0
2013-08-16 11:23:03,106 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13925914, inMemoryMapOutputs.size() -> 7, commitMemory -> 83769308, usedMemory ->125597074
2013-08-16 11:23:03,106 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97695222 > mergeThreshold=86139864. Current usedMemory=125597074
2013-08-16 11:23:03,106 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:23:03,107 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-5:8080 freed by fetcher#2 in 13664s
2013-08-16 11:23:03,402 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:23:03,403 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:23:03,403 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97695131 bytes
2013-08-16 11:23:04,730 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0006_r_000008_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006/output/attempt_1376651007637_0006_r_000008_0/map_2.out.merged of size 97695214
2013-08-16 11:23:07,239 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000001_0,attempt_1376651007637_0006_m_000007_0,attempt_1376651007637_0006_m_000014_0,attempt_1376651007637_0006_m_000018_0,attempt_1376651007637_0006_m_000013_0,attempt_1376651007637_0006_m_000015_0,attempt_1376651007637_0006_m_000026_0,attempt_1376651007637_0006_m_000023_0,attempt_1376651007637_0006_m_000022_0,attempt_1376651007637_0006_m_000027_0,attempt_1376651007637_0006_m_000030_0,attempt_1376651007637_0006_m_000034_0 sent hash and received reply
2013-08-16 11:23:07,246 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000001_0 decomp: 13944842 len: 13944846 to MEMORY
2013-08-16 11:23:09,876 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13943698 bytes from map-output for attempt_1376651007637_0006_m_000021_0
2013-08-16 11:23:09,877 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13943698, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41846694
2013-08-16 11:23:09,882 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000004_0 decomp: 13922378 len: 13922382 to MEMORY
2013-08-16 11:23:09,911 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13958154 bytes from map-output for attempt_1376651007637_0006_m_000016_0
2013-08-16 11:23:09,911 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13958154, inMemoryMapOutputs.size() -> 2, commitMemory -> 13943698, usedMemory ->55769072
2013-08-16 11:23:09,915 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0006_m_000024_0 decomp: 14008698 len: 14008702 to MEMORY
2013-08-16 11:23:20,061 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14008698 bytes from map-output for attempt_1376651007637_0006_m_000024_0
2013-08-16 11:23:20,061 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14008698, inMemoryMapOutputs.size() -> 3, commitMemory -> 27901852, usedMemory ->69777770
2013-08-16 11:23:20,065 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0006_m_000035_0 decomp: 13967618 len: 13967622 to MEMORY
2013-08-16 11:23:21,568 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13922378 bytes from map-output for attempt_1376651007637_0006_m_000004_0
2013-08-16 11:23:21,568 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13922378, inMemoryMapOutputs.size() -> 4, commitMemory -> 41910550, usedMemory ->83745388
2013-08-16 11:23:21,573 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_1376651007637_0006_m_000033_0 decomp: 13948378 len: 13948382 to MEMORY
2013-08-16 11:23:26,340 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13948378 bytes from map-output for attempt_1376651007637_0006_m_000033_0
2013-08-16 11:23:26,341 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13948378, inMemoryMapOutputs.size() -> 5, commitMemory -> 55832928, usedMemory ->97693766
2013-08-16 11:23:26,341 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-6:8080 freed by fetcher#3 in 61632s
2013-08-16 11:24:03,075 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13967618 bytes from map-output for attempt_1376651007637_0006_m_000035_0
2013-08-16 11:24:03,075 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13967618, inMemoryMapOutputs.size() -> 6, commitMemory -> 69781306, usedMemory ->97693766
2013-08-16 11:24:03,079 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 about to shuffle output of map attempt_1376651007637_0006_m_000037_0 decomp: 13935690 len: 13935694 to MEMORY
2013-08-16 11:24:07,650 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13935690 bytes from map-output for attempt_1376651007637_0006_m_000037_0
2013-08-16 11:24:07,898 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13935690, inMemoryMapOutputs.size() -> 7, commitMemory -> 83748924, usedMemory ->111629456
2013-08-16 11:24:07,898 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97684614 > mergeThreshold=86139864. Current usedMemory=111629456
2013-08-16 11:24:07,898 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:24:07,902 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-4:8080 freed by fetcher#5 in 117222s
2013-08-16 11:24:08,141 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:24:08,142 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:24:08,142 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97684523 bytes
2013-08-16 11:24:10,951 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0006_r_000008_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006/output/attempt_1376651007637_0006_r_000008_0/map_4.out.merged of size 97684606
2013-08-16 11:29:29,944 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13944842 bytes from map-output for attempt_1376651007637_0006_m_000001_0
2013-08-16 11:29:29,945 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13944842, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13944842
2013-08-16 11:29:29,949 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000007_0 decomp: 13983114 len: 13983118 to MEMORY
2013-08-16 11:29:37,096 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13983114 bytes from map-output for attempt_1376651007637_0006_m_000007_0
2013-08-16 11:29:37,097 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13983114, inMemoryMapOutputs.size() -> 2, commitMemory -> 13944842, usedMemory ->27927956
2013-08-16 11:29:37,101 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000014_0 decomp: 13955762 len: 13955766 to MEMORY
2013-08-16 11:29:38,825 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13955762 bytes from map-output for attempt_1376651007637_0006_m_000014_0
2013-08-16 11:29:38,825 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13955762, inMemoryMapOutputs.size() -> 3, commitMemory -> 27927956, usedMemory ->41883718
2013-08-16 11:29:38,935 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000018_0 decomp: 13989562 len: 13989566 to MEMORY
2013-08-16 11:29:43,825 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13989562 bytes from map-output for attempt_1376651007637_0006_m_000018_0
2013-08-16 11:29:43,826 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13989562, inMemoryMapOutputs.size() -> 4, commitMemory -> 41883718, usedMemory ->55873280
2013-08-16 11:29:43,831 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000013_0 decomp: 14033866 len: 14033870 to MEMORY
2013-08-16 11:29:44,200 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 14033866 bytes from map-output for attempt_1376651007637_0006_m_000013_0
2013-08-16 11:29:44,200 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14033866, inMemoryMapOutputs.size() -> 5, commitMemory -> 55873280, usedMemory ->69907146
2013-08-16 11:29:44,207 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000015_0 decomp: 13893050 len: 13893054 to MEMORY
2013-08-16 11:29:44,304 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13893050 bytes from map-output for attempt_1376651007637_0006_m_000015_0
2013-08-16 11:29:44,304 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13893050, inMemoryMapOutputs.size() -> 6, commitMemory -> 69907146, usedMemory ->83800196
2013-08-16 11:29:44,416 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000026_0 decomp: 13991954 len: 13991958 to MEMORY
2013-08-16 11:29:44,461 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13991954 bytes from map-output for attempt_1376651007637_0006_m_000026_0
2013-08-16 11:29:44,462 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13991954, inMemoryMapOutputs.size() -> 7, commitMemory -> 83800196, usedMemory ->97792150
2013-08-16 11:29:44,462 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Starting inMemoryMerger's merge since commitMemory=97792150 > mergeThreshold=86139864. Current usedMemory=97792150
2013-08-16 11:29:44,462 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 7 segments, while ignoring 0 segments
2013-08-16 11:29:44,473 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000023_0 decomp: 13932362 len: 13932366 to MEMORY
2013-08-16 11:29:44,656 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Initiating in-memory merge with 7 segments...
2013-08-16 11:29:44,656 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Merging 7 sorted segments
2013-08-16 11:29:44,656 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 97792059 bytes
2013-08-16 11:29:44,749 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13932362 bytes from map-output for attempt_1376651007637_0006_m_000023_0
2013-08-16 11:29:44,749 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13932362, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->111724512
2013-08-16 11:29:44,885 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000022_0 decomp: 13884834 len: 13884838 to MEMORY
2013-08-16 11:29:44,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13884834 bytes from map-output for attempt_1376651007637_0006_m_000022_0
2013-08-16 11:29:44,992 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13884834, inMemoryMapOutputs.size() -> 2, commitMemory -> 13932362, usedMemory ->125609346
2013-08-16 11:29:44,997 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1376651007637_0006_m_000027_0 decomp: 13924666 len: 13924670 to MEMORY
2013-08-16 11:29:45,509 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13924666 bytes from map-output for attempt_1376651007637_0006_m_000027_0
2013-08-16 11:29:45,510 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13924666, inMemoryMapOutputs.size() -> 3, commitMemory -> 27817196, usedMemory ->139534012
2013-08-16 11:29:45,511 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2013-08-16 11:29:45,511 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#4 in 454830s
2013-08-16 11:29:45,516 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#5
2013-08-16 11:29:45,517 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#5
2013-08-16 11:29:45,524 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000030_0,attempt_1376651007637_0006_m_000034_0 sent hash and received reply
2013-08-16 11:29:45,537 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2013-08-16 11:29:45,537 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#5 in 20s
2013-08-16 11:29:45,537 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#1
2013-08-16 11:29:45,538 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#1
2013-08-16 11:29:45,545 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000034_0,attempt_1376651007637_0006_m_000030_0 sent hash and received reply
2013-08-16 11:29:45,550 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2013-08-16 11:29:45,551 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#1 in 14s
2013-08-16 11:29:45,552 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#3
2013-08-16 11:29:45,552 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#3
2013-08-16 11:29:45,567 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000034_0,attempt_1376651007637_0006_m_000030_0 sent hash and received reply
2013-08-16 11:29:45,568 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2013-08-16 11:29:45,568 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#3 in 16s
2013-08-16 11:29:45,569 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging hadoop-512-7:8080 with 2 to fetcher#2
2013-08-16 11:29:45,569 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 2 of 2 to hadoop-512-7:8080 to fetcher#2
2013-08-16 11:29:46,497 INFO [InMemoryMerger - Thread to merge in-memory shuffled map-outputs] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: attempt_1376651007637_0006_r_000008_0 Merge of the 7 files in-memory complete. Local file is /mnt/hdfs-tmp/nm-local-dir/usercache/ubuntu/appcache/application_1376651007637_0006/output/attempt_1376651007637_0006_r_000008_0/map_15.out.merged of size 97792142
2013-08-16 11:29:46,673 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1376651007637_0006&reduce=8&map=attempt_1376651007637_0006_m_000034_0,attempt_1376651007637_0006_m_000030_0 sent hash and received reply
2013-08-16 11:29:46,677 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000034_0 decomp: 13937770 len: 13937774 to MEMORY
2013-08-16 11:29:48,541 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13937770 bytes from map-output for attempt_1376651007637_0006_m_000034_0
2013-08-16 11:29:48,541 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13937770, inMemoryMapOutputs.size() -> 4, commitMemory -> 41741862, usedMemory ->55679632
2013-08-16 11:29:48,666 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 about to shuffle output of map attempt_1376651007637_0006_m_000030_0 decomp: 13976354 len: 13976358 to MEMORY
2013-08-16 11:29:49,748 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 13976354 bytes from map-output for attempt_1376651007637_0006_m_000030_0
2013-08-16 11:29:49,748 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13976354, inMemoryMapOutputs.size() -> 5, commitMemory -> 55679632, usedMemory ->69655986
2013-08-16 11:29:49,748 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2013-08-16 11:29:49,748 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: hadoop-512-7:8080 freed by fetcher#2 in 4179s
2013-08-16 11:29:49,752 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 5 on-disk map-outputs
2013-08-16 11:29:49,835 INFO [main] org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2013-08-16 11:29:49,836 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 69655921 bytes
2013-08-16 11:29:50,681 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 69655986 bytes to disk to satisfy reduce memory limit
2013-08-16 11:29:50,682 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 6 files, 558593708 bytes from disk
2013-08-16 11:29:50,684 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2013-08-16 11:29:50,684 INFO [main] org.apache.hadoop.mapred.Merger: Merging 6 sorted segments
2013-08-16 11:29:51,786 INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 558593606 bytes
2013-08-16 11:29:51,975 WARN [main] org.apache.hadoop.conf.Configuration: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2013-08-16 11:30:14,242 ERROR [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:ubuntu (auth:SIMPLE) cause:java.io.IOException: DFSOutputStream is closed
2013-08-16 11:30:14,243 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: DFSOutputStream is closed
	at org.apache.hadoop.hdfs.DFSOutputStream.isClosed(DFSOutputStream.java:1269)
	at org.apache.hadoop.hdfs.DFSOutputStream.writeChunk(DFSOutputStream.java:1436)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunk(FSOutputSummer.java:163)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:138)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:127)
	at org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:118)
	at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:92)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:70)
	at org.apache.hadoop.examples.terasort.TeraOutputFormat$TeraRecordWriter.write(TeraOutputFormat.java:57)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:580)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at org.apache.hadoop.mapreduce.Reducer.reduce(Reducer.java:150)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:648)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:404)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)

2013-08-16 11:30:14,246 ERROR [Thread-3] org.apache.hadoop.hdfs.DFSClient: Failed to close file /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1376651007637_0006_r_000008_0/part-r-00008
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /user/hduser/terasort-output-4/_temporary/1/_temporary/attempt_1376651007637_0006_r_000008_0/part-r-00008: File does not exist. Holder DFSClient_attempt_1376651007637_0006_r_000008_0_-1452035094_1 does not have any open files.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2484)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2474)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2543)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:553)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:395)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:40983)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:526)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1018)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1818)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1814)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1489)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1812)

	at org.apache.hadoop.ipc.Client.call(Client.java:1301)
	at org.apache.hadoop.ipc.Client.call(Client.java:1253)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:204)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:163)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:82)
	at com.sun.proxy.$Proxy10.complete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:354)
	at org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:1828)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:1815)
	at org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(DFSClient.java:684)
	at org.apache.hadoop.hdfs.DFSClient.closeOutputStreams(DFSClient.java:716)
	at org.apache.hadoop.hdfs.DistributedFileSystem.close(DistributedFileSystem.java:559)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2401)
	at org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer.run(FileSystem.java:2418)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2013-08-16 11:30:14,248 INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
